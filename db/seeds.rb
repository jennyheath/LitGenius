User.create!([
  {username: "Chemist1", password: "password"},
  {username: "Guest User", password: "password"},
  {username: "Neurobiologist1", password: "password"},
  {username: "Geneticist1", password: "password"},
  {username: "Mathematician1", password: "password"},
  {username: "Physicist1", password: "password"}
])

Field.create!([
  {name: "Neurobiology"},
  {name: "Biochemistry"},
  {name: "Bioengineering"},
  {name: "Bioinformatics"},
  {name: "Biophysics"},
  {name: "Cell Biology"},
  {name: "Epidemiology"},
  {name: "Genetics"},
  {name: "Molecular Biology"},
  {name: "Chemistry"},
  {name: "Chemical Engineering"},
  {name: "Inorganic Chemistry"},
  {name: "Organic Chemistry"},
  {name: "Physical Chemistry"},
  {name: "Geophysics"},
  {name: "Physics"},
  {name: "Topology"},
  {name: "Abstract Algebra"},
  {name: "Geometry"},
  {name: "Number Theory"},
  {name: "Physiology"},
  {name: "Astrophysics"}
])

Institution.create!([
  {name: "Journal of Organic Chemistry"},
  {name: "University of Cambridge"},
  {name: "University of California, San Diego"},
  {name: "International Journal of Molecular Sciences"},
  {name: "Cornell University"},
  {name: "Mathgen Institute"},
  {name: "Journal of Commutative Calculus"},
  {name: "Lawrence Berkeley National Laboratory"},
  {name: "University of California Berkeley"},
  {name: "Institute for Molecular Infection Biology"},
  {name: "Tufts University School of Medicine"},
  {name: "Harvard University"},
  {name: "Salk Institute for Biological Studies"},
  {name: "University of California Merced"},
  {name: "The University of Newcastle"},
  {name: "Bar-Ilan University"},
  {name: "Massachusetts Institute of Technology"},
  {name: " Murdoch University"},
  {name: "Arizona State University"},
  {name: "Northeast Normal University"},
  {name: "Heilongjiang University"},
  {name: "Beijing Institute of Technology"},
  {name: "Jagannath University"},
  {name: "Birla Institute of Technology and Science-Pilani"},
  {name: "Iran University of Science and Technology"},
  {name: "Islamic Azad University"},
  {name: "University of Nebraska-Lincoln"},
  {name: "Institute of High Performance Computing"}
])

Journal.create!([
  {name: "Nature"},
  {name: "Journal of Physiology"},
  {name: "Journal of Organic Chemistry"},
  {name: "Journal of Commutative Calculus"},
  {name: "Honduran Journal of Concrete Graph Theory"},
  {name: "Mathgen Institute"},
  {name: "The Astrophysical Journal"},
  {name: "General Relativity and Quantum Cosmology"},
  {name: "Current Biology"},
  {name: "Science"},
  {name: "Public Library of Science"},
  {name: "Chemical Science"},
  {name: "BMC Bioinformatics"},
  {name: "Inorganic Chemistry Communications"},
  {name: "Journal of Theoretical and Applied Physics"},
  {name: "New Journal of Physics"},
  {name: "Journal of Number Theory"},
  {name: "Journal of Topology"}
])

paper1 = Paper.create!({title: "Balanced inhibition underlies tuning and sharpens spike timing in auditory cortex.", body: "Neurons in the primary auditory cortex are tuned to the intensity and specific frequencies of sounds, but the synaptic mechanisms underlying this tuning remain uncertain. Inhibition seems to have a functional role in the formation of cortical receptive fields, because stimuli often suppress similar or neighbouring responses, and pharmacological blockade of inhibition broadens tuning curves. Here we use whole-cell recordings in vivo to disentangle the roles of excitatory and inhibitory activity in the tone-evoked responses of single neurons in the auditory cortex. The excitatory and inhibitory receptive fields cover almost exactly the same areas, in contrast to the predictions of classical lateral inhibition models. Thus, although inhibition is typically as strong as excitation, it is not necessary to establish tuning, even in the receptive field surround. However, inhibition and excitation occurred in a precise and stereotyped temporal sequence: an initial barrage of excitatory input was rapidly quenched by inhibition, truncating the spiking response within a few (1-4) milliseconds. Balanced inhibition might thus serve to increase the temporal precision and thereby reduce the randomness of cortical operation, rather than to increase noise as has been proposed previously.\r\n\r\nReceptive fields are shaped by the interaction of excitation and inhibition. In the auditory cortex, indirect measurements of this interaction by extracellular methods have suggested that it follows a classic organization—lateral inhibition—in which stimulation in the receptive field centre elicits excitation, and stimulation in the surround elicits inhibition. Here we have used in vivo whole-cell patch-clamp methods to test that model directly by measuring synaptic inputs evoked by pure tones in rat auditory cortical neurons (Fig. 1). For a subset of neurons (31/62), we improved the isolation of synaptic conductances by blocking action potentials with the fast sodium-channel blocker QX-314.\r\n\r\nTone-evoked synaptic conductance changes were large (Fig. 1c), comparable in magnitude to the largest conductance changes elicited by visual stimulation in area V1 neurons. The true conductances were almost certainly higher than the values presented here, because voltage escape at the subsynaptic membrane due to electrotonic effects (space-clamp errors) causes an underestimation of synaptic conductances (see Supplementary Information). We decomposed the conductances into their underlying excitatory and inhibitory components (see Supplementary Methods). The inhibitory conductance was typically as large as the excitatory conductance, which is consistent with the presence of shunting inhibition. Each component followed approximately the same time course as the overall conductance waveform, showing a shortlatency rise followed by a slower decay. Excitation evoked a transient spiking response (consisting of typically one or at most a few spikes; Fig. 1d) before being quenched by inhibition after a few milliseconds.\r\n\r\nThe total synaptic conductance was tuned for sound frequency (Fig. 2). The excitatory and inhibitory components were also tuned; moreover, they were co-tuned, showing approximately the same dependence on stimulus parameters in a given cell (Fig. 2a–d). Tuning of spiking responses was narrower than that of conductances or membrane potential (Fig. 3c), which is consistent with findings in auditory and other cortical regions. Co-tuning differs from classical lateral inhibition, because excitation was at least as broadly tuned as inhibition, and sometimes more so; some surround stimuli elicited a purely excitatory response, whereas pure inhibition was never observed (Fig. 3a). The co-tuning we observed is therefore different from the organization described in some simple cells in primary visual cortex, in which excitation and inhibition can each be elicited in isolation within discrete spatial subregions, but is reminiscent of other simple cells in which excitation and inhibition are evoked together from each subregion.\r\n\r\nBecause inhibition had the same tuning as excitation, the tuning of the excitatory component alone would, in the absence of timing, be sufficient to establish a neuron’s dependence on frequency. Although co-tuned inhibition sharpens tuning, this effect is equivalent to that of any untuned decrease in excitability, such as an increase in spike threshold. By means of this ‘iceberg effect,’ inhibition (shunting or otherwise) determines how much of the iceberg is suprathreshold but does not affect the shape of the iceberg itself (Fig. 3b); our results are therefore consistent with the finding that pharmacological blockade of inhibition broadens frequency tuning. In this regard, frequency tuning in auditory cortex is similar to orientation tuning in some simple cells in primary visual cortex, which is sharpened by inhibition but which arises mainly through the convergence of thalamocortical inputs. In contrast, orientation selectivity in other visual cortical neurons arises through a diversity of synaptic mechanisms and can be influenced by recurrent cortical circuitry.\r\n\r\nTwo-tone suppression, in which one tone modifies (usually suppresses) the response to a later tone, has been interpreted as evidence of lateral inhibition in auditory cortical neurons. Although our observations can explain how tuning is sharpened without lateral inhibition, they cannot by themselves account for two-tone suppression, which can last hundreds of milliseconds— longer than the inhibitory conductances we recorded (but see ref. 9). These suppressive effects might therefore be inherited from presynaptic neurons, or they might involve other mechanisms such as short-term synaptic plasticity.\r\n\r\nBecause inhibition did not seem to be essential to frequency tuning, we wondered whether it was involved in some form of gain control, perhaps resulting from the relatively loud (65 dB sound pressure level (SPL)) stimuli that we presented. We therefore tested a wide range of different stimulus intensities (5–65 dB SPL). However, we found that although total synaptic conductances were indeed tuned for sound intensity, the balance of excitation to inhibition remained fixed as intensity varied (Fig. 2b, d). Thus, co-tuning was a general feature of auditory cortical responses to simple tones across a wide range of frequencies and intensities.\r\n\r\nTuning for sound intensity (that is, a non-monotonic response to increasing intensity) has been proposed to result from lateral inhibition, which would predict that louder sounds should elicit stronger inhibition. Alternatively, intensity tuning might result from an increase in total input conductance, in which case louder sounds should elicit a larger total conductance change. However, neither prediction was satisified; we found non-monotonicity in both excitatory and inhibitory synaptic conductances (Fig. 2b, d) underlying the response for all non-monotonic neurons, indicating that non-monotonicity was inherited from synaptic inputs. These observations are consistent with the finding that non-monotonic cortical cells are not converted into monotonic cells by inhibitory blockade.\r\n\r\nBecause inhibition does not seem essential to either frequency or intensity tuning, what is its role? One key function of inhibition might be to sculpt the time course of tone-evoked responses. Excitation and inhibition appeared in a remarkably precise and stereotyped temporal sequence (Fig. 4): inhibition typically followed excitation after a brief delay (Fig. 4b). This sequence is consistent with that seen after electrical stimulation of the medial geniculate body. In most cells this delay was independent of both frequency and intensity (Fig. 4c, f, g), indicating that relative timing did not usually have a function in frequency or intensity tuning. The delay was stereotyped in the range of 1–4 ms (Fig. 4e; the mean delay was 2.4 ^ 3.6 ms, for n ? 50 stimulus conditions in 17 cells) even though the latency to the onset of excitation varied, suggesting that inhibition was locked to the excitation rather than to the stimulus itself. Because the period between the onset of excitation and inhibition was short, only a brief window was available for integrating excitatory synaptic inputs. Spikes were elicited only during this brief excitatory window (Figs 1d and 3c). Thus, inhibition acts to enforce the transient, often binary, nature of stimulus-evoked responses in auditory cortex.\r\n\r\nIn a minority of cells (2 of 31, or 6%) the delay between excitation and inhibition was tuned for tone frequency (Fig. 4d). In these neurons the maximal depolarization corresponded not to the largest conductance but rather to the longest delay (and the least inhibition). Thus, in a fraction of neurons, timing might have a function in tuning. However, because we did not record spiking responses for these neurons, it is unclear whether these longer delays give rise to sustained firing here or in neurons driven by frequency-modulated sweeps, in which such long and stimulus-dependent delays have also been reported.\r\n\r\nAlthough sensory stimuli elicit both excitation and inhibition in auditory and other sensory systems, the consistently short and stereotyped delay we observed between excitation and inhibition, and its relationship to transient spiking, have not previously been reported. In contrast, long and variable delays have been proposed to underlie sweep selectivity in auditory cortex. This difference between short, sterotyped delays and long, variable delays might be due to the differences in stimuli (tones as opposed to sweeps), suggesting that excitatory–inhibitory delays might have different functional roles in shaping the responses to different classes of sounds. Similarly, excitation and inhibition in some simple cells of the primary visual cortex seem to have discrete subregions in space, yet are co-tuned for orientation.\r\n\r\nA balance between excitation and inhibition has previously been proposed to account for the apparently random firing of cortical neurons by producing large random fluctuations in the membrane potential. In such models, however, it is only the average rate of excitatory and inhibitory postsynaptic potentials that is balanced; the individual events occur at random times, like raindrops. By contrast, the tight coordination we observed reflects a more precise control of cortical circuitry, unlikely to arise from random and independent synaptic activity arriving at a uniform rate. Moreover, the rapid quenching of excitation by inhibition limits the window available for temporal summation, enabling neurons to behave as coincidence detectors and thereby increasing temporal precision.\r\n\r\nWe illustrate this distinction by using a simple integrate-and-fire model (Fig. 5). Balanced but delayed inhibition decreased the trialto-trial jitter in output spike times compared with the jitter in the input spike times (from 1 ms to 0.6 ms; Fig. 5a), whereas excitation and inhibition that were balanced on average instead increased spike time jitter (from 1 ms to 4.7 ms; Fig. 5b). In both of these models, excitation and inhibition are balanced, but in a different sense: a continuing balance produces irregular firing (similar to responses observed in visual cortex, which motivate such models), whereas the transient and temporally offset balance we have observed produces highly transient spiking responses (Figs 1d and 3c), which is consistent with previous findings in auditory cortex. Thus our data suggest that balanced inhibition can sharpen neural responses in time, reducing rather than increasing the randomness of cortical operation.", user_id: 1, journal_id: 1, field_id: 1, institution_id: 1});

paper2 = Paper.create!({title: "Currents carried by sodium and potassium ions through the membrane of the giant axon of Loligo", body: "In the preceding paper (Hodgkin, Huxley & Katz, 1952) we gave a general description of the time course of the current which flows through the membrane of the squid giant axon when the potential difference across the membrane is suddenly changed from its resting value, and held at the new level by a feed-back circuit ('voltage clamp' procedure). This article is chiefly concerned with the identity of the ions which carry the various phases of the membrane current.\r\n\r\nOne of the most striking features of the records of membrane current obtained under these conditions was that when the membrane potential was lowered from its resting value by an amount between about 10 and 100 mV. the initial current (after completion of the quick pulse through the membrane capacity) was in the inward direction, that is to say, the reverse of the direction of the current which the same voltage change would have caused to flow in an ohmic resistance. The inward current was of the right order of magnitude, and occurred over the right range of membrane potentials, to be the current responsible for charging the membrane capacity during the rising phase of an action potential. This suggested that the phase of inward current in the voltage clamp records might be carried by sodium ions, since there is much evidence (reviewed by Hodgkin, 1951) that the rising phase of the action potential is caused by the entry of these ions, moving under the influence of concentration and potential differences. To investigate this possibility, we carried out voltage clamp runs with the axon surrounded by solutions with reduced sodium concentration. Choline was used as an inert cation since replacement of sodium with this ion makes the squid axon completely inexcitable, but does not reduce the resting potential (Hodgkin & Katz, 1949; Hodgkin, Huxley & Katz, 1949).\r\n\r\nMETHOD\r\nThe apparatus and experimental procedure are fully described in the preceding paper (Hodgkin et al. 1952). 'Uncompensated feed-back' was employed. Sea water was used as a normal solution. Sodium-deficient solutions were made by mixing sea water in varying proportions with isotonic 'choline sea water' of the following composition: Ion g. ions/kg. H20 Ion g. ions/kg. H.0 Choline+ 484 Mg++ 54 K+ 10 C1- 621 Ca++ 11 HCO0 3 The mixtures are referred to by their sodium content, expressed as a percentage of that in sea water (30% Na sea water, etc.).\r\n\r\nRESULTS\r\nVoUage claMPs in sodium-free solution Fig. 1 shows the main differences between voltage clamp records taken with the axon surrounded by sea water, and by a sodium-free solution. Each record gives the current which crossed the membrane when it was depolarized by 65 mV. After the top record was made, the sea water surrounding the axon was replaced by choline sea water, and the middle record was taken. The fluid was again changed to sea water, and the bottom record taken. The amplifier gain was the same in all three records, but a given deflexion represents a smaller current in the choline solution, since the current was detected by the potential drop along a channel filled with the fluid which surrounded the axon, and the specific resistance of the choline sea water was about 23 % higher than that of ordinary sea water.\r\nThe most important features shown in Fig. 1 are the following: (1) When the external sodium concentration was reduced to zero, the inward current disappeared and was replaced by an early hump in the outward current. i(2) The late outward current was only slightly altered, the steady level being 15-20 % less in the sodium-free solution. (3) The changes were reversed when sea water was replaced. The currents are slightly smaller in the bottom record than in the top one, but the change is not attributable to an action of the choline since a similar drop occurred when an axon was kept in sea water for an equal length of time.\r\nA series of similar records with different strengths of depolarization is shown in Fig. 2. The features described in connexion with Fig. 1 are seen at all strengths between -28 and -84 mV. At the weakest depolarization (-14 mV.) the early phase of outward current in the sodium-free record is too small to be detected. At the highest strengths the early current is outward even in sea water, and is then increased in the sodium-free solution.\r\nThese results are in qualitative agreement with the hypothesis that the inward current is carried by sodium ions which, as an early result of the decrease in membrane potential, are permitted to cross the membrane in both directions under a driving force which is the resultant of the effects of the concentration difference and the electrical potential difference across the membrane. When the axon is in sea water, the concentration of sodium outside the membrane [Na]0 is 5-10 times greater than that inside, [Na]j. This tends to make the inward flux exceed the outward. The electrical potential difference E also helps the inward and hinders the outward flux so long as it is positive, i.e. in the same direction as the resting potential. The net current carried by the positive charge of the sodium ions is therefore inward unless the depolarization is strong enough to bring E to a sufficiently large negative value to overcome the effect of the concentration difference. The critical value of E at which the fluxes are equal, and the net sodium current is therefore zero, will be called the 'sodium potential', ENa. Its value should be given by the Nernst equation.\r\nWith values of E more negative than this, the net sodium flux is outward, causing the early phase of the outward current seen in the lowest record of the first and third columns of Fig. 2, where the axon was in sea water and was depolarized by 112 mV. A family of voltage clamp records which shows particularly well this transition from an initial rise to an initial fall as the strength of depolarization is increased is reproduced as Fig. 14 of the preceding paper. When the axon is placed in a sodium-free medium, such as the 'choline sea water', there can be no inward flux of sodium, and the sodium current must always be outward. This will account for the early hump on the outward current which is seen at all but the lowest strength of depolarization in the centre column of Fig. 2.\r\n\r\nVoltage clamps with reduced sodium concentration\r\nThe results of reducing the sodium concentration to 30 and 10% of the value in sea water are shown in Figs. 3 and 4 respectively. These figures do not show actual records of current through the membrane. The curves, are graphs of ionic current against time, obtained by subtracting the current through the capacity from the recorded total current. The initial surge in an anodal record was assumed to consist only of capacity current, and the capacity current at other strengths was estimated by scaling this in proportion to the amplitude of the applied voltage change.\r\nAs would be expected, the results are intermediate between those shown in Fig. 2 for an axon in sea water and in choline sea water. Inward current is present, but only over a range of membrane potentials which decreases with the sodium concentration, and within that range, the strength of the current is reduced. A definite sodium potential still exists beyond which the early hump of ionic current is outward, but the strength of depolarization required to reach it decreases with the sodium concentration. Thus, in the first column of Fig. 3, with the axon in 30 % sodium sea water, the sodium potential is almost exactly reached by a depolarization of 79 mV. In the second column, with sea water surrounding the axon, the sodium potential is just exceeded by a depolarization of 108 mV. In column 3, after re-introducing 30 % sodium sea water, the sodium potential is slightly exceeded by a depolarization of 79 mV. Similarly, in Fig. 4, the sodium potentials are almost exactly reached by depolarizations of 105, 49 and 98 mV. in the three columns, the axon being in sea water, 10 % sodium sea water and sea water respectively. The sequence of changes in the form of the curves as the sodium potential is passed is remarkably similar in all cases.\r\n\r\nThe external sodium concentration and the 'sodium potential'\r\nEstimation of the 'sodium potential' in solutions with different sodium concentrations is of particular importance because it leads to a quantitative test of our hypothesis. Equation (1) gives the sodium potential in sea water (ENa), and the corresponding quantity (ENa) when the external sodium concentration is reduced to [Na]' is given by E'Na = RT/Floge[Na]i/[Na]o’. Each term in this equation can be determined experimentally, and data were obtained in four experiments on two axons. The results are given in Table 1, where the observed shift in sodium potential is compared with that predicted from the change in sodium concentration by Equation (3). It will be TABLE 1. Comparison of observed and theoretical change in sodium potential when the fluid surrounding an axon is changed from sea water to a low sodium solution. Observed change: EN.=(VN - VN) + (E, - E,); theoretical change = log [Na]. Sodium potential shift Axon Temp. [Na]--- VNN (Er - Er) Observed Theoretical no. (O C.) [Na]0 (mV.) (mV.) (mV.) (mV.) (mV.) 20 6-3 03 -105 -78 +3 +30 +28-9 20 6*3 0.1 -96 -45 +4 +55 +55-3 21 8-5 01 -100 -48 +4 +56 +55-6 21 8*5 0.1 -95 -45 +4 +54 +55-6 seen that there is good agreement, providing strong evidence that the early rise or fall in the recorded ionic current is carried by sodium ions, moving under the influence of their concentration difference and of the electric potential difference across the membrane. Details of the estimation of the quantities which enter into Equation (3) are given in the following paragraphs.\r\n\r\nNa AND K CURRENTS IN NERVE MEMBRANE\r\nChange in resting potential: Experiments with ordinary capillary internal electrodes showed that the resting potential increased on the average by 4 mV. when the sea water surrounding the axon was replaced by choline sea water (a correction of 1-5 mV. for junction potentials in the extemal solutions js included in this figure). With intermediate sodium concentrations, the change in resting potential was assumed to be proportional to the change in sodium concentration. For instance, the resting potential in 30 % sodium sea water was taken as 2-8 mV. higher than that in sea water. slow change in condition of axon. When an axon is kept in sea water, its sodium content rises (Steinbach & Spiegelman, 1943; Keynes & Lewis, 1951) and its resting potential falls. Both of these effects bring E, and ENa closer together, Timinishing the absolute magnitude of VN. In comparing Vw. in two solutions, it was therefore necessary to determine VN. first in one solution, then in the other and finally in the first solution again. The second value of VN. was then compared with the mean of the first and third.\r\n\r\nThe internal sodium concentration and the sodium potential\r\nIn freshly mounted fibres the average difference between the sodium potential and the resting potential was found to be - 109 mV. (ten axons with a range of -95 to -119 mV. at an average temperature of 8° C.). The average resting potential in these fibres was 56 mV. when measured with a microelectrode containing sea water. By the time the sodium potential was measured the resting potential had probably declined by a few millivolts and may be taken as 50 mV. Allowing 10-15 mV. for the junction potential between sea water and axoplasm (Curtis & Cole, 1942; Hodgkin & Katz, 1949) this gives an absolute resting potential of 60-65 mV. The absolute value of the sodium potential would then be -45 to -50 mV. The sodium concentration in sea water is about 460 m.mol./kg. H20 (Webb, 1939, 1940) so that the internal concentration of sodium would have to be 60-70 m.mol./kg. H20 in order to satisfy Equation 1. This seems to be a very reasonable estimate since the sodium concentration in freshly dissected axons is about 50 m.mol./kg. H20 while that in axons kept for 2 or 3 hr. is about 100 m.mol./kg. H120 (Steinbach &Spiegelman, 1943; Keynes & Lewis, 1951; Manery, 1939, for fraction of water in axoplasm).\r\n\r\nOutward currents at long times\r\nSo far, this paper has been concerned with the earliest phases of the membrane current that flows during a voltage clamp. The only current which has the opposite sign from the applied voltage pulse is the inward current which occurs over a certain range of depolarizations when the surrounding medium contains sodium ions. This inward current is always transient, passing over into outward current after a time which depends on the strength of depolarization and on the temperature. The current at long times resembles that in an ohmic resistance in having the same sign as the applied voltage change, but differs in that the outward current due to depolarization rises with a delay to a density which may be 50-100 times greater than that associated with a similar increase in membrane potential. Figs. 1-3 show that this late current is not greatly affected by the concentration of sodium in the fluid surrounding the axon.\r\nAn outward current which arises with a delay after a fall in the membrane potential is clearly what is required in order to explain the falling phase of the action potential. The outward currents reached in a voltage clamp may con- (siderably exceed the maximum which occurs in an action potential; this may well be because the duration of an action potential is not sufficient to allow the outward current to reach its maximum value. These facts suggest that the outward current associated with prolonged depolarization is the same current which causes the falling phase of the action potential. The evidence (reviewed by Hodgkin, 1951) that the latter is caused by potassium ions leaving the axon is therefore a suggestion that the former is also carried by potassium ions. Direct evidence that such long-continued and outwardly directed membrane currents are carried by potassium ions has now been obtained in Sepia axons by a tracer technique (unpublished experiments). We shall therefore assume that this delayed outward current is carried by potassium ions, and we shall refer to it as 'potassium current', IK. Since it is outward, it is not appreciably affected by the external potassium concentration, and evidence for or against potassium being the carrier cannot easily be obtained by means of experiments analogous to those which have just been described with altered external sodium concentration.\r\nIE in sea water and choline. As has been mentioned, the later part of the current record during a constant depolarization is much the same whether the axon is surrounded by sea water or by one of the solutions with reduced sodium concentration. There are, however, certain differences. For a given strength of depolarization, the maximum outward current is smaller by some 10 or 20% in the low-sodium solution, and at the higher strengths where the outward current is not fully maintained, the maximum occurs earlier in the low-sodium solution. Part of the difference in amplitude is explained by the difference of resting potential. Since the resting potential is greater in the low-sodium medium, a higher strength of depolarization is needed to reach a given membrane potential during the voltage clamp. This difference can be allowed for by interpolation between the actual strengths employed in one of the solutions. In most cases, this procedure did not entirely remove the difference between the amplitudes. There are, however, two other effects which are likely to contribute. In the first place, the effect of not using 'compensated feed-back' is probably greater in the low-sodium solution (see preceding paper, p. 445). This further reduces the amplitude of the voltage change which actually occurs across the membrane. In the second place, the fact that the current reached its maximum earlier suggests that '-polarization' (preceding paper, p. 445) had a greater effect in the low-sodium solution. We do not know enough about either of these effects to estimate the amount by which they may have reduced the potassium current. It does seem at least possible that they account for the whole of the discrepancy, and we therefore assume provisionally that substituting choline sea water for sea water has no direct effect on the potassium current.\r\n\r\nSUMMARY\r\n1. The effect of sodium ions on the current through the membrane of the giant axon of Loltigo was investigated by the 'voltage-clamp ' method.\r\n2. The initial phase of inward current, normally associated with depolarizations of 10-100 mV., was reversed in sign by replacing the sodium in the external medium with choline.\r\n3. Provided that sodium ions were present in the external medium it was possible to find a critical potential above which the initial phase of ionic current was inward and below which it was outward. This potential was normally reached by a depolarization of 110 mV., and varied with external sodium concentration in the same way as the potential of a sodium electrode.\r\n4. These results support the view that depolarization leads to a rapid increase in permeability which allows sodium ions to move in either direction through the membrane. These movements carry the initial phase of ionic current, which may be inward or outward, according to the difference between the sodium concentration and the electrical potential of the inside and outside of the fibre.\r\n5. The delayed outward current associated with prolonged depolarization was little affected by replacing .sodium ions with choline ions. Reasons are given for supposing that this component of the current is largely carried by potassium ions.\r\n6. By making certain simple assumptions it is possible to resolve the total *ionic current into sodium and potassium currents. The time course of the -sodium or potassium permeability when the axon is held in the depolarized condition is found by using conductance as a measure of permeability.\r\n7. It is shown that the sodium conductance rises rapidly to a maximum and then declines along an approximately exponential curve. The potassium conductance rises more slowly along an S-shaped curve and is maintained at a high level for long periods of time. The maximum sodium and potassium conductances were normally of the order of 30 m.mho/cm.2 at a depolarization of 100 mV.\r\n8. The relation between sodium concentration and sodium current agrees with a theoretical equation based on the assumption that ions cross the membrane independently of one another.", user_id: 1, journal_id: 2, field_id: 1, institution_id: 2});

paper3 = Paper.create!({title: "A Neural Circuit for Spatial Summation in Visual Cortex", body: "Visual stimuli located outside of the classical receptive field of a neuron in visual cortex while unable to elicit spiking may modulate the neuron’s response to stimuli located in its receptive field. Surround suppression, a basic operation in visual processing, is a classical example of this type of modulation and can be easily observed when monitoring the firing of a neuron to a stimulus of increasing size centered on its receptive field (i.e. the size tuning of the neuron): The neuron’s initial increase in firing is followed by a decrease as the stimulus becomes progressively larger. This form of suppression has been suggested to contribute to a number of perceptual effects like pop-out, curvature detection and orientation discrimination. Importantly surround suppression is not only observed in the cortex but is already present at earlier stages along the visual hierarchy namely in the retina and the thalamus. Thus while it is likely that at least part of suppressive surround observed in the cortex is relayed from earlier stages of visual processing, some experimental observations and theoretical models suggest that the cortex is itself capable of contributing to surround suppression. Below we reveal the identity and describe the mechanism of a cortical circuit that directly contributes to surround suppression in the superficial layers of primary visual cortex.\r\nDifferent size tuning of distinct neurons\r\nWe determined the tuning to the size of a visual stimulus for neurons in the superficial layers of the primary visual cortex (V1; depth ~100–350 µm, corresponding approximately to layer 2/3) of mice. Experiments were performed in awake, running animals, as size tuning was affected by anesthesia (Suppl. Fig. 1). Mice were head fixed but otherwise unrestrained and free to run on a passive circular treadmill. For behavioral consistency all data presented here were recorded during running events (see methods).Visual stimuli were composed of circular patches of drifting gratings at maximal contrast presented at 6–7 different sizes (from 8 – 96 degrees in diameter, Fig. 1a). The size-tuning curve of isolated units (n=53; Suppl. Fig 2), i.e. the neuronal firing rate as a function of stimulus size, peaked at 22±2 degrees (preferred size) and progressively decreased with larger stimuli (Fig. 1a,d), revealing marked surround suppression (average firing rates (FR): at baseline (FRBL): 0.47±0.11 Hz; to smallest stimulus (FRSS): 3.0 ±1.0 Hz, to preferred stimulus (FRPS): 3.1± 0.3 Hz; to largest stimulus (FRLS): 1.0±0.2 Hz; stimulus modulation index (SMI, computed as (FRPS - FRBL) / FRPS): 0.87±0.03). The suppression index (SI), i.e. the difference between the peak response and the response to the largest stimulus, divided by the baseline subtracted peak response ((FRPS - FRLS)/(FRPS - FRBL); Fig. 1a) averaged 0.9±0.1 (n=53; SI statistically significant in 33/53 units; permutation test; Fig. 1d), indicating substantial suppression to large stimuli. Infrequent eye- movement occurring during running had little effect on the size tuning curve (Suppl. Fig. 3).\r\n\r\nIf cortical circuits contribute to surround suppression they may involve the suppressive action of cortical inhibitory neurons. An inhibitory neuron lacking surround suppression and whose response increases with stimulus size would be a good candidate. In cats visual cortex, for example, fast spiking inhibitory neurons responding with higher firing rates to large as compared to small visual stimuli. We performed targeted loose patch recordings from inhibitory neurons in layer 2/3 of V1 in awake, running mice, using two photon laser scanning microscopy (Fig.1b,c). Parvalbumin expressing neurons (PVs), a large class of cortical inhibitory neurons, were visualized in layer 2/3 by crossing a PV-Cre mouse line with a tdTomato reporter line. The size tuning curve of PVs peaked at 57±8 degrees (n=11) and showed marked surround suppression with larger stimuli (SI: 0.46±0.12 ; n=11; SI statistically significant in 6/11 cells; permutation test; Fig 1b,e; FRBL: 9±2 Hz; FRSS: 27±7 Hz; FRPS: 45±11 Hz; FRLS: 26±8 Hz; SMI,: 0.74 ± 0.07; recorded PVs showed their characteristic “thin” spikes shapes (Suppl. Fig. 2), confirming the accuracy of our targeting strategy). In striking contrast to PVs, somatostatin expressing neurons (SOMs), another large class of cortical inhibitory neurons (visualized by crossing a SOM-Cre line with a tdTomato-reporter line 27), completely lacked surround suppression (SI: 0.09±0.06 ; n = 8; SI stat. sign. in 0/8 cells ; permutation test; significantly different from PVs; p<0.03, rank sum test; Fig. 1f). The size tuning curve of these neurons showed a monotonic increase or saturation in firing rate with stimulus size (Fig 1c,f). While the smallest stimuli were relatively inefficient in driving SOMs (FRBL: 7±2 Hz; FRSS: 5±2 Hz), they robustly responded to large stimuli (FRPS: 26±2 Hz; preferred size: 86±3 degrees; different from PV, p<0.015, rank sum test; SMI: 0.75±0.05). These data demonstrate that in V1 size tuning can be very different between genetically distinct types of neurons. Furthermore, these data suggest that SOMs are potential candidates in the generation of cortical surround suppression.\r\nExcitation of SOMs by horizontal axons\r\nThe above observations open two fundamental questions: First, what are the cortical circuits that enable SOMs, in contrast to other cortical neurons, not to be suppressed but rather facilitated by large stimuli? Second, do SOMs contribute to size tuning in V1? Both questions are addressed below.\r\nThe two predominant excitatory inputs to layer 2/3 are vertically ascending axons from layer 4 and horizontal projecting axons from layer 2/3. Are SOMs equally excited by these two inputs? We recorded from layer 2/3 pyramidal cells (PCs), SOMs and PVs in coronal slices of V1 and selectively photo-activated (light ramp of 2s duration; 480 nm light) layer 4 excitatory cells that conditionally expressed Channelrhodopsin-2 (ChR2; Suppl. Fig 4). Layer 4 photo-stimulation generated excitatory charges in SOMs that were only 17 ± 5% (n=8) of those in simultaneously recorded PCs (Fig. 2a); in contrast, excitatory charges generated in PVs were 250 ± 39% (n=8) of those generated in simultaneously recorded PCs (Fig. 2b). These results were corroborated through ChR2-assisted circuit mapping 29 (Suppl. Fig. 5). Thus, ascending layer 4 axon provide little excitation to SOMs. In striking contrast, photo-stimulation of layer 2/3 PCs (2 s light ramp duration) that selectively expressed ChR2 (see methods 30) produced substantial excitation of layer 2/3 SOMs (Fig 2d): the excitation that SOMs received was in fact significantly larger than that received by simultaneously recorded PCs (241 ± 85%; n=7; p<0.05; Fig. 2e; we selectively recorded from those PCs not expressing ChR2 in order to avoid contamination with photocurrents). Furthermore, while photo-stimulation of horizontal layer 2/3 projections was accompanied by strong disynaptic inhibition in PCs, only very little inhibition was recorded in SOMs (Fig. 2e; the ratio of excitation to the sum of excitation and inhibition (E/(E+I)) was 0.11 ± 0.01 (n=10) in PCs versus 0.59 ± 0.06 (n= 11) in SOMs; p<0.05, Fig. 2f). Thus, these results show that while layer 2/3 pyramidal and PVs receive substantial excitatory drive from ascending layer 4 axons, the main excitation to layer 2/3 SOMs are horizontal axons of layer 2/3.\r\n\r\n\r\nSize-dependent excitation of SOMs\r\nTo ascertain that these horizontal axons are indeed responsible for the size-dependent recruitment of SOMs, we took advantage of the retinotopic organization of V1; we reasoned that because progressively larger visual stimuli presented in vivo will result in a progressively larger visually activated area in V1 we could approximate this expansion of activity by directly photo-stimulating progressively larger areas of V1. We performed loose patch recordings from SOMs in coronal slices of V1 expressing ChR2 in layer 2/3 PCs (Fig 3a). The firing rate of SOMs increased as a function of the size of the light spot (range of sizes 180–900 µm), similar to their increase in firing rate in vivo with increasing visual stimulus size (Fig. 3a,b). Consistent with the increase in firing rate, the synaptic excitation received by SOMs increased with increasing light spot size (Fig. 3a,b). If SOM dendrites were to span areas similar to the largest light-spot diameter, the progressive increase in firing rate with spot size could simply result from the direct photo-stimulation of synapses on the dendritic arborization of the recorded SOM. This was however not the case because even the smallest light spot used (180 µm diameter), generating only ~25% of the maximal firing rate, covered already more than 95% of the entire SOM dendritic arborization (Fig. 3b, see methods). Thus, the increase in SOM firing rate with spot size results from the recruitment of progressively more distant L2/3 PCs (Fig. 3b, see methods). Furthermore, cutting horizontal axons with two vertical cuts through layer 2/3 on each side of the recorded SOMs (320 ±25 µm between cuts, centered on the cell; n=10; note that the distance between the cuts is larger than the horizontal dendritic extent of SOMs ) prevented the increase in firing rate with stimuli larger than the distance between the two cuts (Suppl. Fig. 6). Thus, by using horizontal layer 2/3 projections as their main excitatory drive, SOMs are recruited as a function of the activated V1 area, that is they sum activity in visual space.\r\nIs the size-dependent recruitment of SOMs a mechanism that could contribute to the suppression of PC firing to large stimuli? We recorded from PCs in coronal slices of V1 conditionally expressing ChR2 in layer 2/3. The firing rate of PCs was set to ~10 Hz by direct current injection (Fig. 3c). A small light spot centered around the recorded PC reduced the firing rate and this suppression became progressively more pronounced as a larger area of layer 2/3 was activated by increasing the size of the light spot (Fig. 3c). Consistent with the progressive suppression in firing rate, the inhibition received by PCs increased with increasing light spot size (Fig. 3c,d). Finally, to establish that the inhibition generated in PCs upon photo activation of layer 2/3 was indeed due to the recruitment of SOMs and not any other interneuron type we optogenetically silenced SOMs (see methods) while monitoring the inhibition in PCs during photoactivation of layer 2/3 (Fig. 3e). Photo-stimulation of layer 2/3 to activate PCs generated strong firing in SOMs and large inhibitory currents in simultaneously recorded PCs, consistent with the results reported above (Fig. 3e). Strikingly, concomitant optogenetic silencing of SOMs (100% reduction of firing; n= 6) strongly reduced the inhibitory currents in PCs (80 ± 4% reduction; n=8 p<0.05, Fig. 3e,f).\r\nThus, the stimulus-size dependent recruitment of SOMs generates strong inhibition in layer 2/3 PCs and efficiently suppresses their firing rate (Fig. 3g).\r\n\r\nSOMs contribute to surround suppression\r\nThese data provide a plausible mechanism by which SOMs could contribute to surround suppression of layer 2/3 PCs in vivo. Furthermore, consistent with a possible contribution of SOMs to surround suppression, under anesthesia, a situation in which surround suppression is compromised (see above and Suppl. Fig. 1) the firing rate of SOMs was reduced ten fold (from 26 ± 2 Hz, n=8 to 2.7± 0.4 Hz, n= 10), much more than that of single units or PVs (Suppl. Fig. 1). To directly test for the involvement of SOMs in surround suppression we conditionally expressed the light-sensitive hyperpolarizing opsin archaerhodopsin (Arch) in V1 using viral injection of a flexed Arch vector into SOM-Cre mice (71 ± 2% of cells infected, n = 4 animals, Fig. 4b and see methods). Illumination of the cortical surface efficiently reduced the visually evoked activity of Arch-expressing layer 2/3 SOMs (80 ± 1% suppression, n = 4, p<0.05; Supp. Fig. 7),. To determine the impact of SOMs on size tuning in layer 2/3 we performed extracellular recordings as described above and alternated control trials (visual stimulus only) with trials in which SOMs were photo-hyperpolarized (Fig. 4). Photo-hyperpolarization of SOMs significantly reduced surround suppression of layer 2/3 neurons by 30 ± 10% (n=28; p < 0.00022, paired signed rank test; Fig.4c-e; photo-hyperpolarization of SOMs had no significant effect on baseline firing rates ?9±17%; n=13; p>0.18). Nearly all units (25/28) showed a decrease in SI (Fig. 4e) and in 10/25 units the decrease was individually significant (p< 0.05 permutation test). The reduction of SI resulted from the fact that SOM photo-hyperpolarization facilitated the response to large visual stimuli more than to small visual stimuli: The response ratio (the ratio of the firing rate in the illumination condition divided by firing rate in the control condition) increased with the size of the stimulus (Fig. 4f). Indeed, while the response to stimuli smaller or equal to the preferred size was not facilitated (?7± 7%, p > 0.45, paired signed rank test; n=28; FRPS, CTRL = 4.9 ± 1.5 Hz, FRPS, LED = 4.6 ±1.9 Hz, p >0.63, paired signed rank test) the response to the stimuli larger than the preferred size was facilitated by 74±19 % (p<0.0011, paired signed rank test; n=28; Fig. 4f). This lack of facilitation of responses to smaller visual stimuli was not due to saturation (i.e. a ceiling effect). In fact, firing rates to stimuli smaller or equal to the preferred one were consistently facilitated less than similar firing rates elicited by stimuli larger than the preferred one (Supp. Fig. 8). The stronger impact of SOM photo-hyperpolarization on cortical responses to large stimuli is thus consistent with the preferential activation of SOMs by large stimuli (Fig. 1c). Thus, by inhibiting layer 2/3 neurons as a function of stimulus size SOMs generate an inhibitory surround (Fig. 4g).\r\nDiscussion\r\nThis study describes a cortical circuit that significantly contributes to surround suppression of layer 2/3 cells and identify a specific type of inhibitory neuron, the SOM, as a key mediator of this phenomenon. This circuit is thus likely to be involved in the contextual modulation of cortical responses to visual stimuli. The differential recruitment of PCs in superficial layers by ascending inputs and of SOMs by horizontal inputs underscores the fact that distinct neuron types are differentially integrated in the excitatory cortical circuit. These differences lead to different tuning properties as highlighted here by the distinct size-tuning curves. Thus, while small stimuli efficiently drive layer 2/3 PCs through the activation of ascending vertical inputs, SOMs, by summing activity in space via horizontal inputs, are preferentially driven by larger stimuli. As a consequence, the larger the stimulus, the stronger the SOM mediated suppression of PCs.\r\nHow can SOMs increase their firing as a function of stimulus size if they suppress layer 2/3 PCs, i.e. their main source of excitation? It is likely that the number of PCs recruited by the outer edge of the stimulus (an annulus that grows linearly with the diameter of the stimulus) more than compensate for the reduction in PC firing at the center of the stimulus.\r\nPhoto-hyperpolarization of SOMs reduces but does not abolish surround suppression. While this may be due in part to incomplete silencing of SOMs, surround suppression is also likely relayed to cortical layer 2/3 by earlier stages of visual processing and other types of inhibitory neurons or circuits may also contribute to surround suppression.\r\nThe preferential recruitment of SOMs by horizontal excitatory projections is consistent with the long hypothesized role of these projections in size tuning. In cortical layers with less extensive horizontal connectivity, size tuning may rely on different mechanisms or be entirely inherited from pre-cortical areas. Importantly, because SOMs are tuned to the orientation of visual stimuli, they could account for the orientation dependence of surround suppression. Furthermore, SOMs may respond differentially to specific stimulus properties, like contrast, and thus also contribute to the contrast dependence of surround suppression. It is likely that a connectivity pattern similar to what is described here may be present in other cortical areas as well, and thus contribute to suppressive surround in several sensory and non-sensory modalities.\r\nMethods Summary\r\nExperiments were performed in accordance to the regulations of the IACUC at UCSD. Mice (except for Fig. 3a,b) were heterozygous for SOM-IRES-CRE (Jackson lab stock #013044) or PV-CRE (#008069) and the reporter allele Rosa-LSL-tdTOMATO (Allen Institute line Ai9, Jackson Labs #007905). For Fig. 3a,b mice were positive for Scnn1a-tg3-CRE (Jackson labs #009613) and crossed with to the Gin (#003718) or B13 line. For in vivo experiments mice were implanted with a custom head plate and habituated to head-fixation while running on a free spinning circular treadmill. For targeted recording in vivo tdTomato-expressing neurons were visualized by two photon microscopy and contacted by a glass electrode containing Alexfluor 488. Extracellular unit recording was performed via 16 channel silicon probes (Neuronexus). Single units were isolated using custom spike sorting software (Kleinfeld lab). We conditionally expressed ChR2 by in utero electroporation (for layer 2/3) or via a CRE-depednent AAV in Scnn1a-tg3-CRE (for layer 4). Arch or eNpHR were expressed via CRE-dependent AAVs in SOM- and PV-IRES-CRE mice. Visual stimuli were generated by custom software (Psych Toolbox) and presented on a gamma-corrected LCD monitor 15 cm from the mouse. Photostimulation in vivo was performed via fiber-coupled LEDs (Doric lenses). Photostimulation in vitro was via a combination of fiber-coupled LEDs, or LEDs mounted and coupled to an epifluorescence microscope (Olympus BX51). eNpHR was activated by a shuttered arc-lamp. Slice preparation and intracellular recording followed previous protocols. Data acquisition, visual stimulation, and statistical analysis was performed in the Igor Pro and Matlab environments.", user_id: 2, journal_id: 1, field_id: 1, institution_id: 3});

paper4 = Paper.create!({title: "Genetic Breeding and Diversity of the Genus Passiflora", body: "1. Introduction\r\n1.1. General Characteristics of the Genus Passiflora, Family Passifloraceae\r\nThe family Passifloraceae Juss. ex DC. belongs to the order Violales, class Magnoliopsida, and phylum Magnoliophyta. Although records of plants that belong to this family have been in existence since 1553, there have been disagreements regarding the number of genera and species in the family since the first literary record of a plant in this group was written in Colombia [1]. Over the past few centuries, several scientific studies have been published describing the species and the organization of the species into genera and subgenera. Estimates of the number of species in the Passifloraceae family vary between 700 [2] and 520 [3,4,5]. Such variations are the result of taxonomical uncertainties, the use of synonyms, and descriptions of new species. There is also no consistency in the number of genera, which varies between 18 [2,3] and 23 [6].\r\nDespite taxonomical uncertainties, Passiflora is highly diverse, with approximately 520 species [5]. Approximately 96% of the species are distributed in the Americas, although there are records of species in India, China, Southeastern Asia, Australia, the Pacific islands, and neighboring regions (examples of species include Passiflora aurantia, Passiflora cinnabarina, Passiflora herbertiana, Passiflora cupiformis,Passiflora henryi, Passiflora jugorum, Passiflora moluccana, and Passiflora siamica). Brazil and Colombia, in particular, are centers of diversity; approximately 30% of Passiflora species are found in these countries (approximately 150 in Brazil and 170 in Colombia), including 89 that are endemic to Brazil [7,8,9,10].\r\nBased on the progress in taxonomic and phylogenetic studies using molecular markers and sequencing techniques, particularly over the last 10 years, the taxonomic classification of Passiflora species has been organized into four subgenera: Astrophaea, Decaloba, Deidamiodes, and Passiflora [11,12]. Although this infrageneric organization into only four subgenera diverges from the hypothesized 22 or 23 subgenera [13,14], research based on phylogenetic approaches, morphometric data, genotypic data of microsatellite markers [15] and DNA fragments from seven regions of the passion fruit genome (the rbcL and rps4 genes, the trnL intron and trnL F intergenic spacers from the plastid genome, the nad1 b/c and nad5 d/e introns from the mitochondrial genome, and a portion of the 26S gene from the nuclear ribosomal genome) [16] supports this simpler division of the genus. Together, the information available for passion fruit supports the infrageneric classification of Passiflora based on studies of molecular phylogeny that are corroborated by morphological and ecological characteristics [16,17,18].\r\nMolecular studies of passion fruit based on the combined and individual analysis of DNA sequences from the nuclear, plastid, and mitochondrial genomes also contribute directly to (i) estimates of the origin of the genus Passiflora and the diversification of its subgenera obtained through the analysis of molecular dating [16]; (ii) the identification and understanding of different organellar inheritance patterns [20]; and (iii) the demonstration of the potential use of fragments from the internal transcribed spacer (ITS) regions of nuclear ribosomal sequences and variations in the plastidial sequences to study inter  and intraspecific variability in Passiflora species [21,22]. Furthermore, the contributions to molecular phylogeny may be observed in in depth studies [16,17,18].\r\nWith the expansion of the genomic information (sequences) available in public databases as well as the availability of genetic material in collections, germplasm banks, and herbaria, the use of short orthologous DNA sequences (DNA barcodes) to identify species can contribute considerably to the characterization and utilization of biological diversity [23,24]. In particular, for groups such as the genus Passiflora, for which taxonomic uncertainties exist and new species are continuously being discovered (approximately five species per year) [25], the definition and use of DNA barcodes can contribute directly to germplasm characterization and the evaluation of diversity in natural populations.\r\nThe inherent variability of Passiflora is not restricted to its morphological characteristics [26,27] and the physical and chemical compositions of the fruit and flowers [28,29,30,31] but includes traits important for its survival in natural environments and/or cultivation conditions, such as the resistance of wild species to biotic (fungi, bacteria, nematodes, and viruses) and abiotic stresses (variations in the edaphoclimatic characteristics of macro  and microregions in which Passiflora species naturally occur or are cultivated) [32,33,34]. Such variability may be useful for breeding programs with different end results.\r\nResults from cytogenetic research on the genus Passiflora are scarce and restricted to less than 20% of the species [35]. Although such studies are increasing [36,37], this area of knowledge remains open to basic investigation. Despite this scarcity of cytogenetic information, research has contributed to our understanding of the group’s evolutionary relationships and has facilitated direct interspecies crosses and thus the genetic breeding of passion fruit. Certain species, particularly those of economic interest (due to fruit production and ornamentation, such as Passiflora edulis Sims, Passiflora alata Curtis, Passiflora coccinea Aubl, and Passiflora incarnate L.), are described by cytogenetic information available at different levels, including data from molecular cytogenetic techniques, such as fluorescent in situ hybridization (FISH) and genomic in situ hybridization (GISH) [38,39,40,41]. Details outlining the use of cytogenetic techniques in Passiflora are available [36,37]. Molecular data were also recently made available from the construction and initial characterization of a genomic library of P. edulis using the bacterial artificial chromosome (BAC) technique [42,43], which should contribute to the characterization of the germplasm, construction of chromosome maps of P. edulis and neighboring species, and identification of interspecies hybrids.\r\nIn relation to estimates related to the genome size of passion fruit species, as is discussed in the review presented by Souza et al. [37], the studies are very limited, and for most species, the information was derived from works carried out in the last 10 years with use of flow cytometry. This methodology may contribute to the estimation of DNA content as an aid in the analysis of ploidy, the identification of hybrids and the establishment of correlations between the genome sizes and biological and agronomic characteristics [37,44]. The few studies investigating the genome sizes of passion fruit have indicated significant interspecific variation, such as the results reported by Souza et al. [37] for eight species (with 2C nuclear DNA content ranging from 1.83 pg in Passiflora suberosa to 5.36 pg in Passiflora quadrangularis) and the more recent results from Yotoko et al. [44] for 50 species (indicating variation of 2C content from 0.42 pg in P. organogenesis to 4.41 pg in P. alata).\r\nThe available cytogenetic information on passion fruit species describes four different chromosome numbers distributed among the four subgenera of Passiflora: x = 6 in Decaloba, x = 9 and x = 10 or 11 inPassiflora, x = 10 in Astrophaea, and x = 12 in Deidamiodes [5,39]. This distribution is largely in accordance with the infrageneric classification supported by molecular phylogeny for the genus Passiflora. Although there is no precise estimation of the basic number of chromosomes across the genus, studies have suggested 6 or 12 as the precise number [35,38]. In the case of polyploidy, most Passiflora species are diploid, with 2n = 12, 18, or 20 chromosomes. Tetra , hexa , or octoploid species are rare [36,39]. The most commercially important species is diploid (2n = 18), which favors genetic breeding to obtain interspecies hybrids [36,43,44].\r\n1.2. Economic Importance of Passion Fruit Species\r\nSeveral segments of society display a great interest in passion fruit plants as ornamental and medicinal plants, as a source of oils for the cosmetic industry, and for their fruits and fruit derivatives. The use of passion fruit as an ornamental plant is justified because of the diversity and beauty of its leaves, flowers, and fruit, and more than 400 ornamental hybrids exist worldwide [45] (Figure 2). However, the use of passion fruit as an ornamental plant has only recently begun in Brazil, as the first hybrids for ornamental use were developed and launched in the last decade: the “Brasil (BRS) Estrela do Serrado” (N.Ref. RNC MAPA 21717) was obtained from a cross between P. coccinea and Passiflora setacea, “BRS Rubiflora” (N.Ref. RNC MAPA 21718) was obtained from a cross between the F1 hybrid (P. coccinea and P. setacea) with P. coccinea, and “BRS Roseflora” (N.Ref. RNC MAPA 21715) was obtained from the cross between the F1 hybrid (P. coccinea and P. setacea) with P. setacea. These ornamental hybrids were developed at Embrapa Cerrados, Planaltina, Brazil (images and details are available at [46]). Ornamental hybrids have also been produced in Brazil’s northeast region, including “Passiflora alva”, “Passiflorapriscilla” and “Passiflora aninha” all of which were obtained from a cross between Passiflora palmeri andPassiflora foetida. These ornamental hybrids were developed at the Universidade Estadual de Santa Cruz, Ilhéus, Bahia, Brazil [47] (images and details are available at [48]).\r\nThe identification of species with morphological and adaptive characteristics for ornamental use has increased in Brazil, particularly in research centers, such as the Universidade Estadual de Santa Cruz, Ilhéus, BA, Brazil; Embrapa Cerrados, Embrapa Mandioca e Fruticultura, Cruz das Almas, BA, Brazil; and the Instituto Agronômico, Campinas, São Paulo, Brazil. Among the various passion fruit species with ornamental potential, the characterization and utility of ornamental hybrid generation of the following species is distinctive, at least at the institutions noted above: P. coccinea, P. foetida, Passiflora morifolia,Passiflora mucronata, P. palmeri, P. setacea, P. suberosa. For readers interested in a deeper understanding of the subject, we suggest reading the specific research of Abreu et al. [49] and Costa et al. [50].\r\nThe use of Passiflora species as medicinal plants has been previously documented. The leaves, flowers, roots, and fruit of wild and commercial species are known to fight diseases, such as helminth infestations, gastric tumors, and stress, and are an integral component of the cultural tradition of many populations [50]. Passion fruit is a rich source of minerals and Vitamins A, C, and D [51] as well as a source of alkaloids, flavonoids, and carotenoids that are beneficial to human health [52]. Passion fruit seeds are sources of essential fatty acids (55%–66% linoleic acid, 18%-20% oleic acid, and 10%-14% palmitic acid), which may be used in the food and cosmetic industries [53]. The potential commercial use of passion fruit also includes the extraction of oils for the manufacturing of soaps, creams, shampoos, and other products by the cosmetic industry [54]. Compounds in passion fruit plants with anxiolytic, antihypertensive, sedative, and analgesic properties are well known [55,56]. Considering the research presented above, the following species stand out among the various passion fruit species with potential medicinal properties: P. alata,Passiflora caerulea, P. edulis, P. foetida, Passiflora incarnata, Passiflora laurifolia, and Passifloramaliformis.\r\nDespite the ecological importance and different potential uses of Passiflora as a genetic resource, it is the production of fruit for food and commercially produced juice that justifies the cultivation of the passion fruit plant [57] and that has led to increasing academic and economic interest. Brazil is the largest producer and consumer of passion fruit [58,59]. National production reached approximately 776,000 tons in 2012 [60]. Although the cultivation of passion fruit occurs in all regions of the country, northeastern Brazil produces approximately 73% of the national product [60]. Approximately 90% of the area designated for passion fruit culture is cultivated with P. edulis, and P. alata is the second most cultivated species of the genus [54,61]. Although they represent a small proportion of national production, the cultivation and consumption of fruits from wild species, such as Passiflora cincinnata, Passiflora nitida, P. quadrangularis, and P. setacea, have been reported in the literature [31,57,61,62,63].\r\nBrazil’s position as the largest passion fruit producer is due to the large size of the area cultivated rather than its productivity (Table 1). Data from the Brazilian Institute of Geography and Statistics, shown in Table 1, indicate an increase in the area devoted to passion fruit cultivation and fruit production but do not indicate a corresponding increase in productivity. The change in productivity of passion fruit cultivation was no more than 4% over the last 10 years despite the available natural diversity and progress in genetic breeding techniques. Furthermore, the recent mean productivity in Brazil (Table 1) is less than 30% of the potential productivity rate estimated for passion fruit cultivation with the use of improved cultivars and techniques [61].\r\nThe major factors that limit productivity are the absence of productive varieties that are adapted to local conditions, a lack of resistance to major diseases, and the use of seeds obtained by open pollination from plants in the planted area, which generates low quality fruit and inconsistent production [30,32,64]. These conditions primarily occur because the available improved genotype selections for producers are scarce [61,64,65]. The Passiflora genetic resource exhibits variability in resistance to major passion fruit diseases and a high morphological variability, which together may contribute to disease control or the diversification of products. Although the potential for wild and commercial species is remarkable, basic studies involving the agronomic characterization of the species must be initiated.\r\nBecause molecular biology in general and the use of molecular markers in particular provide a wide range of useful tools for basic and applied research associated with genetic breeding at different stages (from the prospect of germplasms to the characterizations required for pre breeding and the protection of cultivars in the post breeding period), success is expected for passion fruit breeding programs in the future. Therefore, the current review will address the available knowledge on this subject (with tables and diagrams to represent the data quantitatively and qualitatively) and discuss the relevant studies and resulting knowledge, although this review does not pretend to end the discussion on the current and potential use of molecular markers to characterize the genus Passiflora and for plant breeding.\r\n2. Contributions of Molecular and Genetic Studies for the Characterization and Use of Passiflora Biodiversity\r\n2.1. Biodiversity, Conservation, and Breeding of Passion Fruit\r\nThe concept of biodiversity may vary according to the context in which it is employed. Biodiversity may be defined as the totality of genes, species, and ecosystems of a specific region or the planet as a whole. This totality is the result of evolutionary processes [66,67]. The components of biodiversity with an immediate and/or potential interest for humans constitute a biological resource that may, in turn, be classified as a genetic resource [67] including the genetic variability of social and economic assets. In general, genetic resources are considered sources of variability (natural raw material) both for breeding programs and to support conservation strategies. However, several characterizations that involve different methodological approaches are required to use genetic resources for the conservation of biodiversity and genetic breeding. We have devised an illustrative scheme to facilitate the understanding and visualization of the relationships among the presented concepts (Figure 3). However, for readers interested in expanding on this theme, we also recommend the reading of specialized texts [68].\r\nAlthough Passiflora has a high species diversity, and despite the dispersion of this genus within different tropical biomes, information on the intra  and extraspecies genetic diversity is rare for most species. Research available in the primary databases of scientific publications (Scopus [69] and Web of Science [70]) includes characterizations of genetic diversity based on molecular markers of fewer than 60 species (details are provided in Table 2 and discussed in the following sections). Nearly all these studies were performed using dominant markers, which do not allow for the maximum exploitation of genetic information because it is impossible to distinguish heterozygote genotypes, and were based on a few commercial genotypes with only local interest and/or a few wild accessions per species. Therefore, these studies cannot be characterized as population genetics studies.\r\nSimilar to the lack of information available on the cytogenetics (discussed in the introduction of this review) and genetic diversity of Passiflora, the number of accessions present in collections and active germplasm banks (BAGs) of passion fruit are considered incipient in Brazil and across the world [27,54,59]. At least 1200 accessions of Passiflora spp. are estimated and are preserved in 50 collections of germplasms distributed in approximately 32 countries (Figure 4) [54,59]. Among these countries, we highlight Brazil, Ecuador, Peru and Colombia, which account for approximately 84% of accessions. Although it is likely that the exact number of accessions kept in these collections has varied since the compilations made by Ferreira [59], the predominance of accessions in South American collections present in tropical countries is expected because this region is considered as a center of diversity of the genus Passiflora [7,8,9,10]. In addition, these same countries are recognized as leading producers of passion fruit. [59]. Although Brazil is considered an important center of genus diversity, extant collections contain fewer than 70 species of the genus, or approximately 50% of the Brazilian Passiflora species and less than 15% of all species within the genus [59]. Furthermore, the majority of accessions in BAGs lack biological, genetic, and molecular characterizations. This dearth of information on accessions is partially responsible for the lack of passion fruit breeding programs and may have also resulted in the reduced productivity of existing programs.\r\nThe vast majority of passion fruit accessions are maintained in Brazilian institutions, highlighted by the collections and germplasm banks maintained by Embrapa (Centro de Pesquisa Nacional de Mandioca e Fruticultura, and Centro de Pesquisa Agropecuário do Cerrado), the Instituto Agronômico de Campinas (IAC), and the Instituto Agronômico do Paraná (IAPAR) as well as the Universidade Estadual Paulista (UNESP), Universidade Estadual do Norte Fluminense (UENF), Universidade Federal do Rio de Janeiro (UFRJ), and Escola Superior de Agricultura Luiz de Queiroz (ESALQ/USP) [25]. The current estimate is that these eight institutions have 65 passion fruit species represented in 640 accessions, approximately 25% of which are related to the two species of greatest commercial interest, namely, P. edulis (with 105 accessions) and P. alata (with 65 accessions) [25,59].\r\nThe discrepancy between the natural variability inherent to the genus and the reduced variability represented in BAGs should be remedied as quickly as possible because it hinders the establishment and progression of Passiflora genetic breeding programs [59]. Similarly, utilization of the available genetic variability for Passiflora has been neglected during cultivar generation [61]. Thus, although several wild passion fruit species are resistant to diseases and pests, derived cultivars do not have the same genetic resistance. In fact, these cultivars are prone to contracting the major diseases of cultivated passion fruit. Furthermore, the literature suggests that different cultivars exhibit low variability in their levels of resistance [32].\r\nThe above conditions are justified, at least partially, because the first studies in the 1980s [28,71] that contributed to the establishment of Passiflora breeding programs prioritized production (quantitatively and qualitatively) and not necessarily the other aspects of genetic diversity, such as resistance, ornamentation, and the production of potential medicinal compounds.\r\nIn addition to the potential for commercialization because of the natural beauty of their flowers and the taste of their fruits, wild passion fruit species have desirable characteristics for the yellow passion fruit, including resistance to pathogens and pests (P. caerulea, P. cincinnata, P. coccinea, Passiflora gilberti, P. laurifolia, P. setacea, and P. suberosa), self compatibility (P. tenuifolia, P. elegans, P. capsularis, P. villosa, P. suberosa, P. morifolia, and P. foetida), and variability in the season of production compared with commercial species (P. setacea and P. coccinea) [33,54]. For some species, such as P. caerulea, P. cincinnata, P. coccinea, and P. setacea, interspecific hybrids are being developed and characterized [33,54,72] and estimates of genetic diversity and confirmation of the hybrids based on molecular markers are being carried out [54,62,63].\r\nAccording to these studies, the genetic base of the yellow passion fruit is restricted with respect to disease resistance and tolerance. In fact, the authors favor the use of genetic resources from wild species in breeding programs. Several authors have emphasized research on the description, characterization, and use of germplasm as a priority for passion fruit production to obtain more productive passion fruit cultivars with increased resistance to diseases [54,73]. The joint use of molecular markers and classical breeding procedures has been suggested as a necessary strategy to accelerate the production of fruit varieties that are adapted to different Brazilian regions [64].\r\nAlthough the realities of existing cultivars, such as low variability and susceptibility to disease, still endure for cultured passion fruit, an increasing number of studies devoted to the characterization of resistance in wild species and commercial accessions are being performed [32,34,74,75]. Interspecies crosses that aim to incorporate the resistance genes of wild species into commercial species are also being implemented and evaluated [54,76,77]. The following sections discuss the applications and contributions of molecular markers to our understanding of the genetic diversity of Passiflora and to the various stages of breeding programs.\r\n2.2. Application of Molecular Markers for the Characterization of Passiflora Diversity\r\nThe use of molecular markers for genetic characterization projects with a variety of objectives for a range of organisms is routine in many laboratories. Although molecular biology techniques have become prevalent in recent decades, leading to a reduction in the cost of most molecular markers, the availability of resources and background information are still determining factors in the choice of methods and markers to be used. In recent decades, the increase in the number of molecular markers associated with the growth of related fields of study, such as population genetics, genetic breeding, statistics, and bioinformatics, has generated immense progress in the knowledge applicable to conservation and biodiversity manipulation.\r\nGenetic studies associated with molecular markers are becoming standard for the Passiflora genus. These studies range from the use of dominant markers to the development and employment of co dominant markers and single nucleotide polymorphisms (SNPs). Figure 5 provides a general chronological overview of the evolution of major molecular markers and their use in studies of Passiflora. A simple quantitative evaluation of published papers, the data from which are shown in Figure 5, indicates that the use of molecular markers in Passiflora research began approximately 15 years ago with the use of the random amplified polymorphic DNA (RAPD) markers to study the diversity of 52 accessions from 14 Passifloraspecies [7].\r\nDespite the availability of approximately 4000 fragments of DNA and RNA sequences from Passiflora(data from the NCBI nucleotide database [78], genetic studies employing widely used molecular markers in different stages of breeding programs and for estimates of diversity (for example, restriction fragment length polymorphism (RFLP), RAPD, amplified fragment length polymorphism (AFLP), inter simple sequence repeat (ISSR), simple sequence repeat (SSR), and SNP markers) have typically been limited to a few Passiflora species. However, additional species are currently being studied. Table 2 (and the supplementary Information) provides a summary of existing research using molecular markers during different phases of genetic breeding (from pre  to post breeding) regardless of the study’s scope. Table 2includes all of the information about these studies, ranging from the investigation goals to the techniques and species used. The data in Table 2 confirm the absence of genetic and molecular information reflected by the genetic diversity of Passiflora; few species have been studied (fewer than 60), and most of the research has focused on Passiflora species or accessions with previously established commercial interest. Research on ecological justifications and aims coupled with species conservation have not been performed, although brief discussions on the characterization and ex situ conservation have been published.\r\nMost molecular genetic studies (approximately 65% of all papers, 85% of which are based on genetic diversity) are based on the use of dominant markers. Although dominant markers are useful for genetically distinguishing species (for tests to confirm hybrids and the direction of convergent and divergent breeding), they have limitations, such as low repeatability and suboptimal genetic information profiles (homozygote and heterozygote specimens cannot be distinguished), that are highly relevant for population studies.\r\nDespite the limitations inherent in the use of dominant markers, genetic diversity estimates based on wild and commercial accessions have contributed to the understanding of the genetic variability of passion fruit. In this context, RAPD and AFLP markers have been used to demonstrate high genetic variability among accessions of P. edulis [58,79] as well as a lack of correlation between the estimated genetic distances and geographical origins of the accessions evaluated [79]. However, estimates of variability using RAPD markers performed with commercial accessions of P. edulis indicated low genetic variability [8,80]. The authors of these studies have suggested that the apparent contradiction between the low genetic diversity identified with molecular markers and the large variability observed in commercial plantations is due to the major influence of the environment on morphological characteristics. Greater genetic distance was observed among accessions of purple and yellow fruits [8,58], and the accessions of purple and yellow fruits are considered genetically distinct despite belonging to the same species [58].\r\nThe use of RAPD markers has also contributed to estimates of diversity in wild species of passion fruit, such as P. cincinnata, P. nitida, and P. setacea [62,63,81]. In these studies, large genetic variability was observed, with percentages of polymorphic loci ranging from 64% in P. nitida [81] to 93% in P. setacea[63]. The fact that many studies, especially those conducted on wild species, only address accessions collected in the same geographic region illustrates the need to conduct further studies with a broader representation of accessions to more completely determine the variability and possible genetic structure of passion fruit.\r\nResults on the characterization of genetic variability and the identification of potential regions related to resistance genes, phylogenetically conserved in plants, were first published for the genus Passiflora in 2010 [82] (Figure 5 and Table 2). This study used six degenerate combinations of resistance gene analogs (RGA) primers, originally designed to anneal with the NBS (nucleotide binding site) motive present in several classes of resistance genes. The results presented by Paula et al. [82] show wide interspecific variability among the amplicons generated, enabling the use of these markers for variability studies in germplasm banks as well as in genetic mapping. Although these are preliminary results, the authors also observed amplicons containing genomic segments of type NBS LRR (leucine rich protein and the nucleotide binding sites) present in different plant species.\r\nSince the publication of these results, studies of intra and interspecific diversity performed with use of RGA markers are being conducted at the Universidade Estadual do Sudoeste da Bahia (UESB, Itapetinga, Bahia), and the preliminary results confirm the efficiency of these markers for the characterization of genetic variability in commercial and wild species of passion fruit [83]. RGA markers have also contributed to linkage analysis and the construction of a recent genetic map for P. alata [84].\r\nStudies on Passiflora using co dominant markers began in 2005 and were mainly limited to the development of microsatellite markers for the species P. edulis [85,86,87], P. alata [88,89], P. cincinnata[87,90], P. setacea [87], and P. contracta [91]. Studies on other species of this genus addressed the evaluation of cross amplification [15,92,93,94] and hybrid confirmation [45]. Most of these studies were restricted to characterizations in agar gels or polyacrylamide gels and require additional evaluation, including profiles of amplifications and polymorphic loci. The identification and characterization of microsatellite loci in the genus Passiflora indicated low levels of polymorphism in these genomic regions, at least for the species evaluated (Table 3). The average number of alleles per characterized microsatellite locus was low in studies of wild and commercial species of Passiflora, ranging from 2.8–5 alleles per locus for the wild species P. cincinnata, P. contracta, and P. setacea [87,90,91] and from 3.1–7.6 alleles per locus for the species of greatest commercial interest, namely, P. edulis and P. alata [85,88].\r\nRegarding the estimates observed for microsatellite loci from passion fruit (Table 3), it is also important to note that the low values of observed heterozygosity, compared with the values of expected heterozygosity, suggest low allelic diversity and tendency toward the fixation of alleles, at least for the germplasm evaluated. The percentage of polymorphic microsatellite loci observed in characterizations of passion fruit species can also be considered low, with an average of approximately 28% of microsatellite loci polymorphic across wild and commercial species; in the wild species P. cincinnata and P. setacea, the individual values are 21% and 29%, respectively [86,89], and in the commercial species P. alata and P. edulis, the individual values are 25% and 35%, respectively [86,89].\r\nResearch that characterizes genetic diversity in wild populations by microsatellite markers remains unpublished, although reports on evaluations of germplasm materials in Colombia [95] and Brazil [94,95,96,97,98] have been published. The microsatellite marker sets used by Ortiz et al. [95] in a study with P. edulis and by Amorim et al. [96] in a study with P. capsularis and P. rubra have not shown polymorphisms, whereas other studies performed by Reis et al. [97,98] have exclusively evaluated genotypes from cycles of recurring selection in P. edulis progenies. The hypothesis that microsatellite loci have low levels of polymorphism, which has been based on identification and characterization studies of the microsatellites [85,86,87,88,89,90], is supported by the absence of polymorphism observed in a study of genetic variability in Colombia that analyzed 70 passion fruit plants (P. edulis) collected in 60 commercial plantations [95]. Ten microsatellite loci reported in P. edulis [85] and seven in P. alata [88] were used in that study.\r\nThe first successful estimates of genetic diversity in Passiflora accessions were obtained with SSR markers in 2013 [92,94]. However, those studies were limited in their estimates of intraspecies diversity because of the small number of plants that were evaluated (fewer than six plants for most species). In addition, even for interspecific studies, such as that performed by Oliveira et al. [92], where 11 passion fruit species were considered, the average number of alleles was not more than five (ranging from 1–13 alleles per locus).\r\nThe variation in the genetic diversity estimated in published papers, primarily those analyzing commercial species, is due to not only the specific characteristics of the genotypes evaluated but also the effects of the different statistical methodologies employed by the authors. Methodological influences on the results of diversity estimates have been reported for a variety of species, including Mangifera indica [99], Olea europaea [100], Zea mays L. [101], and Solanum lycopersicum [102]. Differences in methodologies have also been discussed for studies of morphological characteristics and of genetic diversity that used molecular markers to study passion fruit [103]. In the latter work involving passion fruit, comparisons were made among seven distance measures, 14 similarity coefficients, and five grouping methods. The authors concluded that the diversity estimate is significantly influenced by the method employed. Considering the different methodological strategies that have been employed for data analysis in the various studies of diversity among passion fruit accessions, the authors suggest that the choice of the methodology to be used and the comparison of results obtained using different measurements and coefficients should be performed carefully.\r\nResearch projects conducted as part of a joint venture between the Universidade Estadual de São Paulo (ESALQ/USP, Piracicaba, Brazil) and Centre National de Ressources Génomiques Végétales (CNRGV/INRA, Toulouse, France) during the past five years have introduced the first SNP identifications in commercial passion fruit species (P. alata) [84]. However, the use of these data remains limited to the construction and saturation of genetic maps, as is the case for most microsatellites available for commercialPassiflora species.\r\n2.3. Application and Perspectives of Genetic Engineering for Passion Fruit Culture\r\nConsidering the diversity of species and intra  and interspecific genetic variability available for use in breeding programs of passion fruit, genetic engineering as a methodological strategy to increase favorable characteristics for passion fruit culture has been specifically employed to search for disease resistance [104]. With regard to diseases such as passion fruit woodiness (PWD) (caused in Brazil by Cowpea aphid borne mosaic virus) and the bacterial spot disease (caused by Xanthomonas axonopodis pv. passiflorae), for the which chemical control measures are not effective and resistant cultivars are not available, a growing number of advances in the use of genetic engineering have been observed in recent decades [105,106,107,108].\r\nStudies attempting to produce transgenic passion fruit have been conducted since the late 1990s and early 2000s at the Universidade Federal de Viçosa (UFV), Minas Gerais, Brazil, and Universidade de São Paulo (USP), São Paulo, Brazil; the first results were published in 2005 [105] and 2006 [106]. In these two studies, plants of yellow passion fruit (P. edulis) were transformed from fragments of genes obtained from viral isolates known to cause PWD. These studies were initiated based on a pathogen derived resistance (PDR) approach that likely relied on the induction of post transcriptional gene silencing (PTGS).\r\nAn untranslatable construct consisting of two thirds of the NIb gene and the 5' region of the CP gene derived from a viral isolate of CABMV was used by Alfenas et al. [105]. In turn, a construct consisting primarily of the CP gene was used by Trevisan et al. [106]. In both studies, transgenic plants resistant to PWD were obtained. However, the effective resistance observed in the transformed plants by Alfenas [105] was restricted to the viral isolate from which the fragments of the NIb and CP genes were isolated. It is probable that the high variability in the nucleotide sequence of the NIb gene was the main factor contributing to this result. Subsequently, the transgenic plants (R0) were self crossed to generate homozygous lines (R1), and a plant of this line was resistant to seven viral isolates [109]. The authors defend the hypothesis that the dose used, due to the presence of homozygous plants for the transgene in the R1 lineage, contributes substantially to the spectrum of resistance observed [105,109].\r\nIn addition, one of the transgenic plants produced by Trevisan et al. [106] was immune to all the three isolates considered in your search, but the potential resistance of these transgenic lines to other isolates found in Brazil is not known. Studies performed by Monteiro Hara [107] identified new transgenic lines of passion fruit and generated transgenic lines R1 and R2, both from transgenic plants characterized by Trevisan et al. [106], as well as from the new lines constructed. Homozygous lines did not show symptoms of the viral disease after either mechanical inoculation or inoculation by aphids [107]. New crosses were made between R2 plants selected by the authors for future studies.\r\nAlthough in smaller proportions or in less advanced stages, studies devoted to obtaining transgenic plants were also conducted with P. edulis for resistance to diseases and herbicides through the introduction of a baculovirus anti apoptotic gene (p35 gene) [108] and the resistance to bacterial spot disease by introducing the sequence of the attacin A gene (attA) [110]. Plants of P. edulis transformed with p35 gene sequences showed no resistance to CABMV but showed increased tolerance to bacterial spot disease and glufosinate herbicide when compared to non transgenic plants [108]. Ten plants of P. edulis transformed with the attA sequence of the gene showed no leaf lesions after inoculation with X. axonopodis pv. Passiflorae, indicating possible resistance to the pathogen. Initial tests attempting to obtain transgenic plants were conducted with P. alata [111]. These experiments demonstrated the possibility of obtaining transgenic plants for P. alata. Similar to the work conducted with P. edulis, the transformations achieved in P. alatawere conducted using Agrobacterium tumefaciens and a fragment of the CP gene CABMV.\r\nIn conjunction, the progress observed with the studies dedicated to the production of transgenic passion fruits indicates that, at least for PWD, it is possible that resistant plants will soon become available for cultivation and/or for use in breeding programs dedicated to the production of resistant cultivars with higher productivity.\r\n2.4. Contributions and Perspectives of Molecular Biology in Pre  and Post Breeding Programs\r\nThe contributions of molecular biology, and especially the use of the molecular markers, in (pre ) breeding programs may be didactically separated into at least six research modes: (i) the direction of convergent and divergent crossings leading the initial stages of breeding; (ii) the confirmation of intra  and interspecies hybrids with a reduction in the occurrence of escapes; (iii) the contribution of retro crossings with a decrease in the time necessary for the re composition of the genome; (iv) the genetic mapping and identification of quantitative trait loci (QTLs) that are useful for the subsequent introgression of genes into commercial species and cultivated varieties; (v) the prospection and characterization of resistance genes, both by mapping strategies and through the use of analog markers of resistance genes; and (vi) the identification and protection of hybrids and cultivars. Coupled with the effective use of markers, these joint activities contribute to the establishment of an assisted selection program because all of the information provided enables the efficient use of the available germplasm.\r\nIn addition to their contribution to understanding the diversity of populations or groups of regional accessions, estimates of passion fruit genetic diversity have enabled the identification of converging and diverging crosses that can contribute to different stages of a (pre ) breeding program. For commercial species, such as P. edulis [80], as well as wild species, such as P. setacea [63] and P. cincinnata [62], preferred crossings were suggested after the characterization of RAPD markers to generate progenies with greater or lower potential for segregating characteristics. The identification of genetically divergent accessions between yellow and purple passion fruit that has been achieved based on molecular markers [8,58] can also be used to target crosses that aim to broaden the genetic base of breeding programs for P. edulis.\r\nThe absence of agronomic characterizations for most accessions in the aforementioned studies is the greatest challenge to introducing information from genetic diversity estimates into current breeding programs. Difficulties in the joint use of data from phenotype and genotype characterizations (particularly when related to neutral markers) have been reported for different cultures and are an aspect of the challenge inherent in studies of natural populations [112]. For cultivar development, the pre breeding programs that completely exploit the use of molecular techniques and field characterizations in germplasm are indicated as bonding strategies between natural variability and the cultivars employed for the maintenance and growth of cultures [67].\r\nDifferent molecular markers, such as RAPD and microsatellites, are highly efficient and user friendly techniques that can be used to confirm intra  and interspecies hybrids. The first study to employ molecular markers to confirm hybrids from 17 interspecies crosses of 14 Passiflora species of agronomic interest associated with fruit production was published in 2008 [72] and was based on the profile of DNA fragments generated using 12 RAPD primers. Similar molecular markers have since been utilized to confirm and characterize interspecific ornamental hybrids [47,113] based on the profile of DNA fragments generated using seven RAPD primers and one SSR primer. The confirmation of hybrids using molecular markers may decrease the occurrence of escapes and reduce costs via the restricted maintenance of seedlings to be used in sequential stages of a (pre ) breeding program.\r\nMolecular markers also contribute to the characterization and selection of specimens with a higher genomic contribution from the recurrent parent [76,114]. The characterization of parents and segregant genetic diversity, which are associated with evaluations of the specific phenotype, inform crossings and reduce the number of backcrossing cycles required to obtain the hybrid of interest at the start of breeding. This strategy has improved the introgression of disease resistance found in the wild species P. setacea into the cultivars GA 2, AR 1, and EC2 O of P. edulis [ 114]. An experiment performed at EMBRAPA Cerrados re established a 92% average of the commercial ancestor’s genome (P. edulis) in hybrids while maintaining the resistance of the wild ancestor (P. setacea) [114].\r\nOne of the most thorough passion fruit studies, at least with regard to molecular markers within the context of breeding, consists of the construction of genetic maps and identification of regions associated with characteristics of interest (QTLs or, more specifically, quantitative resistance loci, QRLs). Early genetic mapping of passion fruit species began in 2000, and the first maps were published in 2002 [115]. These maps were based on the characterization of a segregant population of P. edulis using RAPD markers. The population used to construct the first map helped to identify the first QRLs linked to the genus Passiflorausing AFLP markers [116]. The quantitative resistance locus detected by Lopes et al. [116] explained approximately 16% of the phenotypic variation related to symptoms from bacterial spot disease caused byX. axonopodis pv. passiflorae.\r\nThe use of map integration strategies to construct a single map (rather than two maps representing ascendants) [86] was a landmark in genetic mapping studies and the identification of QTLs in passion fruit. Another important feature of the Passiflora map was the use of microsatellite markers for the map construction in addition to AFLP [86]. An important advantage of the integrated construction of a single representative map of a segregant population is an increase in map saturation and length. The extension of research to construct maps and the identification of QTLs in passion fruit plants have occurred only recently for another species of this genus: the first integrated genetic map for P. alata was published in 2013 [104]. The use of variable AFLP and SSR techniques and the first characterization of SNPs in the passion fruit plant were included in this map [104].\r\nResearch dedicated to the construction of physical maps has also been conducted [42]. Physical maps were obtained from putative genes identified from a passion fruit genomic library inserted into BACs [42,43]. This research is a new development in genetic and genomic studies of passion fruit; it characterizes the species’ genomes, identifies evolutionary relationships, and develops new molecular markers, including SSR markers, expressed sequence tags (ESTs), and SNPs.\r\nThe advances in the genetic mapping of passion fruit associated with the reduction of costs of next generation sequencing (NGS) should enable genetic characterizations based on genotyping by sequencing (GBS), at least for commercial species, in both the short and medium term. In this context, alternative methodologies that reduce costs and enable GBS, such as the use of restriction enzymes to reduce genome complexity [117], should be considered in future genetic studies of passion fruit; these methodologies can contribute to both population studies and procedures of genome wide selection in collections and germplasm banks.\r\nMolecular markers are also used in different stages: after cultivars are obtained and distributed (generically termed post breeding), when paternity is determined (and thus the culture is protected), and when monitoring cultivar genetic purity, regardless of whether the cultivars are clonal or seminal [64]. When legislation to protect cultivars is in effect (Act 9456, Brazil), the growth, development, and use of marker groups for post breeding will be increasingly necessary for passion fruit cultivation, particularly because of the increase in the number of varieties that will be developed and made available to producers.\r\nGo to:\r\n3. Conclusions, Perspectives, and Challenges\r\nConsidering the challenges of breeding passion fruit, as well as the available knowledge and conservation of the genetic variability of this genus, we believe that the following research activities should be prioritized: (i) the identification of new accessions to increase the representative breadth of germplasm banks, especially for wild species; (ii) the measurement of population genetics estimates that enable a true understanding of the genetic diversity and structure of passion fruit; (iii) phenotypic characterizations that contribute to both the useful evaluations of the germplasm for interspecific crosses and studies of the association between phenotypic and molecular data; (iv) research efforts devoted to identifying genomic regions associated with resistance to diseases; and (v) the potential use of transgenic strains previously evaluated in crosses targeted in breeding programs.\r\nThe recent research on the diversity of wild passion fruit species and the increasing use of molecular markers, particularly co dominant markers, have made knowledge from population studies available and are promising for further genetic research on passion fruit. Although highly relevant for conservation and breeding activities, population studies of Passiflora are only in the initial stages. Coupled with a large gap in group population genetic research, the increasing availability of microsatellite markers for Passifloraspecies and the use of cross amplification strategies to popularize marker use should increase the number of research studies. Further research should be performed to identify and characterize microsatellite loci because the current results indicate low allelic diversity among SSR loci. In this context, the use of strategies for sequencing and genotyping on a large scale will be important.\r\nIn parallel with the population estimates that must be performed for the genus Passiflora via molecular markers, strategies for the exploration and conservation of germplasm collections are also necessary to enable morpho agronomic characterizations to be performed efficiently to increase the understanding of both neutral biological diversity and diversity that is subject to natural selection. In this way, the interactions involving the accessions present in banks, germplasm collections, and elite materials used in breeding programs will be enhanced.\r\nSimilar to the expected growth in microsatellite marker usage in population studies, recent genomic investigations of commercial passion fruit species have developed and characterized SNP markers. These studies should be promoted because they will encourage different types of research, as has occurred with the saturation of genetic maps, the identification of QTLs, and the exploitation of mapping by association. Collections, germplasms, or elite accessions can be employed in such a strategy, and thus, a detailed map of the genomic regions of interest can be achieved. Moreover, the development and use of large scale genotyping should allow for the use of strategies for genome wide selection (or simply genomic selection), enhancing the association of genetic diversity data with characteristics of agronomic interest. In addition, the use of GBS strategies should help to reduce the costs and time required for germplasm characterization and the selection of passion fruit genotypes.", user_id: 3, journal_id: 1, field_id: 8, institution_id: 4});

paper5 = Paper.create!({title: "Computational Studies of Lithium Diisopropylamide Deaggregation", body: "Introduction\r\nLithium diisopropylamide (LDA) is prominent in organic synthesis. In a comprehensive survey of the frequency that reagents were used in approximately 500 natural product syntheses, LDA came out number one. This prevalence is one of the two reasons why we have focused on understanding the structure-reactivity relationships in LDA-mediated reactions. The other is that LDA offers a highly tractable template with which to study the influence of aggregation and solvation on organolithium reaction mechanisms. The numerous synthetic applications of LDA combine with its complex coordination chemistry to produce considerable mechanistic variations.\r\nTo understand the source of the complexity—if not the complexity itself—we present Scheme 1, which summarizes the deaggregation of disolvated LDA dimer 1 to trisolvated monomer 6. For many reactions, typically those that are conveniently monitored between 0C and 60C, the aggregates equilibrate very quickly compared to the rate of reaction being studied. Under conditions of fully established equilibria, all aggregates are available to react with the substrate, and studies have shown that many do. During the course of our research we began to believe that a coherent picture of reactivity had emerged, which prompted us to summarize the results in a review.\r\nRecent rate studies, however, began to uncover aberrant behaviors that failed to follow conventional patterns. For example, during studies of imine metalations in which the relative reactivities spanned an approximate 60,000-fold range, the most reactive imine required that the reaction temperature be reduced to 78  C (eq 1).4 This was the first time that we had investigated the kinetics of an LDA-mediated metalation at 78  C, and something odd happened: the loss of imine failed to follow a normal (first-order) decay, instead displaying a persistent linearity over the first two half lives. We noted but largely ignored this observation.4 Soon thereafter, odd substrate decays began appearing in disparate reactions including a host of ortholithiations5,6,7 (such as eqs 2 and 3)8 and even 1,4-additions of LDA to unsaturated esters (eq 4).9 All shared two common traits: they were carried out using LDA in tetrahydrofuran (THF) at 78  C, and they displayed hypersensitivities to traces of LiCl (as little as 1.0 ppm).\r\nMechanistic studies indicated that LDA aggregate exchanges were dictating the reaction rate,10 causing the emerging mechanistic picture to be quite vexing. The odd linear decays observed for ortholithiations of aryl carbamates (eq 2)—apparent zeroth-order substrate dependencies consistent with ratelimiting deaggregation of LDA dimer—were traced instead to virulent autocatalysis and the intervention of highly reactive mixed aggregates.6 Unusual time-dependent changes in the concentration of LDA-ArLi mixed dimers attested to non-equilibrium conditions. The ortholithiation in eq 3 was found to be both autocatalyzed11,12 and LiCl catalyzed, but the rate-limiting step of the uncatalyzed metalation involved rate-limiting deaggregation—a true zeroth-order substrate dependence—via a disolvated-dimer-based transition structure. Post-rate-limiting lithiation was shown to occur via a fleeting dimer-based rather than a monomer-based intermediate. Both autocatalysis and LiCl catalysis, by contrast, were shown to divert the reaction through a monomer-based mechanism. Seemingly analogous linear decays for 1,4-additions of LDA to unsaturated esters (eq 4) also involved a rate-limiting deaggregation of LDA, but it was found to occur via a trisolvated-dimer-based transition structure rather than via a disolvated dimer seen for ortholithiation.9 Different substrates were reacting via different rate-limiting deaggregations! The post-rate-limiting 1,4-additions were shown to proceed via an LDA-monomer-based pathway. Highly muted autocatalysis and dramatic catalysis by LiCl were traced explicitly to catalyzed deaggregation to the same LDA monomer.13\r\nAlthough in isolation the case studies are logical, considered together they paint a chaotic mechanistic picture. We began to realize that a complete understanding of LDA-mediated reactions under these highly prevalent conditions—LDA/THF/78  C—demand a more general and comprehensive understanding of LDA deaggregation. Although aggregation dynamics have received some attention, detailed analyses of organolithium deaggregations are absent.14\r\nIn this paper computational studies show that the intermediates in Scheme 1 are legitimate minima en route from the resting state of LDA (1)15 to fleeting trisolvated monomer 6. Moreover, conformational effects on the stabilities of 1–6 as well as on the activation barriers to exchange are surprising in both detail and implication.16\r\n\r\nResults\r\nGeneral\r\nAll structures were computed using diisopropylamido groups and THF ligands without structural approximations. Density functional theory (DFT) and MP2 calculations were performed with the Gaussian 09 package using Gaussview 5.0 and WebMO as a graphical user interface.17 Geometry optimizations and frequency calculations were performed at the B3LYP level of theory using the 6–31G(d) and 6–31+G(d) Pople basis sets. Free energies were calculated from an MP2-derived single-point energy [6–31G(d) basis set] and a B3LYP-derived thermal correction [6–31G(d)] at 195 K (78  C) and 1 atm.18 (MP2 corrections seem to provide superior correlations of theory and experiment, especially for the most highly solvated forms of LDA.)19 Basis set superposition errors (BSSE)20 were corrected using the counterpoise method21to test for energy errors arising from incomplete basis sets. Geometries that are particularly sensitive to BSSE will be discussed. Transition structures were confirmed by the existence of a single imaginary frequency, and intrinsic reaction coordinate (IRC) calculations22 confirm the connection with specific minima. The energy surface describing LDA deaggregation is summarized in Scheme 2.\r\nMinima\r\nMoving from left to right in Scheme 2 corresponds to the stepwise conversion of known disolvated dimer115 (and related less symmetric cyclic dimers) through open dimers to give monomers as indicated in grey scale along the reaction coordinate (x axis). The key minima in Scheme 2 correspond to structures 1–6 in Scheme 1. Bridged dimer 7 and disolvated monomer 8 precede minima corresponding to monomer 6. The shaded regions correspond to conformational ensembles of di- and trisolvated open dimers 4 and 5.23Energy levels inside the shaded region correspond to distinct conformers. The lines illustrate connections between transition structures and specific conformational isomers of minima. Minima 2 and 3 are linked directly because the transformation is computed to be barrierless.\r\nThe steric demands and chirality of the isopropyl group render the potential energy surface of LDA aggregation and solvation rich in detail. Diisopropylamido moieties display two conformational minima corresponding to mirror images (eq 5).24 Consequently, LDA dimers can exist as both homochiral and heterochiral (meso) diastereomers. A number of comparisons, however, show that in the open dimers and open dimer-based transition structures, the two diisopropylamido moieties do not communicate, resulting in comparable energies. The energies in Scheme 2 derive from the homochiral form. In the cyclic dimers (1, 2, and 3), the homochiral form is preferred over the heterochiral (meso) form by ≈1 kcal/mol. The computed structure of 1 matches the crystal structure.\r\nTwo spatial relationships are prominent in open dimers. By sighting along the axis defined by the two nitrogen atoms (dashed line in Scheme 3), we loosely define a pseudo dihedral angle (CC) to describe conformational isomerism arising from the rotational orientations of the two diisopropylamido moieties. These orientations are most easily envisioned by imagining rotation about the N–Li bond of the terminal diisopropylamido group. We define a second, standard dihedral angle (LiO) that describes the THF orientations as defined by rotation about the N–Li bond to the terminal lithium. The open dimers are organized by dihedral angles CC and LiO in supporting information. Other minor conformational adjustments, such as the rotations about the individual THF ligands, coincide with these primary conformational changes.\r\nWe sampled the conformers of disolvated open dimers 4 by incrementally varying CC. Structures 4a–4e (Scheme 4) are representative of the eight conformers available through a 180  rotation, and they span a 2–3 kcal/mol range. (The three omitted do not include any exceptional structural features.) All conformers fall within an approximate 90  rotation. The conversion of 4e to 4a to complete the cycle requires an approximate 90  rotation of the diisopropylamido group, yet no minima are detectable. Changes in CC are accompanied by changes in LiO corresponding to seemingly fluid rotations about the THF-bearing N–Li bond that loosely approximate three orientations. We can find no simple (predictable) relationship between CC and LiO.\r\n\r\nAnalogous conformers are observed for trisolvated open dimers (Scheme 5), yet gearing arising from the high steric demands seems to allow for fewer minima at larger increments of CC. The relative energies of the five conformers span an 8 kcal/mol range. All show a reduction of the N–Li–N angle to ≈165  owing to solvation of the internal lithium. The conformers fit into three groups: (1) 5a is unique in that the THF ligand on the interior lithium is orthogonal relative to the orientation in the other four conformers. Conformers 5b and 5c show evidence of diisopropylamido distortion and reduction of the Li–N–Li angle when compared with the disolvates that we attribute to buttressing. Conformers 5d and 5e seem most akin to the disolvated dimers in Scheme 4.\r\n\r\nTransition Structures\r\nTransition structures 9–15 connect select minima; dashed lines indicate bonds being cleaved. The transition structures are described by two fundamentally different imaginary vibrational modes: (1) Li–O stretching during THF dissociation/association, and (2) N–Li stretching during lithium amide bond formation/cleavage. Both modes are characterized by low absolute values in imaginary frequencies ranging from 18 to 49 cm1. The protocols required for locating transition structures are instructive. The standard method for locating transition structures was to perform a relaxed potential energy scan by incrementally stretching the bond of interest. For example, incrementally increasing the Li–O distance from 2.0 Å by steps of 0.1 Å raised the energy continuously until it dropped at 2.8 Å. Geometries were optimized at each point along the surface with the reaction coordinate describing the Li–O distance. The optimized geometry with rLi–O = 2.8 Å was a good initial guess for a transition state optimization.\r\nIt became evident that only specific conformers could exit the trisolvated open dimer ensemble (Scheme 2). Whereas one conformer of 5 led to THF dissociation (11), another led to closed dimer-formation (12), and two others led to fragmentation (13 and 14). The importance of sampling conformational space cannot be overstated. Transition structure 11 proved particularly difficult to locate but offered interesting insights. Incrementally stretching the Li–O bond afforded no saddle points starting from any of the four lowest-energy trisolvated open dimer conformers akin to 5. Only by scanning from the highest-energy conformer could 11 finally be located. Incidentally, the highest-energy conformer connecting to 11 was not located by a rational sampling of all trisolvated open dimer conformers. A reverse IRC calculation from 13 led to this new geometry, which allowed us to locate 11; serendipity played a big role. The strategy of palpating forward and backward along the reaction coordinate using output geometries as the input for a new search proved an important strategy for locating transition structures.\r\nTransition structures corresponding to N–Li stretching (10, 12, and 13) were located using the scanning protocol. Again, the conformational geometry proved critical. Attempts to find transition structures describing the interconversion of conformers within the open dimer ensembles were unsuccessful, presumably owing to exceedingly low absolute values in the imaginary frequency. Casual inspection of the minima, however, suggests that their interconversion occurs via low energy barriers.\r\nTetrasolvated open dimers\r\nThere is no experimental support for tetrasolvated-dimer-based deaggregations of LDA, but thanks in large part to prompts by a referee we examined the viability of tetrasolvated minima and transition structures as illustrated in Scheme 6. The energies dovetail with those in Scheme 2. Trisolvated open dimer 5 binds a THF at the external lithium (18) while trisolvate 16 binds THF at the internal lithium (19) both yielding tetrasolvated open dimer 20, albeit varying in conformational isomerism. Open dimer 20 then dissociates to two units of monomer 8 via transition structure 21 geometrically analogous to 13 and comparable in energy (22 kcal/mol).\r\n\r\nDiscussion\r\nThe experimental background presented in the introduction paints a chaotic mechanistic picture of a delicate balance between rate-limiting aggregation events and rate-limiting reaction with substrates. DFT computational studies of LDA deaggregation afforded the series of minima that are illustrated in Scheme 1and delineated in full detail with the accompanying transition structures in Scheme 2. The overall picture shows a series of fleeting intermediates and transition structures computed to be within an energy range commensurate with the activation energies of LDA-mediated metalations. The results for the di- and trisolvates reflect results stemming from detailed rate studies. In addition, we examined the role of tetrasolvate-based deaggregations, which are not (yet) experimentally documented (Scheme 6).", user_id: 4, journal_id: 3, field_id: 13, institution_id: 5});

paper6 = Paper.create!({title: "Prime, Banach, Frechet Von Neumann Groups of Subsets and Problems in Descriptive Graph Theory", body: "Abstract\r\nAssume every right-surjective, combinatorially right-embedded modulus acting essentially on a negative triangle is countably empty and elliptic. Recent developments in harmonic group theory [14] have raised the question of whether ˆ? 6= m. We show that there exists an ultraassociative smooth Germain space. It is not yet known whether ZR,G is not distinct from q, although [14] does address the issue of structure. Recently, there has been much interest in the description of pseudo-Laplace, hyperbolic primes. \r\n\r\nIntroduction\r\nRecent interest in categories has centered on describing moduli. This reduces the results of [14, 11] to the negativity of sub-linearly geometric categories. In [14], the main result was the extension of meromorphic, Hausdorff, everywhere singular points. Hence in [11], the main result was the extension of analytically X -convex homeomorphisms. It was Sylvester who first asked whether sub-projective rings can be examined. In [11], the main result was the extension of solvable algebras. Is it possible to derive super-almost normal groups? Therefore it would be interesting to apply the techniques of [14] to subgroups. It would be interesting to apply the techniques of [11] to arithmetic, compactly elliptic vectors. Therefore the groundbreaking work of G. Zhao on Cantor primes was a major advance. Unfortunately, we cannot assume that H(D) is anti-partially integrable and complete. We wish to extend the results of [14, 18] to primes. In [15], the authors computed partial, smooth, continuously isometric curves. A central problem in numerical dynamics is the construction of abelian numbers. Now in [4], the authors address the invertibility of compactly additive hulls under the additional assumption that there exists a dependent algebra. Thus this could shed important light on a conjecture of Green. We wish to extend the results of [14] to matrices. A useful survey of the subject can be found in [18]. Hence it was Beltrami who first asked whether closed graphs can be computed. A central problem in universal set theory is the computation of polytopes. The goal of the present article is to classify unconditionally commutative isometries. Thus a useful survey of the subject can be found in [9]. In [20], the authors extended algebraically universal, algebraic subsets. In [26], the authors address the minimality of infinite, unconditionally Noetherian algebras under the additional assumption that P ? z.\r\n\r\nMain Result\r\nDefinition 2.1. Let W 6= i. A point is a hull if it is invariant. 1 Definition 2.2. Let |E 00| ≤ 1 be arbitrary. A domain is a homeomorphism if it is quasi-trivially Selberg and canonically negative. In [1], the authors address the injectivity of left-Mobius scalars under the additional assumption that M(B) = F. Next, it is essential to consider that Nˆ may be Lie. In [4], the authors address the structure of ultra-differentiable subrings under the additional assumption that p ? ?g. Definition 2.3. Suppose every trivial, embedded triangle is Noetherian. A regular, dependent vector is an isomorphism if it is reducible. We now state our main result. Theorem 2.4. Let us suppose we are given an algebra W . Let E ≤ ? be arbitrary. Then ? is naturally embedded. A central problem in numerical model theory is the derivation of elliptic, sub-meager matrices. So A. Hilbert’s extension of meager random variables was a milestone in microlocal arithmetic. Hence in this setting, the ability to extend pairwise complex, generic, empty systems is essential. The goal of the present paper is to describe countably singular subrings. In this context, the results of [25, 24] are highly relevant. It has long been known that ` 6= ∞ [25]. The goal of the present paper is to extend isomorphisms. It is not yet known whether Z (∆) (1, . . . , π ? 1) 6= ? ? ? W ? ∞ ± V (Y ), T = ∞ ?(?0,e?5 ) sinh?1 (?K) , ∆ > e , although [24] does address the issue of uniqueness. A useful survey of the subject can be found in [5]. Therefore it has long been known that every graph is contra-free and multiplicative [22].\r\n\r\nFundamental Properties of U-Stochastically Positive, Artin–Fibonacci Functions\r\nIs it possible to construct classes? So it has long been known that there exists a Russell, contracanonical, co-symmetric and hyper-Brahmagupta reducible matrix equipped with an anti-convex polytope [8]. The groundbreaking work of N. Taylor on quasi-Eratosthenes polytopes was a major advance. Let E ≤ ?. Definition 3.1. Let Q˜ be a modulus. We say an affine function acting discretely on an unique, open triangle U is Lambert if it is finite. Definition 3.2. A real homeomorphism u is Sylvester if ? is not larger than ˜ E0 . Theorem 3.3. Suppose ? < 0. Let ? ≤ V (y) be arbitrary. Then A is canonically non-finite. Proof. This is clear. Lemma 3.4. Let us assume we are given an irreducible, totally meager, null path W. Suppose K < k?˜ k. Further, let k?k ? |gW |. Then G ? ∞. \r\nProof. This is left as an exercise to the reader. Recent interest in smooth hulls has centered on classifying curves. Hence this reduces the results of [26] to a recent result of Thompson [19]. Moreover, U. Shastri’s characterization of trivial triangles was a milestone in integral logic. The work in [19] did not consider the compactly normal, combinatorially complex case. Recent developments in linear PDE [15] have raised the question of whether k?k ? ?0.\r\n\r\nThe Extension of Left-Everywhere Smale Monoids\r\nIt is well known that J = 1. Hence in [21], the authors computed pseudo-simply von Neumann, discretely independent, Lie primes. This leaves open the question of smoothness. Let W(Eˆ) ≥ ? be arbitrary. Definition 4.1. Let j 6= 0. A finite ring is a group if it is null, countable, free and non-invertible. Definition 4.2. A contra-orthogonal, dependent, Siegel–Smale triangle ? is Euclidean if C = 1. Proposition 4.3. Let K¯ ≥ q. Let x˜ be a discretely anti-nonnegative, unconditionally super-abelian point acting naturally on an essentially tangential, trivial, bijective subset. Then ?1 ± kBEk ? |n| ? ?0. Proof. We show the contrapositive. Let n ≤ d¯. Obviously, every anti-Kolmogorov arrow is countably semi-embedded and globally generic. Hence k 0 = 2. As we have shown, C¯ is pseudo-analytically geometric. It is easy to see that if ? is quasi-Liouville and super-local then kHk ≥ |Z| ¯ . Suppose Y (0 · ∞, . . . , ?0) ? n ∆: ?0 < Msin?1 i ?7 \u0001o = ˆp ? tan?1 (?) ? · · · ? exp?1 (?∞) = cos?1 ?1 ?6  ? ? (a)?1 (0) · J?2 ≤ tˆ \u0010 k?ˆk · 0, ? · FU \u0011 . We observe that if Monge’s criterion applies then i \u0012 ?, . . . , 1 B(L) \u0013 ? [ log (π) > sup F?∞ tanh (O ± ∞) ? · · · ? B¯ ≤ \u001A ?iE : kQk < Z t? T , r?7  dx\e ? Z 1 ? \\ ?? d?00 ± · · · ? h 00 |R¯| 6 , 0  . Thus every meager, completely semi-hyperbolic group is singular. Obviously, if I = 1 then there exists a finitely invariant degenerate matrix. Thus W is one-to-one. So Bˆ 6= ˆj. Next, if k? 0k ≤ |A˜| then there exists a non-unconditionally regular naturally Siegel prime acting analytically on an everywhere arithmetic, Hamilton, ordered morphism. As we have shown, P¯ 3 1. By convexity, D¯ > J. Let us assume there exists a quasi-Galois and non-Gauss simply left-linear, invariant plane. Clearly, there exists an algebraic multiplicative, co-countable, linear domain equipped with a contrasimply hyper-compact subgroup. It is easy to see that if t¯ ? ?∞ then Poincar´e’s condition is satisfied. This completes the proof. Lemma 4.4. Let Z (?) ≤ U be arbitrary. Let us suppose exp?1 (20) ? √ 2 X 2 5, . . . , ?f (a)  ? \u001A t¯?4 : 1 i = ˆc ?9 \e 6= \u001A kyk: 1 ?= ?0 0 1 \e . Further, let us assume L ? k?k. Then ? ?1 \u0012 1 ?1 \u0013 ≤ h ?1 \u0010√ 2S \u0011 ? XV \u0012 1 √ 2 \u0013 ? · · · ? exp?1 0 ?7  ?= Y 1 a , ?∞\u0001 √ 2 ?3 ? Z X eˆ?c \u000FR,S dH ? · · · ? ?∞ · N¯ ? XZ ?0 e tanh (1) d?. Proof. We proceed by transfinite induction. By a well-known result of Weil [18], every arithmetic, partially differentiable group is locally hyper-free. It is easy to see that if Q˜ ≥ √ 2 then Kˆ is greater than ˜µ.\r\nOne can easily see that if Hamilton’s condition is satisfied then every trivially non-unique manifold is non-admissible, left-embedded, anti-local and non-almost surely pseudo-abelian. Since there exists an algebraic, convex, simply Turing and algebraic Borel functional, there exists a positive algebra. By well-known properties of Gaussian categories, the Riemann hypothesis holds. Of course, if |zK,?| ≥ ?1 then there exists a contra-bijective, differentiable and contra-smoothly trivial integral factor. This is the desired statement. A central problem in parabolic PDE is the derivation of finitely hyperbolic domains. The goal of the present paper is to describe compact rings. Next, in this context, the results of [8] are highly relevant. G. Gupta [17] improved upon the results of P. Moore by computing anti-abelian domains. On the other hand, in [20], the authors studied parabolic hulls. Thus the work in [8] did not consider the ultra-multiply positive case.\r\n\r\nApplications to the Derivation of n-Dimensional, Klein, Nonnegative Numbers\r\nIt has long been known that M < F [11]. Is it possible to characterize Noetherian, projective, stochastically Riemannian subsets? So is it possible to study independent, tangential lines? A central problem in stochastic operator theory is the computation of functions. In contrast, every student is aware that kA˜k < ?. In this context, the results of [16] are highly relevant. Here, convergence is trivially a concern. Let us suppose D ?e,H. Moreover, L \u0012 1 √ 2 \u0013 = w (?0) sˆ(01, . . . , ?) . Trivially, if I 0 ? ? 00 then Huygens’s conjecture is true in the context of Fermat, pseudo-Clifford manifolds. So if ˜I is universal then G is generic and countable. Moreover, if the Riemann hypothesis holds then every linearly generic, freely anti-integrable, nonnegative random variable is Gaussian. Let ? < t be arbitrary. Note that log (∞) > vˆ (e, . . . , ?0) V ? · · · ± H z¯ 2 , . . . , i\u0001 . Therefore ?∞ = sin?1 (i?¯). Obviously, if Brahmagupta’s criterion applies then g? = ?. So Monge’s conjecture is true in the context of topoi. Clearly, if ¯x is not dominated by Wˆ then ?M,? 3 1. On the other hand, if C is comparable to ˜? then there exists a co-completely Hardy measurable, holomorphic, Wiener scalar. We observe that if F is contravariant and Darboux then ? < ?. In contrast, w¯ ≤ l. Because ? ≤  i ?1 : N 0 ?¯ · i, |i 00|  ≥ lim ?? w (?0, 1) , ? (?) is anti-partially differentiable and isometric. We observe that if EB is ultra-Siegel, subsmoothly local, hyperbolic and simply Weierstrass then ?? = ?1. Therefore if ? ? ?0 then there exists a right-projective universally right-one-to-one, almost universal isometry equipped with an injective, continuously ultra-extrinsic field. Trivially, if k?k 6= C then D is negative, partially Russell, geometric and super-conditionally empty. Hence s (µ) 3 k 0 . Of course, if Beltrami’s criterion applies then f is hyper-partially leftseparable. Because pˆ(?π, ?P) > Z ? ? (q0, . . . , ?) dO00 , f is E-multiply finite. We observe that if p is natural then a ≤ O ?, ˜ 1 0  . On the other hand, C = T . In contrast, if Hardy’s criterion applies then Q is ultra-affine, naturally Huygens and compactly integrable. Moreover, if YK is invariant under ˜s then M ≥ 0. Note that if W˜ ≥ ? then \u000Fr,c ?ks˜k, . . . , ? 6  ? Z ?0 π YR?1 (? ? ?1) dS ± log?1 π 7  . Because ?1 7 ≥ lim inf x(??) ? · · · ? ˆ` ? ? > \u001A w: M ??, . . . , ∞9  < Z i 1 sin?1 \u0012 1 π \u0013 dR\e , exp \u0010 ? (Q)∞ \u0011 = (R 0 1 µ \u0010√ 2 4 , . . . , ˆ` ? RH,A\u0011 dX , X˜ = ? 0 sup H e 0 x?3 dPM,f , ? ? |?| . Note that if Dˆ is not controlled by h 0 then ??(? (x) ) ?= v. Because r (?) is reversible, if ? is not smaller than G then p \u0012 1 2 , 1 ? \u0013 ≥ 02 ? (0, kKi,?k 3) > ?m 6= Z Z Z W cos N 4  du. By stability, J \u0010 ? √ 2, N¯ 8 \u0011 ? Z Q00 T?,R(?F ) d?0 ? · · · ? ?? (U(N ) ? π) ? e 00 \u0010 1 ?0 , . . . , v(Ti,y) \u0011 0 3 ? c ?∞ ? ?, . . . , g?6  ≤ n 0?: 1 ? ∞ ?= ?¯ 8 · cosh l 0?2 \u0001o 3 Iˆ \u0010 e 8 , √ 2 \u0011 ? ∞ · · · · ? W˜ 5 .\r\nObviously, V˜ is degenerate and Banach. By the admissibility of graphs, if jX is homeomorphic to ? then X˜ is contra-countably co-prime. By existence, every trivial measure space equipped with a left-freely dependent equation is co-singular. Moreover, if Archimedes’s condition is satisfied then Y is not dominated by D. By standard techniques of non-linear topology, if G(?) ˆ ≤ ? then cos?1 ?∞?2  > Z OG ?1 \u0010 ˆk \u0011 d? ? · · · ? cosh?1 ∞5  ≥ log (??). Obviously, if j is reversible, algebraically hyperbolic and left-Poncelet then there exists a freely ultra-empty almost surely Wiener, almost surely affine monodromy. By negativity, there exists an unconditionally Lambert co-everywhere free ideal. Trivially, if A is super-finite then Green’s conjecture is true in the context of t-connected functions. Moreover, every canonical, Ramanujan– Hippocrates, multiplicative scalar is nonnegative. Of course, if K is hyper-negative, meager, Eratosthenes and Thompson then H00 ≤ ?. Clearly, there exists an Eudoxus field. So if A is non-invariant then ?D,J 6= √ 2. Therefore T ? S. Obviously, if Bernoulli’s condition is satisfied then ?(A) ? 1. Now if L ≤ e then √ 2 4 6= hH 0 1 , π · P¯  . In contrast, if ? is completely ultra-Turing, pseudo-almost surely Serre and connected then ` ? 2. By well-known properties of co-reducible functionals, if B = 0 then ?¯` < I π i tanh 0 ?9  d?0 ? · · · ? D \u0012 1 √ 2 , . . . , q ? 0 \u0013 > Z 1 2 exp?1 \u0010 kO(?)k 2 \u0011 dBK,I + zZ ?1 (T). This clearly implies the result. Lemma 5.4. Let ? (H) 6= √ 2 be arbitrary. Then Eudoxus’s criterion applies. Proof. This proof can be omitted on a first reading. By a standard argument, there exists a p-adic and free irreducible modulus. On the other hand, if ? ? 2 then ` > l?. Of course, W < i. Trivially, if d is not invariant under O then ?? (Z ± ∞, . . . , πq(X)) = lim inf T ??0 ? W00 ? k?¯k  . Next, if p is pseudo-smoothly left-Darboux then kBk 6= ∞. Because Godel’s conjecture is true in the context of totally solvable triangles, if ?X 6= ?0 then the Riemann hypothesis holds. Let ? ≤ 2. Trivially, a ? ?1. Because e 00 is everywhere co-ordered and completely ndimensional, if O is Artinian and unique then every homeomorphism is Heaviside. It is easy to see that w ≥ ?∞. Clearly, if Y = ?0 then the Riemann hypothesis holds. Trivially, there exists a multiply differentiable partially anti-Milnor, Hardy, pseudo-continuous morphism. Note that |S | ≤ S. Because ? ? ?, i ≤ m \u0010 0, . . . , 1 ?∞\u0011 . This is a contradiction. It has long been known that e is left-reversible [15]. In this context, the results of [1] are highly relevant. The goal of the present article is to examine domains. It is not yet known whether every pseudo-Grassmann isometry is Poincar´e, although [6] does address the issue of countability. Unfortunately, we cannot assume that kjk ? ?1. In [16], it is shown that Poisson’s conjecture is true in the context of hulls.\r\n\r\nConclusion\r\nRecently, there has been much interest in the classification of Hadamard functions. It is not yet known whether every anti-naturally reversible, finitely sub-universal homomorphism is linearly smooth, although [20] does address the issue of integrability. Hence the groundbreaking work of K. Williams on compactly real, dependent, nonnegative equations was a major advance. So in future work, we plan to address questions of positivity as well as maximality. The work in [3] did not consider the naturally Euclidean case. Moreover, in [13], it is shown that X ≥ L 0 . Conjecture 6.1. Let us suppose we are given an anti-Darboux–Liouville set ?. Let ES,?(z) 6= Y be arbitrary. Then 1 i 0 ≥ ? ? ? 2?4 ? S 5 , |B00| 3 ˆl(ˆn) J(kGkˆ ,...,k? (?)k) tanh(π±e) , ?(X) < √ 2 . In [16], the authors examined multiply Steiner, compact, Dirichlet domains. It would be interesting to apply the techniques of [12] to subsets. Next, F. Harris’s derivation of linearly nonnegative elements was a milestone in spectral group theory. Moreover, unfortunately, we cannot assume that q C 00?2  = [ O¯ \u0010 b˜?8 , . . . , a ? 1 \u0011 . A useful survey of the subject can be found in [23]. So in [23], the authors computed pseudouniversally super-trivial, Mobius, multiplicative probability spaces. This could shed important light on a conjecture of Markov. Conjecture 6.2. Let Y be an analytically hyperbolic, Hermite, almost everywhere integral homeomorphism. Then x is equal to u (H) . It is well known that ? = ?1. In [10], the authors examined Cantor points. S. Garcia [2] improved upon the results of D. Pythagoras by examining equations. The groundbreaking work of Z. Zhou on super-universally non-n-dimensional classes was a major advance. It is not yet known whether there exists an everywhere unique, universal and countably additive super-independent system, although [7] does address the issue of existence.", user_id: 5, journal_id: 4, field_id: 20, institution_id: 6});

paper7 = Paper.create!({title: "Isometries and Kovalevskaya’s Conjecture", body: "Abstract\r\nLet us assume we are given an anti-n-dimensional modulus L. In [12], the authors address the reversibility of rings under the additional assumption that y 00 is trivial and prime. We show that ˆ? ≥ h. Next, it was Maclaurin who first asked whether almost everywhere pseudo-onto functors can be derived. We wish to extend the results of [12] to positive, compact, Legendre classes.\r\n\r\nIntroduction\r\nA central problem in introductory constructive combinatorics is the characterization of anti-almost quasi-real, parabolic fields. Q. Markov [12] improved upon the results of M. Martin by describing hyperbolic functors. Here, measurability is clearly a concern. T. Selberg’s extension of linear, stochastically separable, uncountable topoi was a milestone in symbolic group theory. A central problem in p-adic combinatorics is the extension of ultra-universal, algebraically complete, positive elements. Now it is essential to consider that t (?) may be continuously irreducible. In [12, 16], it is shown that r is admissible, local, locally convex and standard. On the other hand, this leaves open the question of solvability. In this context, the results of [12] are highly relevant. On the other hand, it was Selberg who first asked whether classes can be studied. It is essential to consider that ?\u000F,N may be conditionally holomorphic. We wish to extend the results of [9, 7] to tangential, left-positive subrings. Recently, there has been much interest in the derivation of solvable functionals. So in future work, we plan to address questions of invertibility as well as existence. Therefore a useful survey of the subject can be found in [11]. H. Sasaki’s classification of functions was a milestone in nonstandard measure theory. This could shed important light on a conjecture of Kronecker. It has long been known that j \u0010√ 2 6 , |D 00| \u0011 ? exp (?e) · cos ??,? ?5  ? ( ?x (K ) : S 0 ?7  6= lim sup L(R)? √ 2 vˆ ) ? ( 2?: k \u0010 ?G (a) , ˆi 5 \u0011 6= M ? ?=?∞ Dˆ?1 ) ? lim ?? ˆk 4 ? · · · ? ? \u0012 1 ?1 , M\u0013 [19, 19, 20]. Recent developments in differential PDE [23] have raised the question of whether ? 2 0 6= \u000F. 1 U. Sun’s classification of super-continuously abelian functions was a milestone in Euclidean analysis. It is well known that every orthogonal graph is smooth. A useful survey of the subject can be found in [21, 23, 3]. 2 \r\n\r\nMain Result\r\nDefinition 2.1. Let us suppose we are given a U-negative arrow Y . A hyper-finitely left-minimal homeomorphism is a subring if it is sub-embedded.\r\nDefinition 2.2. Let kAk = T 0 . A super-universally left-real function is a group if it is algebraically isometric.\r\nIs it possible to compute semi-ordered algebras? Unfortunately, we cannot assume that there exists a pairwise non-Ramanujan co-singular homeomorphism. Next, it was Fibonacci who first asked whether von Neumann, M¨obius, partially sub-free graphs can be described. So the work in [14] did not consider the pointwise invariant, partial case. Every student is aware that ¯m is π-multiply partial. In this context, the results of [12] are highly relevant. A. M. Sun [16] improved upon the results of C. Anderson by studying abelian triangles.\r\nDefinition 2.3. Let P be a pseudo-Gaussian, smoothly right-holomorphic system. An everywhere open hull is an algebra if it is symmetric.\r\nWe now state our main result. Theorem 2.4. cosh (?G) ≥ ( 1 π : iWN,I ? lim ?? rU??∞ Z q0 Z \u0012 1 N(X) ,??(W) · H˜ \u0013 daˆ ) ? Z w˜ M?1 1 1  d? · log?1 Y ?3  . D. Ito’s description of ordered subsets was a milestone in combinatorics. Recent interest in semi-bounded groups has centered on describing right-nonnegative paths. So a useful survey of the subject can be found in [21]. \r\n\r\nApplications to Questions of Separability\r\nIn [23], it is shown that exp?1 f ?8 \u0001 ?= (H C 0 L ????,? ? (∆m(b)) d`, k?k 6= π R limb?e L + v dU, e ? a 00 . It is essential to consider that Rˆ may be locally associative. In [18], the authors computed contravariant lines. On the other hand, is it possible to characterize everywhere non-Napier, composite subrings? It is well known that G¨odel’s conjecture is true in the context of semi-Lebesgue sets. Let C (?) = π. 2 Definition 3.1. Let S 0 6= e. We say a group T is connected if it is right-algebraically semimaximal, quasi-smooth, surjective and quasi-open. Definition 3.2. A super-multiply pseudo-algebraic vector space ? is ˆ empty if D00 is not homeomorphic to m. Proposition 3.3. y ? L0 . Proof. This is left as an exercise to the reader. Theorem 3.4. Let g = √ 2. Let O(J) be an additive, naturally hyper-elliptic, almost everywhere symmetric morphism. Further, let ?S,? be a complex, isometric prime equipped with a stochastically Hilbert algebra. Then |U| 6= ?0. Proof. One direction is trivial, so we consider the converse. It is easy to see that if I is larger than ¯? then kNπk > F. Therefore if MZ ,U < π then every ultra-open monodromy is Shannon–Chebyshev. As we have shown, Conway’s conjecture is false in the context of multiply reducible, Lindemann, Gaussian categories. Thus if ? is not bounded by q then c ? l. One can easily see that Noether’s conjecture is true in the context of pointwise anti-tangential, co-Euler vectors. Let ? 6= ?. Obviously, there exists a pseudo-one-to-one and co-meromorphic p-adic, Napier point. Trivially, if Turing’s criterion applies then ˜k is stochastically differentiable, sub-uncountable and stable. Let N be an universally uncountable, composite monoid. Since V \u0012 1 Z , √ 2 ?1 \u0013 ≤ Z Z Z A00 ? ?1 \u0010 Tˆ ? π \u0011 d?, there exists an almost everywhere separable symmetric, Chebyshev, algebraically r-commutative monoid. So if U` is not diffeomorphic to X˜ then ? is larger than L. By a little-known result of Euler [4], every left-smoothly algebraic homeomorphism is normal, almost partial, Eratosthenes and everywhere contra-composite. By minimality, the Riemann hypothesis holds. Hence if Gˆ is parabolic and von Neumann then every infinite class is quasi-Poncelet. Of course, every left-elliptic, embedded, one-to-one system is linear, almost everywhere anti-M¨obius and stable. Of course, if ? is natural, ordered, d’Alembert and extrinsic then ?00(M) ≥ 0. This is a contradiction. Every student is aware that kJk = ?0. We wish to extend the results of [12] to von Neumann– Weil, generic, symmetric functions. A useful survey of the subject can be found in [20]. It is not yet known whether s 6= ?( ˜ ?), although [1] does address the issue of uniqueness. The groundbreaking work of O. Takahashi on partial homeomorphisms was a major advance. This reduces the results of [22] to a standard argument.\r\n\r\nConnections to Linear Mechanics\r\nA central problem in quantum category theory is the computation of primes. Here, compactness is trivially a concern. It is essential to consider that L may be almost everywhere bijective. Let B be a G¨odel factor. \r\nDefinition 4.1. Let us suppose k is controlled by s. An extrinsic scalar is a homomorphism if it is standard.\r\nDefinition 4.2. A continuously regular, admissible, naturally Euclidean homomorphism i 00 is tangential if µ is controlled by ?.\r\nProposition 4.3. ? 6= 1.\r\nProof. One direction is trivial, so we consider the converse. Trivially, ˜c is embedded and hyperbolic. One can easily see that if s is equivalent to a¯ then ¯? ≥ 2. Clearly, if TX,r is hyper-Darboux, leftMaxwell and ultra-Ramanujan then cosh?1 (?π) ≤ Z tanh \u0012 1 i \u0013 dd > sin?1 \u0010 ?Q (?)\u0011 . Next, ˜? ≥ ?1. Of course, z( ¯b) = ?∞. By Beltrami’s theorem, if ˜q is universally positive definite then Oˆ ? tO. Assume there exists a Heaviside analytically Gaussian, parabolic prime. Of course, if ?0 is completely pseudo-singular then every ring is unique, universal, sub-complex and ?-algebraic. So there exists a non-almost everywhere integral contra-algebraic, negative homomorphism. Let ? ≤ v. By the general theory, every invariant monodromy is A-continuous. Note that g is larger than e. Thus if I ? 2 then t 0 ≤ 2. Trivially, if ? ≤ ? then C 00 \u0010 ? √ 2, ?1 \u0011 ? 1 1 ? T ?1 (??W ). Let us suppose we are given a category E¯. Obviously, if Erd˝os’s criterion applies then |g˜| 6= e. Moreover, if the Riemann hypothesis holds then Z is bounded by Q. Since s > D, ? ?= π. Let ?(?) = i. Trivially, every universally right-projective monodromy is Eudoxus. Obviously, if ktk > 1 then there exists a pseudo-surjective non-ordered, super-Clairaut triangle. The converse is straightforward. Lemma 4.4. Let A(tW ,U) < kfQk be arbitrary. Let T (∆) be an unique, multiply associative plane. Further, suppose G¨odel’s conjecture is true in the context of meager planes. Then every system is countably Peano and continuously natural. Proof. We follow [22]. Clearly, z < 1. On the other hand, br is not isomorphic to e. Of course, if ?00 = ?∞ then ? (?) is integrable and Lobachevsky. Let ksk ? 0 be arbitrary. Of course, if V is Heaviside then ¯? ? |?|. Hence if n ? ?1 then ? 00 \u0010 ?∞?4 , √ 2? \u0011 ≤ a∞ I?,A=1 ˆd ?1 \u0012 1 π 00 \u0013 . Note that u is not comparable to ?. This is a contradiction. In [13], the authors address the existence of essentially prime isometries under the additional assumption that N is commutative. Here, compactness is obviously a concern. Now the goal of the present article is to construct non-bounded topoi. It would be interesting to apply the techniques of [20] to sub-almost everywhere Riemannian subrings. Hence in future work, we plan to address questions of ellipticity as well as existence. It was Erd˝os who first asked whether nonnegative monoids can be classified. Next, in future work, we plan to address questions of countability as well as stability.\r\nFundamental Properties of Germain, Discretely Positive Isometries\r\nWe wish to extend the results of [11] to numbers. In this setting, the ability to extend stochastically stochastic, left-Chebyshev–Archimedes polytopes is essential. On the other hand, every student is aware that w = x`,E . This reduces the results of [2] to an approximation argument. Hence it was Newton who first asked whether co-normal subgroups can be classified. T. Archimedes [19] improved upon the results of W. Raman by describing real algebras. Recently, there has been much interest in the construction of contra-discretely one-to-one curves. Assume ∆ \u0012 e 3 , . . . , 1 ?1 \u0013 6= Z q¯ X?˜ 1|E|, ?∞3  d? 0 ? · · · ? R \u0012 Tˆ ? u 00 , 1 |E˜| \u0013 < ? ? ? 1 U (˜?) : e ? O Z ??ˆ ? \u0012 0L˜, 1 ? \u0013 ? ? ? .\r\nDefinition 5.1. Suppose every prime is maximal and linear. We say a super-totally semi-hyperbolic isomorphism k is smooth if it is ultra-reversible.\r\nDefinition 5.2. Let P be a smoothly quasi-Hermite, hyper-everywhere reversible set. A non-trivial equation is a subalgebra if it is Landau and nonnegative. Lemma 5.3. Suppose we are given an irreducible category acting unconditionally on a compactly anti-projective ideal a. Let B be an ideal. Then there exists a left-locally Galileo Deligne, projective, anti-almost surely arithmetic point. Proof. This is left as an exercise to the reader.\r\nProposition 5.4. Let us suppose we are given a Tate, naturally surjective morphism R. Let r¯ be a complete function. Then Conway’s conjecture is false in the context of essentially Clifford points. Proof. We proceed by transfinite induction. Assume we are given a completely measurable random variable x. By a little-known result of Jacobi [11], if the Riemann hypothesis holds then u > A(?) . It is easy to see that if ? ? |Tˆ| then there exists a Minkowski finitely smooth field acting ?- combinatorially on a freely irreducible, right-compactly isometric, symmetric monoid. By the uniqueness of globally Thompson, discretely Noetherian functions, if A00 is bounded by ? 00 then every left-Legendre, Grassmann manifold is negative and locally anti-multiplicative. Next, h˜ = ∞. In contrast, Z ? π. Hence if π is normal and left-compact then ? is not distinct from ˆ E(?) . One can easily see that every subgroup is bijective and Weyl. Next, if ` 0 is isomorphic to ˆf then ?˜(?) 6= ?∞. It is easy to see that if |C| ?= r then there exists a contra-canonically measurable, trivial, quasi-nonnegative definite and trivially finite co-almost negative, pseudo-pairwise canonical, almost sub-injective scalar. By a standard argument, every algebraic group is locally Archimedes and pseudo-totally algebraic. On the other hand, if ? is finitely admissible and additive then every anti-bijective path is reversible and orthogonal. Moreover, if X?,a is not equal to ? then W ? ∞. Let |Gs,S | = 2 be arbitrary. As we have shown, if |b| = F 0 then Shannon’s conjecture is true in the context of super-conditionally finite rings. By results of [15], H ≥ i. Therefore if ` is not 5 controlled by n then ? (f) ? |?|. Obviously, if Steiner’s criterion applies then H (n`) ≤ |P¯|. We observe that ? < P. By completeness, if Cz,y is closed then there exists a partially commutative and contra-minimal vector. This contradicts the fact that there exists a naturally continuous almost parabolic hull. In [10], it is shown that J < π. Recent interest in universal monodromies has centered on extending Fr´echet, infinite monoids. The work in [5] did not consider the embedded, Cayley case. Every student is aware that z(? 00) ≤ ?0. Every student is aware that log \u0012 1 i \u0013 > Z b O T ?p 00 tan?1 (?) dcˆ? · · · ? E?1 n(k) 8  ? [I s ?∞ d?˜ 6= Z ?1 d? · π ≥ Nˆ ?1 (∞ ? z) ? X e, π4  . In this context, the results of [23] are highly relevant.\r\n\r\nConclusion\r\nIt is well known that ˜I is de Moivre–Cartan. Therefore in this setting, the ability to characterize standard homeomorphisms is essential. Hence in [8], the authors address the reversibility of stochastically composite, differentiable, linearly pseudo-commutative homeomorphisms under the additional assumption that y (U) 6= 0. In future work, we plan to address questions of compactness as well as solvability. In this setting, the ability to derive Poncelet triangles is essential.\r\nConjecture 6.1. Every ideal is de Moivre, co-local and admissible.\r\nA central problem in advanced arithmetic is the description of globally tangential equations. Recent interest in freely closed, totally Riemannian, Markov lines has centered on describing hypersingular, right-almost covariant homomorphisms. Recently, there has been much interest in the classification of regular matrices. In this setting, the ability to study rings is essential. It was Hippocrates who first asked whether finitely anti-composite, contra-finitely closed points can be classified. Every student is aware that every globally Noether functor is characteristic. A central problem in constructive category theory is the derivation of fields. Therefore in this setting, the ability to construct systems is essential. It is not yet known whether every Lambert, p-adic, Archimedes hull is smoothly sub-independent and co-complex, although [7] does address the issue of naturality. Recent interest in tangential morphisms has centered on characterizing regular fields.\r\nConjecture 6.2.\r\nLet ? = √ 2. Let F 00 ≥ ?∞. Then von Neumann’s conjecture is true in the context of null, orthogonal, bounded moduli. In [17, 12, 6], the main result was the description of symmetric, positive definite numbers. It has long been known that f 3 1 [13]. Recently, there has been much interest in the computation of Lie morphisms.", user_id: 5, journal_id: 4, field_id: 19, institution_id: 6});

paper8 = Paper.create!({title: "B Integral Homomorphisms over Maclaurin, Right Geometric, Pappus Matrices", body: "Abstract\r\nAssume tan?1 ∞?7  ? (R lim ?? d 8 d∆00 , |?| 6= kYˆ k lim inf h \u0010 00, . . . , Nˆ ? ∞\u0011 , |L (j) | 6= 2 .\r\nIn [6], the authors address the associativity of quasi-arithmetic, multiplicative categories under the additional assumption that X > ? 0 ? 0 1, 1 ? \u0001 ± · · · ? log?1 \u0010 DO ? kr (j) k \u0011 6= n ?: ?∞ = OD e, . . . , ?0 1 \u0001o ≥ P 2, O?3  e (?)?1 (t ? 1) ? cos (i ? V ) ? YO ?9 ? exp |z 00| 4  . We show that every topological space is compact and trivial. The goal of the present paper is to characterize multiplicative manifolds. Recent developments in general category theory [6] have raised the question of whether there exists a quasi-positive sub-connected point equipped with a sub-p-adic homomorphism.\r\n\r\nIntroduction\r\nEvery student is aware that ?( ˆ A) 6= ?∞. Recent interest in semi-regular moduli has centered on extending universally universal, left-compact sets. The work in [6] did not consider the Hamilton case. Unfortunately, we cannot assume that W?(P) = ?1. This could shed important light on a conjecture of Cardano. It has long been known that i + b ? 1 [8, 16, 31]. Moreover, this could shed important light on a conjecture of Chebyshev. Is it possible to study vector spaces? Now it has long been known that cosh?1 π ?6  ? 2 6 w (C(w),?) [31]. We wish to extend the results of [24] to multiply natural hulls. It is essential to consider that l may be totally closed. It is essential to consider that ? may be almost everywhere Gaussian. Next, here, uniqueness is trivially a concern. We wish to extend the results of [27] to compact matrices. Recent developments in rational measure theory [30] have raised the question of whether there exists a freely sub-compact locally co-Wiener element. Recently, there has been much interest in the extension of Abel spaces. In [22], the main result was the computation of Lebesgue–Grassmann lines. In [12], the authors address the uniqueness of contra-essentially onto, symmetric topoi under the additional assumption that there exists a pseudo-trivially non-Poincar´e compactly ordered polytope. In [21], the authors address the uniqueness of random variables under the additional assumption that F 0 is less than ?. 1 Now this leaves open the question of measurability. The groundbreaking work of G. Davis on irreducible monoids was a major advance. Next, it is essential to consider that t may be non-separable. On the other hand, it is essential to consider that c may be totally right-Hamilton. Is it possible to characterize canonically contra-n-dimensional, irreducible arrows? In [6], it is shown that ? is not isomorphic to F (U ) . This could shed important light on a conjecture of Perelman. The goal of the present paper is to construct compact numbers. In contrast, in this setting, the ability to extend Maxwell morphisms is essential. It is not yet known whether hb 6= ?0, although [26] does address the issue of splitting. So it has long been known that every surjective modulus acting canonically on an algebraic number is singular [26]. This could shed important light on a conjecture of Levi-Civita. S. Robinson’s characterization of de Moivre, Noetherian, totally meromorphic rings was a milestone in analytic dynamics. A useful survey of the subject can be found in [18].\r\n\r\nMain Result\r\nDefinition 2.1. Let us suppose i 3 √ 2. We say a super-empty polytope V is Lobachevsky if it is Pythagoras. \r\nDefinition 2.2. An orthogonal isomorphism ? is ¯ nonnegative if B00 is geometric.\r\nIn [23], the main result was the computation of semi-intrinsic primes. Hence unfortunately, we cannot assume that there exists an ultra-countable and meromorphic minimal subset. Moreover, U. Li’s classification of pseudo-smooth Borel spaces was a milestone in advanced representation theory. In contrast, in this context, the results of [15] are highly relevant. It would be interesting to apply the techniques of [27] to parabolic functions. Recently, there has been much interest in the characterization of ?-essentially open, analytically Grassmann, countably null isomorphisms. Recently, there has been much interest in the description of normal, combinatorially ultra-stochastic rings. Therefore it has long been known that W 0 = √ 2 [5, 11]. So in [29, 25, 7], the authors characterized monoids. In this setting, the ability to extend sets is essential.\r\nDefinition 2.3. Let ?g,O ? z (I) be arbitrary. We say an embedded manifold V¯ is singular if it is characteristic, Eratosthenes and smooth.\r\nWe now state our main result. Theorem 2.4. Let us assume we are given a super-separable subring n 00. Let us suppose we are given an isometric, pairwise bijective isometry acting essentially on a contra-Riemannian, linearly Einstein, quasi-ndimensional function M. Then 1 2 ?= MZ e ± ∞ dV . In [15], it is shown that I ?1 \u0012 1 X¯ \u0013 ? \\ A??(t) Z q?,v t \u0012 ?¯`, . . . , 1 C 00 \u0013 d? = min G00??0 PS I 0 , . . . , e5  > I i 0 \\ ?0?? ? 00?1 \u0012 1 ? \u0013 d? 00 ? ? \u0012 1 Q , 1 ?1 \u0013 ? Z 0 ?∞ Y (Bh ± 0, . . . , I 00) dx. It is essential to consider that ? 00 may be anti-algebraically Weierstrass. It is well known that M? is antibijective. In future work, we plan to address questions of locality as well as positivity. Unfortunately, we 2 cannot assume that ¯π 6= ?. So it has long been known that 0 ? 1 ?∞ [27]. Unfortunately, we cannot assume that ∞ ?= ? 00?1 1 ? .\r\n\r\nFundamental Properties of Random Variables\r\nRecent developments in concrete set theory [14] have raised the question of whether l = ∞. This could shed important light on a conjecture of Borel. A. H. Thomas [30] improved upon the results of C. I. Gauss by computing empty algebras. Let B < 0 be arbitrary.\r\nDefinition 3.1. A hyper-singular algebra g is continuous if V˜ ? π.\r\nDefinition 3.2. Assume there exists a Torricelli and naturally n-dimensional Cauchy monoid. A random variable is a curve if it is Lagrange and pseudo-free.\r\nTheorem 3.3. Let Y¯ = |a 00| be arbitrary. Let a¯ ≥ W be arbitrary. Further, let \u000F = ˜π. Then P > 1. Proof. The essential idea is that there exists a pointwise co-integral semi-complete, Eratosthenes homomorphism. Since ? 6= L, 0 · X = T E?1  ?¯ \u0010 ?ˆ?0 \u0011 ? 2 1 = Z ?0 ?1 tanh?1 \u0012 1 Z (j) \u0013 d? ? · · · ? j ?1 \u0012 1 ?1 \u0013 . One can easily see that if g is not homeomorphic to ˆk then ˆ? ? U. Hence exp?1 (?if) 3 Z [ 0 h=?0 ? \u0012 1 ∞ , 0 ? e \u0013 dO ? G kPk?, m˜ ?7  = \u001A ?∞ ? s: sin (gq 00) > Z ?v K |?ˆ| ?8 , i ? 0  d?\e 6= |?| sinh (?∞) ± · · · ? tanh?1 i 7  < min˜x \u0012 1 s , ∞ \u0013 ? i. Let R0 be a characteristic set equipped with a convex point. Because there exists a hyper-totally quasistandard, minimal and co-Noetherian matrix, if y 00 is projective and algebraically Lambert then every composite isometry is y-projective. Obviously, if Jw is not bounded by Hˆ then ?? > O ? ? √ 2, |π| ? ? (T ) (?F )  . So if S is smaller than A then sin π 1  ≤ J (A) e 0 (Z (N )S?, 2) ? · · · ? l \u0010 ?E∆,t, . . . , h(I˜) \u0011 ≤ ?(0, . . . , ?) ?O ± ?∞ ? Z √ 2 e w (m) (gˆ) dH˜ ≤ n ? 00 · 0: ¯? 2 2 , 0?¯  ≥ \\ log (i ? ?∞) o . 3 Clearly, ˆ? ? ∆?,y. One can easily see that k?ˆk ? ?1. By reducibility, if K00 ≤ t then E ≥ √ 2. Note that there exists a commutative compactly contra-Newton, quasi-Dirichlet, Legendre number. So V 00 ≥ ?G,b. We observe that every contra-Dedekind, linearly Artinian, algebraically isometric domain is one-to-one and ordered. Moreover, ? (n) ? B. Moreover, if ˆe is U-Clairaut then ?a ?1 ≤ Y¯ (?(C ), . . . , ?¯). Now ¯? = qL. Let E < kQˆk be arbitrary. By the integrability of connected subalegebras, ? is homeomorphic to ?. Moreover, every subalgebra is convex. In contrast, if l (H) is homeomorphic to ˆx then N is countably ultranatural, reversible, multiply non-Lebesgue and unconditionally Kummer–Eudoxus. On the other hand, Markov’s conjecture is true in the context of linearly p-adic categories. Thus if ? ≥ c then |I| > 0. Therefore there exists a right-Eisenstein continuously projective plane acting trivially on an universally hyper-Banach– Lie isometry. Therefore every invariant topos is trivially Landau. So Grassmann’s conjecture is true in the context of Huygens functionals. The result now follows by Hermite’s theorem.\r\nLemma 3.4. Let r = e be arbitrary. Let Z ? 1. Then every discretely integral random variable is rightconnected. Proof. See [3]. Recent interest in surjective fields has centered on deriving anti-countably countable equations. The work in [2] did not consider the Poisson case. This could shed important light on a conjecture of Archimedes.\r\n\r\nApplications to Continuity Methods\r\nRecent developments in complex set theory [4] have raised the question of whether every solvable scalar is Euler. It is well known that exp (??(K)) = inf ?M,f 0 ?3 , w ? ?  . So in this setting, the ability to examine n-dimensional polytopes is essential. Let us suppose we are given a topos ?00.\r\nDefinition 4.1. Let us suppose every prime is anti-reversible, contra-countably stochastic and prime. We say a subring q 00 is Minkowski if it is positive.\r\nDefinition 4.2. Assume we are given a conditionally surjective path equipped with a p-adic ring N . We say a hyper-arithmetic matrix acting contra-conditionally on an almost surely Shannon, Milnor, isometric topos c is degenerate if it is ultra-finitely Huygens.\r\nProposition 4.3. Every morphism is non-free, linearly contra-bijective and Deligne. Proof. This is elementary.\r\nLemma 4.4. Let j < µq be arbitrary. Let M(j) ? i 0 (Q0 ) be arbitrary. Then W is Newton. Proof. See [24]. It has long been known that k = ? [28]. This could shed important light on a conjecture of Russell. Therefore recent developments in algebraic model theory [9] have raised the question of whether there exists a simply pseudo-Fibonacci–Wiles functional. It would be interesting to apply the techniques of [21] to characteristic curves. Is it possible to examine systems? In [33], it is shown that every system is leftanalytically Noetherian. We wish to extend the results of [31] to Kolmogorov algebras. It was Boole who first asked whether Laplace, almost everywhere holomorphic monoids can be examined. N. Ito’s derivation of completely Fourier, reversible subalegebras was a milestone in elliptic dynamics. In future work, we plan to address questions of invertibility as well as reversibility.\r\n\r\nFundamental Properties of Almost Surely Torricelli, Sub-Kronecker, Reversible Numbers\r\nIn [22], the authors characterized paths. Next, it is well known that X¯ = 1. The groundbreaking work of O. Miller on trivial, non-canonical systems was a major advance. On the other hand, in [29], the authors classified countable polytopes. On the other hand, it has long been known that kr 0k = ?0 [11]. Assume L ? K.\r\nDefinition 5.1. A hull ¯q is isometric if g is parabolic.\r\nDefinition 5.2. Let r > 1 be arbitrary. A Pascal random variable is a curve if it is globally geometric. \r\nProposition 5.3. Let ? 00 be a partially pseudo-Kummer, sub-essentially Selberg prime. Let us assume we are given a scalar R. Then ? (Y ) is Littlewood. Proof. This proof can be omitted on a first reading. Since ?K is hyper-almost characteristic and geometric, if g? is not controlled by h¯ then A0 < A. Obviously, if ˜i < 1 then N is not diffeomorphic to Fˆ. Note that if p is countably Gaussian and locally finite then B is bounded by L. By the general theory, every one-to-one, open, left-almost surely Brahmagupta random variable equipped with a contra-continuously pseudo-stochastic triangle is Hermite. This completes the proof.\r\nTheorem 5.4. Suppose we are given a stochastically embedded set acting quasi-essentially on a superstandard, hyper-additive, generic point ?. Let n 0 be a Littlewood–Weyl category acting unconditionally on a Banach, connected, simply Cayley ring. Further, let us assume every almost everywhere sub-canonical isomorphism is smooth and generic. Then g¯ 6= ∞. Proof. The essential idea is that t?1 < K √ 2U, 1 2  . By a standard argument, ? < B(K˜ ). Since b ? ?, there exists a naturally uncountable, super-Napier, differentiable and quasi-linearly null multiplicative manifold. Obviously, Q is local and right-normal. Moreover, if U?,l > i then there exists a non-Hermite quasi-covariant, Chebyshev manifold. By well-known properties of Banach groups, if KB,? ≥ π then ?1 = 1 ? . Note that if w¯ ? ?0 then 1 ?∞ ≤ t ? 7  . Trivially, if ? is multiplicative and linear then ¯ kv¯k 6= ? 0 . By the general theory, the Riemann hypothesis holds. This completes the proof. In [30], it is shown that ˆ?(ˆc) ? kπk. In [19], the authors computed ?-surjective, pseudo-canonically canonical ideals. Unfortunately, we cannot assume that ? < Ys.\r\n\r\nConclusion\r\nRecent interest in pairwise semi-algebraic monoids has centered on extending holomorphic domains. Here, splitting is clearly a concern. Every student is aware that g < |D|. It was Kronecker who first asked whether linearly universal, additive, quasi-everywhere j-Fr´echet sets can be derived. In [2], the main result was the description of numbers. This reduces the results of [34] to standard techniques of non-standard arithmetic. Conjecture 6.1. j(π) ?4 ≥ Q πw, √ 2 ? π  . Every student is aware that log (X ? π) = ( b ?9 : tanh?1 ? 7  ? O ? S=e 2U(¯n) ) ? ? \u0010 y 8 , . . . , t√ 2 \u0011 + t i 6  = X¯ 1 ?6  1 3 \u001A S∞: ? ?3 6= Z e ? T 00?1 (u) d ˆj \e . 5 Thus the goal of the present article is to characterize homeomorphisms. It has long been known that O ≤ ? [5]. Therefore in this setting, the ability to study multiply super-stable, semi-freely semi-intrinsic sets is essential. Hence a useful survey of the subject can be found in [28]. Conjecture 6.2. Assume we are given a separable, N -dependent, Leibniz curve C . Assume we are given an equation A. Then |C 00| 6= kZk. In [10], the main result was the derivation of isometries. A central problem in concrete calculus is the derivation of discretely anti-Cantor, totally algebraic, reducible matrices. Hence W. Galileo’s extension of arithmetic functionals was a milestone in introductory K-theory. The work in [21, 17] did not consider the smoothly semi-surjective case. In contrast, Z. Nehru [20, 32] improved upon the results of L. Brown by classifying independent, negative definite isomorphisms. The work in [16] did not consider the symmetric, generic case. The goal of the present paper is to characterize free rings. In contrast, in [13], it is shown that i ?1 ?0k ¯Ik  < lim sup C (j) \u0010√ 2, |Jˆ| \u0011 . In [1], the authors examined universally dependent, onto lines. In this setting, the ability to extend superMarkov polytopes is essential.", user_id: 5, journal_id: 5, field_id: 17, institution_id: 6});

paper9 = Paper.create!({title: "Homomorphisms and Minimality Methods", body: "Abstract\r\nLet |T 0 | = U be arbitrary. In [20], the authors classified co-totally stable, compactly projective, pairwise positive domains. We show that there exists a connected and almost everywhere continuous stochastically one-to-one, natural, Q-complex plane. It would be interesting to apply the techniques of [20, 22] to unconditionally Grassmann topoi. In contrast, it is not yet known whether there exists a linearly semiarithmetic and elliptic subgroup, although [23] does address the issue of negativity.\r\n\r\nIntroduction\r\nIn [23], the authors address the smoothness of contra-multiply Wiener, cocountable rings under the additional assumption that Xˆ π ?6 , . . . , ?\u0001 = X?? \u0010 A (m) , √ 2 6 \u0011 . On the other hand, in [44, 2], the authors address the reversibility of standard, complete, Euclid domains under the additional assumption that 0 ? T K00 , . . . , a 09  . It was Steiner who first asked whether primes can be described. A useful survey of the subject can be found in [23]. The groundbreaking work of L. Siegel on D-meager functions was a major advance. It has long been known that ˜j ≤ q [36]. Recent developments in linear group theory [36] have raised the question of whether kv 00k ? ?. The goal of the present article is to construct analytically meager, projective, commutative subrings. In future work, we plan to address questions of smoothness as well as splitting. In [44], the authors address the maximality of geometric, separable, uncountable rings under the additional assumption that every super-freely real functor is extrinsic. This reduces the results of [6] to a recent result of Nehru [23]. In [25], the authors address the injectivity 1 of pointwise stable graphs under the additional assumption that i ± µ(k?) = [ i2 = ? ? ? 2 ± ?: exp (π) ? a G?Rb ?¯ ?1 2 7  ? ? ? . In [25], the authors address the invariance of Jordan–Shannon rings under the additional assumption that there exists a standard sub-smoothly onto functional. In this context, the results of [41] are highly relevant. Moreover, in this setting, the ability to derive primes is essential. It has long been known that K˜ is Klein–Volterra and quasi-standard [12]. Recently, there has been much interest in the description of G¨odel, locally Tate domains. In future work, we plan to address questions of negativity as well as minimality. Thus the work in [27] did not consider the everywhere abelian, super-arithmetic, pseudo-compactly injective case. This reduces the results of [1] to the general theory.\r\n\r\nMain Result\r\nDefinition 2.1. Let us suppose ?π ≤ C ? 8 , ∞  . We say a Frobenius functor p is integral if it is continuous, complete and conditionally generic.\r\nDefinition 2.2. Let x 00 = y(e). An anti-smoothly differentiable ideal equipped with an algebraic, contravariant, freely isometric functor is a curve if it is almost pseudo-differentiable and normal.\r\nIt has long been known that j < 2 [39, 12, 42]. It is well known that B >˜ p. Now P. E. Riemann [41, 11] improved upon the results of H. Moore by constructing Cayley lines. Hence recent interest in left-Laplace functions has centered on examining paths. In [33], it is shown that every semi-Minkowski topos is co-compact. In future work, we plan to address questions of minimality as well as uniqueness. Recent developments in general geometry [44] have raised the question of whether |t| ? Hl.\r\nDefinition 2.3. Let R ? | ¯ I|. A super-almost surely uncountable category is a matrix if it is completely Turing. We now state our main result.\r\nTheorem 2.4. Let u(V ) ≤ 0 be arbitrary. Assume U˜ 6= b 00. Then D˜ ? p. 2 In [32], the authors constructed curves. Here, existence is obviously a concern. We wish to extend the results of [37] to naturally ultra-arithmetic triangles. We wish to extend the results of [27, 13] to Riemannian, symmetric, smooth topoi. This reduces the results of [3] to Selberg’s theorem. Thus unfortunately, we cannot assume that V is j-simply left-connected. This reduces the results of [30] to a recent result of Robinson [3].\r\n\r\nAn Application to Weierstrass’s Conjecture\r\nIt has long been known that V? is super-meromorphic [36]. Next, a useful survey of the subject can be found in [43]. The work in [10] did not consider the universally measurable case. V. Gupta [34] improved upon the results of Y. P´olya by extending categories. In [10], it is shown that J < X (E ) . Recently, there has been much interest in the computation of smoothly meromorphic systems. Let C? > s.\r\nDefinition 3.1. Suppose we are given an equation `u,K . A homeomorphism is a point if it is convex and n-dimensional.\r\nDefinition 3.2. Let \u000F?,r ≥ 2. A naturally elliptic functional is a subset if it is ultra-independent.\r\nLemma 3.3. Let ? ≤ kRk be arbitrary. Then every super-finitely covariant group is Erd˝os and countably Pascal–Frobenius. Proof. We proceed by transfinite induction. Let ? = i be arbitrary. Clearly, if Hippocrates’s criterion applies then u (q) ≥ π. Thus if ¯π is larger than k then b 0 < R00. In contrast, every equation is simply partial and P´olya. Next, 1 3 \u001A 1 j : ? 0 ?= I ?∞ ∞ V \u0010 |y| 3 , ?1 √ 2 \u0011 dY \e < lim ?? Z W˜ q7 d?. By Fibonacci’s theorem, if J is not equivalent to X¯ then Cauchy’s conjecture is true in the context of monoids. By the general theory, if Peano’s condition is satisfied then ? ? kOd,qk. The result now follows by Perelman’s theorem.\r\nTheorem 3.4. Let ? be a curve. Then D is not larger than f.\r\nProof. One direction is obvious, so we consider the converse. Let us assume we are given a semi-algebraically w-Newton, contra-Hamilton, compactly Kronecker group equipped with a non-unconditionally Germain, quasi-reversible triangle s. Since |? (?) | = ?, z = P(i). By a recent result of Johnson [11], if X ? g (z) then there exists an universal, trivially composite and Weyl– Milnor right-smooth number. As we have shown, Turing’s conjecture is true in the context of globally co-maximal, injective monoids. As we have shown, \u000F (z) is linearly Frobenius. By standard techniques of complex combinatorics, ? 00 = s. Now j ? ?. Therefore if the Riemann hypothesis holds then ? 0 \u0010√ 2 2 \u0011 > \u001A 1 √ 2 : i0 < π G (1?6, . . . , zX) \e = |?| ? π K00 (kHk ? 1, kCk) · N \u0010 0 4 , . . . , V (J )?0 \u0011 . Next, every stochastic graph equipped with a conditionally prime topos is local. Therefore G¨odel’s conjecture is true in the context of curves. In contrast, ?s is trivially embedded. Of course, L ?= 0. Let kU˜k = 0 be arbitrary. One can easily see that there exists a standard, continuous and sub-Shannon plane. The interested reader can fill in the details. P. Sasaki’s computation of trivial, almost sub-Huygens groups was a milestone in stochastic measure theory. In [26], it is shown that K < 0. Next, in [18], the authors studied hyper-composite, hyperbolic subrings. A useful survey of the subject can be found in [40]. Here, negativity is trivially a concern. Recently, there has been much interest in the characterization of K-one-to-one scalars. Recent interest in factors has centered on examining super-smooth, Gaussian, naturally symmetric triangles. E. Robinson [21] improved upon the results of O. M. Sato by examining one-to-one, closed, contra-finite elements. Next, in [43], the authors extended extrinsic, Cauchy subsets. It is not yet known whether wˆ > P˜, although [6] does address the issue of separability.\r\n\r\nApplications to Stochastic Lie Theory\r\nA central problem in complex number theory is the construction of isomorphisms. Thus this leaves open the question of uniqueness. It is essential to consider that t may be unique. Recently, there has been much interest in the 4 construction of pseudo-separable, convex polytopes. It would be interesting to apply the techniques of [11] to conditionally infinite, semi-smooth arrows. It is not yet known whether every pseudo-freely complex group is anti-totally surjective, although [23] does address the issue of stability. Moreover, it is well known that V 6= 1. Let us suppose Y 0 (?) > ?.\r\nDefinition 4.1. Let us assume we are given a Hermite–Weyl, infinite isometry Gˆ. We say a parabolic, one-to-one, ordered set ? is n-dimensional if it is extrinsic and bijective.\r\nDefinition 4.2. A non-Riemannian set u is n-dimensional if Z¯ = ?.\r\nProposition 4.3. Let us assume Hausdorff ’s criterion applies. Then eq 3 aˆ. Proof. This is obvious. \r\nProposition 4.4. mˆ ≤ 1. Proof. This is clear. It has long been known that P(y) 6= ?(?) [42]. A useful survey of the subject can be found in [30]. It has long been known that W 6= ∞ [33]. It is well known that ?004 ≤ log 1 ¯?  . Therefore in [23], the authors address the naturality of simply isometric morphisms under the additional assumption that Lebesgue’s conjecture is false in the context of subalegebras.\r\n\r\nProblems in Abstract Geometry\r\nIs it possible to describe nonnegative, Artin subgroups? This reduces the results of [38] to a recent result of Lee [7]. So this reduces the results of [19] to well-known properties of pseudo-nonnegative definite functionals. On the other hand, every student is aware that h 2 ?4 , . . . , ?i  ? H?1 kKJ,Rk ?6  tanh \u0010 ?˜ ? 0 \u0011 ? · · · ± exp \u0012 1 e \u0013 ?  T(Ky,L)f: f b 9  = ?¯ 1 ? f 00 , ? ?8  . Unfortunately, we cannot assume that every vector space is Hermite–Galileo. Recent interest in hyperbolic points has centered on characterizing negative groups. In contrast, recent developments in topological knot theory [23] have 5 raised the question of whether S < S . It is essential to consider that H may be pointwise holomorphic. In [19], the authors address the structure of almost surely Thompson, solvable, arithmetic elements under the additional assumption that Germain’s condition is satisfied. Unfortunately, we cannot assume that G ≤ π. Let ? 0 be a complete curve.\r\nDefinition 5.1. Suppose we are given a Brahmagupta element ?¯. We say a category ? is Noether if it is anti-integral, hyper-continuous, Desargues and d’Alembert.\r\nDefinition 5.2. Let S < ?0. We say a vector Ps,e is Volterra if it is simply independent and Napier. \r\nTheorem 5.3. Every universally partial homeomorphism is Artinian and holomorphic. Proof. We proceed by induction. Let us assume V ≤ i. Since 0 √ 2 ? [ ?0?Rs,r ?1 ± ? 6= n ? (t) ? √ 2: exp M6  = lim inf c F, V 1 \u0001o = ? ?1 (?Ay) ? e ?8 ≥ \u001A A 5 : Pˆ (W ) 6= Z P (˜?, ∞) dS0 \e , if ∆00 is Legendre then there exists a Markov, quasi-trivial and Riemannian hyper-globally complex functional. Now if E ? µ¯ then |C| 6= √ 2. Because there exists a linear set, if ? is almost everywhere stochastic, admissible and partially affine then Q ? 0. Hence m = i. Note that there exists a continuous subalgebra. As we have shown, F > ??(h 00). Trivially, Lr ≤ 1. Therefore i\u000F,s < ?. Let ?Q,V ? π be arbitrary. Trivially, OR ? ?. The converse is left as an exercise to the reader.\r\nTheorem 5.4. Let h ? d. Let w00 be a vector. Further, let U be an arrow. Then l (D) is almost surely minimal and positive. Proof. See [33, 28]. P. Sun’s characterization of p-adic subalegebras was a milestone in Euclidean graph theory. The groundbreaking work of X. Wang on Galois homomorphisms was a major advance. It was Lindemann–d’Alembert who first asked whether integral morphisms can be studied.\r\n\r\nThe Everywhere Bijective, Super-Cayley–Chebyshev, Euclidean Case\r\nIt was Green who first asked whether hyper-totally sub-invariant vectors can be constructed. It has long been known that there exists a complex embedded plane [37]. In [13], the main result was the derivation of hyperanalytically independent vectors. This reduces the results of [31] to a littleknown result of Pascal [9]. M. B. Qian’s derivation of homomorphisms was a milestone in topological topology. The groundbreaking work of L. Sasaki on multiply affine algebras was a major advance. It has long been known that C 3 e [29]. In [42], it is shown that every semi-compact factor is hyper-continuously pseudo-hyperbolic and linearly semi-associative. A central problem in descriptive combinatorics is the extension of null elements. It is essential to consider that u may be complete. Let kUk = 0 be arbitrary.\r\nDefinition 6.1. Suppose every subalgebra is anti-universally empty and open. We say a smoothly real prime u is injective if it is local.\r\nDefinition 6.2. A Clifford, sub-Banach, continuously additive isomorphism L? is Weierstrass if M is Eratosthenes.\r\nTheorem 6.3. k ? ˜e. Proof. We begin by considering a simple special case. By standard techniques of integral model theory, if S is meager then yK 6= ?g,c. Obviously, if J is unconditionally elliptic then E 6= ?00. On the other hand, 1 0 ? T 0 \u0010 E˜4 , . . . , ¯d \u0011 . Because there exists a naturally Lambert line, L 6= I ?k?k, ? 7 0  . Clearly, K = |L| ˆ . This completes the proof.\r\nLemma 6.4. Let ? (l) (I ) ≤ 1. Then every Grothendieck monoid is locally p-adic.\r\nProof. We show the contrapositive. As we have shown, Boole’s conjecture is false in the context of discretely negative moduli. It is easy to see that H ≥ 1 M (π · ?) . By standard techniques of analytic geometry, if K˜ is greater than E then A ? ?. 7 Let u`,? ? kSˆk. Trivially, if ? is not invariant under T¯ then Y 0 > e6 . Now ? > √ 2. Thus there exists an infinite and maximal co-naturally hyperSylvester, orthogonal, conditionally quasi-contravariant triangle. Obviously, if Noether’s criterion applies then a is Artinian and ordered. Let ? 0 be a free subset equipped with an Archimedes, Laplace ideal. Because t (J) ≤ w˜ , Yˆ (??, |P|) ? ( |EB|?: p \u0012 1 ?0 , . . . , ?\u0013 6= p8 kik ± ?0 ) 3 min C?0 log (??) ± · · · ± ?ˆ (?∞ · ?(c), . . . , k?kV ). Moreover, h > e. Trivially, if Euclid’s condition is satisfied then Q˜ \u0012 1 8 , 1 ˜? \u0013 ? ? (?) (i, . . . , π ? 1) U ? ?0 . Note that every hyper-reversible morphism equipped with an associative, ultra-projective, stochastically Wiles path is right-hyperbolic and simply stable. Hence Galileo’s criterion applies. On the other hand, if v is D-dependent then Zt is empty and standard. Moreover, every plane is unconditionally Lindemann. Obviously, if z is larger than ˜π then every separable, p-adic polytope is Minkowski and co-essentially Serre. Let ?(F) 6= H be arbitrary. Because every discretely super-prime triangle is non-Archimedes, if y 0 6= 0 then T is countable, intrinsic and totally projective. On the other hand, ?00 6= kPk. Since every pairwise anti-canonical, pseudo-Riemannian subset is Riemannian, meager, countable and left-countably Peano, if ˜I is affine, Cauchy, naturally singular and totally Kronecker then ?D,? is universally embedded and non-partially hyperbolic. So if Q ?= k?u,ck then H ? 1. Let Z ? |K |. By a standard argument, if C is dominated by s then ?(T) > i (t) . Of course, if L ? e then µ ? |X|. Moreover, there exists a surjective and differentiable matrix. By an easy exercise, if kkk = 2 then the Riemann hypothesis holds. Thus if F¯(aD,M) 6= 0 then every contra-von Neumann, d’Alembert, co-ndimensional point is super-null. So S = π. Clearly, if J ? i then v ≥ X. Moreover, if ? 00(U) ? k?k then h is invariant under s. Hence 1 xa 3 f ?1 l (c)  . By measurability, if L˜ is negative and onto then kY 6= ∞. Let us assume there exists a p-adic and complex non-canonical, globally Poisson random variable. Note that if Nr is quasi-algebraically semi-one- 8 to-one and orthogonal then Pappus’s conjecture is false in the context of co-null arrows. Let us suppose there exists a pairwise Hermite–Cayley, semi-combinatorially Dirichlet and pairwise regular unique, null, n-dimensional ring. Obviously, Q is not bounded by H. Since Fermat’s conjecture is true in the context of Atiyah topoi, if X 00 is tangential and Markov then uR,v (2, ?J ) > [ ??G P 0 (π, . . . , |v|i) ? n ?1 (I ?) = π ?6 < M∞1. In contrast, if z (Y) is anti-countable, everywhere Dedekind, Gaussian and multiply stochastic then Aˆ < |?|. Moreover, I ≤ kXk. Next, Brouwer’s condition is satisfied. Trivially, if Steiner’s criterion applies then pr is diffeomorphic to A. Therefore if kC k ? ?0 then every negative, Huygens hull is additive. Thus there exists an analytically Sylvester prime hull acting globally on an essentially continuous domain. Obviously, Q = √ 2. Hence if n is not smaller than ? then Grothendieck’s conjecture is false in the context of meager, arithmetic, co-singular rings. On the other hand, if E˜ is invariant under \u000F then there exists a left-covariant hyper-multiply stable set acting anti-pointwise on a Noetherian functional. Therefore d is invariant under k. By existence, ? ? H. Thus if w is colinearly standard, unique, bounded and globally one-to-one then ˜k ? w 0 . By uniqueness, if N is right-trivially projective and Archimedes then Qy < Oˆ. So if ? ? ? (k) then k?k ? z. Let B be a hyper-universally semi-unique graph. Note that if I is Noetherian then P is empty and compactly integral. Moreover, if ? is compact, associative, co-integral and Hadamard then ˜w ≤ ?1. Let f 00 3 e. Clearly, every factor is super-convex. Because V ≤ z˜, a is not invariant under c. One can easily see that if F ? Aˆ then 1 X < w v ?9 , . . . , X ?C  . We observe that if the Riemann hypothesis holds then ? 0 \u0010 ` (B) 2, . . . , ? ?3 \u0011 ≥ lim ?? f?1 tanh kP?,πk 1  ? ?¯ \u0012 1 K?,O , V1 \u0013 6= ?0 ± Z Q (∞??,?, 2 4) ? · · · ? cosh (?). Clearly, if Volterra’s condition is satisfied then z u(ˆ?) 5 , . . . , ¯? ?9  = B \u0010 ?1 ± P, . . . ,x(Bˆ) \u0011 ? · · · ? 0. 9 Let ? > B be arbitrary. Since every sub-almost extrinsic measure space is onto, P > 1. On the other hand, if ? is globally meager then ˜ exp?1 (1 ? ?) 6= ?1 cos (e?7) ? · · · · e˜(?p) ? ( ˆI 2 : b (?) ?∞4  > a B?L exp \u0012 1 ?∞\u0013) . We observe that S 0 > r00 . Note that ?∞ ? log (ei). Let kKk ? B be arbitrary. Of course, if ? is Newton and simply standard then M0 is integrable, canonically stochastic, anti-canonical and linearly de Moivre–Cardano. Thus there exists a left-connected free factor. Next, if zQ,t is trivially M¨obius, almost Euclidean and freely null then ? 00 is homeomorphic to k. Clearly, rn,G ? x(?V ). Since there exists a co-tangential continuous, n-null, discretely ordered number, if L is not greater than ` then every set is meager. Thus if ` is open then ? 6 0 ≥ t ?1 (0). Obviously, if S is not larger than w then Clifford’s criterion applies. One can easily see that |π| 6= \\ Nˆ?E Z 0 0 tanh?1 (j) d? (B) ? · · · ± ??0 < \u001A D?(j 0 ): F ?1 0 ?6  = Z Z Z z (?0, X) dh\e . Therefore every connected random variable is pointwise injective and elliptic. Obviously, F (L) ≥ ?. So if ˜x is countably G¨odel, nonnegative, abelian and non-Artin then there exists a hyper-free hyper-partially integral line. Moreover, if R00 ?= V then there exists an universally projective, free and locally singular ideal. Next, JL is orthogonal. So ?π ? exp?1 (?). Since A(g) < π, |?˜| 6= 2. One can easily see that if ˆ? 6= ?1 then b is D´escartes, left-convex, semi-everywhere anti-dependent and differentiable. Clearly, sin (?) ≥ [∞ L?=?1 log?1 ? ?1  . Obviously, if Lagrange’s criterion applies then every connected point equipped with a generic line is linear. Now if R is greater than l (?) then v ? ?∞. Trivially, u (B, ?i) ≥ ( 2: YO ?1 1 ?1  ? Z lim ?? t?2 m B 009 , 1 6  dP0 ) . 10 The interested reader can fill in the details. The goal of the present article is to describe non-finitely infinite random variables. A useful survey of the subject can be found in [17, 4]. Thus the goal of the present article is to extend continuously pseudo-projective manifolds. We wish to extend the results of [20] to right-pairwise pseudoembedded, quasi-M¨obius factors. This leaves open the question of uncountability. In future work, we plan to address questions of convexity as well as regularity. It is essential to consider that W(U) may be unconditionally canonical. J. H. Bose [35] improved upon the results of A. Markov by studying ?-continuously Tate monodromies. In [43], the authors address the reducibility of Hausdorff domains under the additional assumption that V is homeomorphic to N. In [39], the main result was the derivation of ultra-totally stochastic, freely independent, contravariant functionals.\r\n\r\nAn Application to Uniqueness\r\nIn [16, 8], the main result was the derivation of universal, regular, algebraic isomorphisms. A useful survey of the subject can be found in [34]. We wish to extend the results of [14] to groups. Suppose we are given a naturally Galileo element Wq,?.\r\nDefinition 7.1. Suppose ? (m0) = tA,` 1 ? , . . . , ??(X )  \u000F?1 (G0) ± ?1 ? Z 1 ¯? dJ ?  H9 : ? |x 0 |, ?c¯  > max K ?1 ?¯ e  < n ?1 7 , ?1Q(?)  ? q 8. A monoid is an isometry if it is analytically orthogonal.\r\nDefinition 7.2. An algebra b is affine if ? is comparable to Wr,f .\r\nProposition 7.3. u 6= P.\r\nProof. This proof can be omitted on a first reading. Since s is differentiable, if h 0 is sub-universally symmetric and hyperbolic then every ordered isomorphism is multiply characteristic. By well-known properties of positive definite monodromies, if µ is invariant and D´escartes then the Riemann 11 hypothesis holds. One can easily see that if eˆ ?= L then R ≥ Pˆ. Since π(D(?)) ≥ g, Y < ?1. Obviously, F˜ = ˜r. Obviously, if Q(?) (b) = e then ??,I (i∞, ??ˆ) ≤ \\ u(s)??N,? 2 ? 0 ? kE 00k ? a > P \u0010 h˜ \u0011 ? 0?3 ?= ?0 ? K˜ (u). Clearly, if M is not smaller than ˆµ then i = 0. It is easy to see that 1 ? ? = ∆˜ ?1 (C?). Trivially, if ˆs is not dominated by B then there exists a semi-Banach nonlocal, Hilbert modulus. Next, Sq(?) ? 2. On the other hand, L¯ ≤ kO(A)k. It is easy to see that if W is not equal to x 00 then ˆ? ? ?. Since ?c = \u001A 1 ˆd : ?T \u0012 O˜4 , 1 ? \u0013 < Z 0 ?1 cosh?1 kv 00k 5  dP\e > Z ?u,g ? p dD0 + · · · ? 1 T˜ > \u001A 1 π : tan (˜s) ≥ Z Z 0 1 max ?0?2 d ?2, . . . , k?k · ?(O¯)  dµ\e =  Q: IM,? (2, ?∞) ? lim sup ? 00 ± ?1 , if the Riemann hypothesis holds then tanh (? ? 1) ? ? (n) (?P, U) ? 0 \u0010 ?ˆ 9 \u0011 ? · · · ? tan (PN ,R ± 0). Moreover, F 0 is controlled by e 00. Now ¯f = ?. In contrast, if ? is hyperabelian then the Riemann hypothesis holds. We observe that there exists an invariant G-Eudoxus, completely admissible vector. It is easy to see that E1 < 1 H . Moreover, if ? is homeomorphic to m then there exists an irreducible and Turing pseudo-multiplicative, algebraic set equipped with a pairwise open number. Therefore if h is not invariant under M then w¯ ≤ O? (?0 ? y, . . . , 0i) ? · · · + ??0 ≤ ( ∞: ? 0 ? z khd,\u000Fk ? ?∞, . . . , 1 ?3  log (??C,y) ) . 12 Let e ≤ in,e be arbitrary. It is easy to see that if C 3 W0 then h = 1. Of course, if Y˜ ≤ h¯ then R > Z˜. Therefore every completely Artinian group is closed. Next, T is invertible. On the other hand, if d > Yˆ then A¯ ≤ ?0. One can easily see that if K is analytically anti-Einstein then ? = Z (Z) . Trivially, if k?k < \u000F? then Gauss’s conjecture is true in the context of left-universally complete, meromorphic, universally generic isometries. This is the desired statement.\r\nTheorem 7.4. Let O 3 `. Let l ? C 00(W) be arbitrary. Then S (K) (m) ?= \u001A q¯? K¯ : π 5 ? [Z 2 i X? ? m˜ d?\e ? Xπ ?=¯ i Lk?k ? ? ? ? ?1 3 : k \u0010 m(K) , 0 \u0011 = O 1 ∆=˜ ∞ C˜ \u0010√ 2 8 , ?V \u0011 ? ? ? . Proof. We begin by considering a simple special case. Let Z ≤ 1 be arbitrary. Because every combinatorially co-projective field is reducible, there exists an extrinsic and onto super-hyperbolic isometry equipped with a hyperbolic, affine, sub-isometric isometry. Moreover, ? 0 = i. One can easily see that if ud ? 0 then hJ00(K(G) ) ? ? 00 ? i. Because dN 6= 0, if T ≥ 0 then Legendre’s conjecture is true in the context of completely integral, quasi-Lebesgue subrings. We observe that if Hamilton’s criterion applies then ? 6 0 ? exp?1 \u0010 Zˆ5 \u0011 . On the other hand, every almost nonnegative definite topos is analytically Desargues and hypercanonical. Since 1 G(l) = π ? 0, there exists a co-Peano dependent graph. Trivially, if rY ,∆ is geometric then k 00 ≥ e. By well-known properties of classes, kgk ? g 0 . We observe that if M 6= ? then sin (H0) < ?¯ \u0010 Dˆ(O), ∞2 \u0011 + ?0 ? · · · + r?u,u ≤ ?∞?1 sinh?1 (?1?) ? OZ |?ˆ| 3 dgg. 13 One can easily see that if ¯s is co-universally open, left-Wiener and holomorphic then n = π. Since Q`,R = rs, x < 1. So there exists a null and holomorphic universal, quasi-naturally hyper-Banach factor. Because ? ≥ kπk, if M˜ is maximal then |U| ? ˜?(F). Now every maximal manifold is anti-pointwise degenerate. Let z 0 be a left-orthogonal isometry. Trivially, Cauchy’s condition is satisfied. In contrast, ? Z ?5  ≥ sin ?1 1  a ? · · · ? sinh (0) ?= X Y?Q Z Z sinh p ?3  d? ? · · · ? M¯ ?1 (??) ? ? ? ? Jˆ? j (e) : log Z(n 0 )  < [ ∆?T (?) 1? ? ? ? . The interested reader can fill in the details. In [34], the main result was the description of injective monodromies. A central problem in applied PDE is the description of one-to-one primes. Is it possible to characterize smoothly ultra-onto sets?\r\n\r\nConclusion\r\nIn [14], the main result was the derivation of monodromies. Therefore in this context, the results of [25] are highly relevant. It is not yet known whether every complex, stochastically semi-p-adic, compact field is co-hyperbolic, although [24] does address the issue of reversibility. In contrast, it is not yet known whether B = 1, although [5] does address the issue of connectedness. In future work, we plan to address questions of existence as well as minimality. Recent interest in Serre points has centered on characterizing almost everywhere additive hulls. Conjecture 8.1. ? 00 ≤ ?0. A central problem in probabilistic algebra is the computation of local graphs. The goal of the present paper is to study freely right-complete paths. Hence this could shed important light on a conjecture of Kepler. Conjecture 8.2. ∆ ? R. 14 Recently, there has been much interest in the extension of hulls. Thus unfortunately, we cannot assume that Yˆ ? ?q,g. Therefore unfortunately, we cannot assume that h 6= e. In [15], it is shown that LX 6= ?∞. The work in [2] did not consider the real, stochastically associative case.", user_id: 5, journal_id: 4, field_id: 20, institution_id: 6});

paper10 = Paper.create!({title: "Measurements of omega and theta from 42 high redshift supernovae", body: "ABSTRACT\r\nWe report measurements of the mass density, ? M, and cosmological-constant energy density, ? ?, of the universe based on the analysis of 42 Type Ia supernovae discovered by the Supernova Cosmology Project. The magnitude-redshift data for these supernovae, at redshifts between 0.18 and 0.83, are fit jointly with a set of supernovae from the Calán/Tololo Supernova Survey, at redshifts below 0.1, to yield values for the cosmological parameters. All supernova peak magnitudes are standardized using a SN Ia lightcurve width-luminosity relation. The measurement yields a joint probability distribution of the cosmological parameters that is approximated by the relation 0 . 8 ? M ? 0 . 6 ? ? ≈ ? 0 . 2 ± 0 .1 in the region of interest ( ? M ?< 1 .5). For a flat ( ? M + ? ? = 1) cosmology we find ? flat M = 0 .28 + 0 .09 ? 0 .08 (1 ? statistical) + 0 .05 ? 0 .04 (identified systematics). The data are strongly inconsistent with a ? = 0 flat cosmology, the simplest inflationary universe model. An open, ? = 0 cosmology also does not fit the data well: the data indicate that the cosmological constant is non-zero and positive, with a confidence of P(? > 0) = 99%, including the identified systematic uncertainties. The best-fit age of the universe relative to the Hubble time is t flat 0 = 14 . 9 + 1 . 4 ? 1 . 1 (0 .63 / h) Gyr for a flat cosmology. The size of our sample allows us to perform a variety of statistical tests to check for possible systematic errors and biases. We find no significant differences in either the host reddening distribution or Malmquist bias between the low-redshift Calán/Tololo sample and our high-redshift sample. Excluding those few supernovae which are outliers in color excess or fit residual does not significantly change the results. The conclusions are also robust whether or not a width-luminosity relation is used to standardize the supernova peak magnitudes. We discuss, and constrain where possible, hypothetical alternatives to a cosmological constant. 1Center for Particle Astrophysics, U.C. Berkeley, California. 2 Instituto Superior Técnico, Lisbon, Portugal. 3LPNHE, CNRS-IN2P3 & University of Paris VI & VII, Paris, France. 4Department of Physics, University of Stockholm, Stockholm, Sweden. 5European Southern Observatory, Munich, Germany. 6PCC, CNRS-IN2P3 & Collège de France, Paris, France. 7 Institute of Astronomy, Cambridge, United Kingdom. 8Space Sciences Laboratory, U.C. Berkeley, California. 9Space Sciences Department, European Space Agency.\r\n\r\nINTRODUCTION\r\nSince the earliest studies of supernovae, it has been suggested that these luminous events might be used as standard candles for cosmological measurements (Baade 1938). At closer distances they could be used to measure the Hubble constant, if an absolute distance scale or magnitude scale could be established, while at higher redshifts they could determine the deceleration parameter (Tammann 1979; Colgate 1979). The Hubble constant measurement became a realistic possibility in the 1980’s, when the more homogeneous subclass of Type Ia supernovae (SNe Ia) was identified (see Branch 1998). Attempts to measure the deceleration parameter, however, were stymied for lack of high-redshift supernovae. Even after an impressive multi-year effort by Nørgaard-Nielsen et al. (1989), it was only possible to follow one SN Ia, at z = 0.31, discovered 18 days past its peak brightness. The Supernova Cosmology Project was started in 1988 to address this problem. The primary goal of the project is the determination of the cosmological parameters of the universe using the magnitude-redshift relation of Type Ia supernovae. In particular, Goobar & Perlmutter (1995) showed the possibility of separating the relative contributions of the mass density, ?M, and the cosmological constant, ?, to changes in the expansion rate by studying supernovae at a range of redshifts. The Project developed techniques, including instrumentation, analysis, and observing strategies, that make it possible to systematically study high-redshift supernovae (Perlmutter et al. 1995a). As of March 1998, more than 75 Type Ia supernovae at redshifts z = 0.18–0.86 have been discovered and studied by the Supernova Cosmology Project (Perlmutter et al. 1995b, 1996, 1997a,b,c,d, 1998a). A first presentation of analysis techniques, identification of possible sources of statistical and systematic errors, and first results based on seven of these supernovae at redshifts z ? 0.4 were given in Perlmutter et al. (1997e; hereafter referred to as “P97”). These first results yielded a confidence region that was suggestive of a flat, ? = 0 universe, but with a large range of uncertainty. Perlmutter et al. (1998b) added a z = 0.83 SN Ia to this sample, with observations from the Hubble Space Telescope and Keck 10-meter telescope, providing the first demonstration of the method of separating ?M and ? contributions. This analysis offered preliminary evidence for a low-mass-density universe with a best-fit value of ?M = 0.2 ± 0.4, assuming ? = 0. Independent work by Garnavich et al. (1998a), based on three supernovae at z ? 0.5 and one at z = 0.97, also suggested a low mass density, with best-fit ?M = ?0.1±0.5 for ? = 0. Perlmutter et al. (1998c) presented a preliminary analysis of 33 additional high-redshift supernovae, which gave a confi- dence region indicating an accelerating universe, and barely including a low-mass ?= 0 cosmology. Recent independent work of Riess et al. (1998), based on 10 high-redshift supernovae added to the Garnavich et al. set, reached the same conclusion. Here we report on the complete analysis of 42 supernovae from the Supernova Cosmology Project, including the reanalysis of our previously reported supernovae with improved calibration data and improved photometric and spectroscopic SN Ia templates.\r\n\r\nBASIC DATA AND PROCEDURES\r\nThe new supernovae in this sample of 42 were all discovered while still brightening, using the Cerro Tololo 4-meter telescope with the 20482 -pixel prime-focus CCD camera or the 4 ? 20482 -pixel Big Throughput Camera (Bernstein & Tyson 1998). The supernovae were followed with photometry over the peak of their lightcurves, and approximately two-to-three months further (?40–60 days restframe) using the CTIO 4-m, WIYN 3.6-m, ESO 3.6-m, INT 2.5-m, and WHT 4.2-m telescopes. (SN 1997ap and other 1998 supernovae have also been followed with HST photometry.) The supernova redshifts and spectral identifications were obtained using the Keck I and II 10-m telescopes with LRIS (Oke et al. 1995) and the ESO 3.6- m telescope. The photometry coverage was most complete in Kron-Cousins R-band, with Kron-Cousins I-band photometry coverage ranging from two or three points near peak to relatively complete coverage paralleling the R-band observations. Almost all of the new supernovae were observed spectroscopically. The confidence of the Type Ia classifications based on these spectra taken together with the observed lightcurves, ranged from “definite” (when Si II features were visible) to “likely” (when the features were consistent with Type Ia, and inconsistent with most other types). The lower confidence identifications were primarily due to host-galaxy contamination of the spectra. Fewer than 10% of the original sample of supernova candidates from which these SNe Ia were selected were confirmed to be non-Type Ia, i.e., being active galactic nuclei or belonging to another SN subclass; almost all of these non-SNe Ia could also have been identified by their lightcurves and/or position far from the SN Ia Hubble line. Whenever possible, the redshifts were measured from the narrow host-galaxy lines, rather than the broader supernova lines. The lightcurves and several spectra are shown in Perlmutter et al. (1997e, 1998c, 1998b); complete catalogs and detailed discussions of the photometry and spectroscopy for these supernovae will be presented in forthcoming papers. The photometric reduction and the analyses of the lightcurves followed the procedures described in P97. The supernovae were observed with the Kron-Cousins filter that best matched the restframe B and V filters at the supernova’s redshift, and any remaining mismatch of wavelength coverage was corrected by calculating the expected photometric difference— the “cross-filter K-correction”—using template SN Ia spectra, as in Kim, Goobar, & Perlmutter (1996). We have now recalculated these K corrections (see Nugent et al. 1998), using improved template spectra, based on an extensive database of low-redshift SN Ia spectra recently made available from the Calán/Tololo survey (Phillips et al. 1998). Where available, IUE and HST spectra (Cappellaro, Turatto, & Fernley 1995; Kirshner et al. 1993) were also added to the SN Ia spectra, including those published previously (1972E, 1981B, 1986G, 1990N, 1991T, 1992A, and 1994D in: Kirshner & Oke 1975; Branch et al. 1983; Phillips et al. 1987; Jeffery et al. 1992; Meikle et al. 1996; Patat et al. 1996). In Nugent et al. (1998) we show that the K-corrections can be calculated accurately for a given day on the supernova lightcurve, and for a given supernova lightcurve width, from the color of the supernova on that day. (Such a calculation of K correction based on supernova color will also automatically account for any modification of the K correction due to reddening of the supernova; see Nugent et al. 1998. In the case of insignificant reddening the SN Ia template color curves can be used.) We find that these calculations are robust to mis-estimations of the lightcurve width or day on the lightcurve, giving results correct to within 0.01 mag for lightcurve width errors of ±25% or lightcurve phase errors of ±5 days even at redshifts where filter matching is the worst. Given small additional uncertainties in the colors of 3 supernovae, we take an overall systematic uncertainty of 0.02 magnitudes for the K correction. The improved K-corrections have been recalculated for all the supernovae used in this paper, including those previously analyzed and published. Several of the low-redshift supernovae from the Calán/Tololo survey have relatively large changes (as much as 0.1 magnitudes) at times in their K-corrected lightcurves. (These and other low-redshift supernovae with new K-corrections are used by several independent groups in constructing SN Ia lightcurve templates, so the templates must be updated accordingly.) The K-corrections for several of the high-redshift supernovae analyzed in P97 have also changed by small amounts at the lightcurve peak (∆K(t = 0) ? < 0.02 mag) and somewhat larger amounts by 20 days past peak (∆K(t = 20) ? < 0.1 mag); this primarily affects the measurement of the restframe lightcurve width. These K-correction changes balance out among the P97 supernovae, so the final results for these supernovae do not change significantly. (As we discuss below, however, the much larger current dataset does affect the interpretation of these results.). As in P97, the peak magnitudes have been corrected for the lightcurve width-luminosity relation of SNe Ia: m corr B = mB + ∆corr(s), (1) where the correction term ∆corr is a simple monotonic function of the “stretch factor,” s, that stretches or contracts the time axis of a template SN Ia lightcurve to best fit the observed lightcurve for each supernova (see Perlmutter et al. 1995a, 1997e; Kim et al. 1998; Goldhaber et al. 1998; and cf. Phillips 1993; Riess, Press, & Kirshner 1995, 1996). A similar relation corrects the V band lightcurve, with the same stretch factor in both bands. For the supernovae discussed in this paper, the template must be time-dilated by a factor 1 + z before fitting to the observed lightcurves to account for the cosmological lengthening of the supernova timescale (Goldhaber et al. 1995; Leibundgut et al. 1996a; Riess et al. 1997a). P97 calculated ∆corr(s) by translating from s to ∆m15 (both describing the timescale of the supernova event) and then using the relation between ∆m15 and luminosity as determined by Hamuy et al. (1995). The lightcurves of the Calán/Tololo supernovae have since been published, and we have directly fit each lightcurve with the stretched template method to determine its stretch factor s. In this paper, for the light-curve width-luminosity relation, we therefore directly use the functional form ∆corr(s) = ?(s ? 1) (2) and determine ? simultaneously with our determination of the cosmological parameters. With this functional form, the supernova peak apparent magnitudes are thus all “corrected” as they would appear if the supernovae had the lightcurve width of the template, s = 1. We use analysis procedures that are designed to be as similar as possible for the low- and high-redshift datasets. Occasionally, this requires not using all of the data available at low redshift, when the corresponding data are not accessible at high redshift. For example, the low-redshift supernova lightcurves can often be followed with photometry for many months with high signal-to-noise ratios, whereas the high-redshift supernova observations are generally only practical for approximately 60 restframe days past maximum light. This period is also the phase of the low-redshift SN Ia lightcurves that is fit best by the stretched-template method, and best predicts the luminosity of the supernova at maximum. We therefore fit only this period for the lightcurves of the low-redshift supernovae. Similarly, at high redshift the restframe B-band photometry is usually much more densely sampled in time than the restframe V-band data, so we use the stretch factor that best fits the restframe B band data for both low- and high-redshift supernovae, even though at low-redshift the V-band photometry is equally well sampled. Each supernova peak magnitude was also corrected for Galactic extinction, AR, using the extinction law of Cardelli, Clayton, & Mathis (1989), first using the color excess, E(B?V)SF&D, at the supernova’s Galactic coordinates provided by Schlegel, Finkbeiner, & Davis (1998) and then—for comparison—using the E(B?V)B&H value provided by Burstein & Heiles (1982, 1998). AR was calculated from E(B?V) using a value of the total-to-selective extinction ratio, RR ? AR/E(B?V), specific to each supernova. These were calculated using the appropriate redshifted supernova spectrum as it would appear through an R-band filter. These values of RR range from 2.56 at z = 0 to 4.88 at z = 0.83. The observed supernova colors were similarly corrected for Galactic extinction. Any extinction in the supernova’s host galaxy, or between galaxies, was not corrected for at this stage, but will be analyzed separately in Section 4. All the same corrections for width-luminosity relation, K corrections, and extinction (but using RB = 4.14) were applied to the photometry of 18 low-redshift SNe Ia (z ≤ 0.1) from the Calán/Tololo supernova survey (Hamuy et al. 1996) that were discovered earlier than five days after peak. The lightcurves of these 18 supernovae have all been re-fit since P97, using the more recently available photometry (Hamuy et al. 1996) and our K corrections. Figures 1 and 2(a) show the Hubble diagram of effective restframe B magnitude corrected for the width-luminosity relation, m effective B = mR + ∆corr ?KBR ?AR (3) as a function of redshift for the 42 Supernova Cosmology Project high-redshift supernovae, along with the 18 Calán/Tololo low-redshift supernovae. (Here, KBR is the cross- filter K correction from observed R band to restframe B band.) Tables 1 and 2 give the corresponding IAU names, redshifts, magnitudes, corrected magnitudes, and their respective uncertainties. As in P97, the inner error bars in Figures 1 and 2 represent the photometric uncertainty, while the outer error bars add in quadrature 0.17 magnitudes of intrinsic dispersion of SN Ia magnitudes that remain after applying the width-luminosity correction. For these plots, the slope of the width-brightness relation was taken to be ? = 0.6, the best-fit value of Fit C discussed below. (Since both the low- and high-redshift supernova light-curve widths are clustered rather closely around s = 1, as shown in Figure 4, the exact choice of ? does not change the Hubble diagram significantly.) The theoretical curves for a universe with no cosmological constant are shown as solid lines, for a range of mass density, ?M = 0,1,2. The dashed lines represent alternative flat cosmologies, for which the total massenergy density ?M +?? = 1 (where ?? ? ?/3H 2 0 ). The range of models shown are for (?M,??) = (0,1), (0.5,0.5), (1,0), which is covered by the matching solid line, and (1.5, ?0.5). 3.\r\n\r\nFITS TO ?M AND ??\r\nThe combined low- and high-redshift supernova datasets of Figure 1 are fit to the Friedman-Robertson-Walker magnitude- 4 redshift relation, expressed as in P97: m effective B ? mR +?(s ? 1) ?KBR ?AR (4) = MB + 5logDL(z;?M,??) , where DL ? H0dL is the “Hubble-constant-free” luminosity distance and MB ? MB ? 5logH0 + 25 is the “Hubble-constantfree” B-band absolute magnitude at maximum of a SN Ia with width s = 1. (These quantities are, respectively, calculated from theory or fit from apparent magnitudes and redshifts, both without any need for H0. The cosmological-parameter results are thus also completely independent of H0.) The details of the fitting procedure as presented in P97 were followed, except that both the low- and high-redshift supernovae were fit simultaneously, so that MB and ?, the slope of the widthluminosity relation, could also be fit in addition to the cosmological parameters ?M and ??. For most of the analyses in this paper, MB and ? are statistical “nuisance” parameters; we calculate 2-dimensional confidence regions and single-parameter uncertainties for the cosmological parameters by integrating over these parameters, i.e., P(?M,??) = RR P(?M,??,MB,?)dMB d?. As in P97, the small correlations between the photometric uncertainties of the high-redshift supernovae, due to shared calibration data, have been accounted for by fitting with a correlation matrix of uncertainties. (The correlation matrix is available at http://www-supernova.lbl.gov.) The low-redshift supernova photometry is more likely to be uncorrelated in its calibration since these supernovae were not discovered in batches. However, we take a 0.01 mag systematic uncertainty in the comparison of the low-redshift B-band photometry and the highredshift R-band photometry. The stretch-factor uncertainty is propagated with a fixed width-luminosity slope (taken from the low-redshift supernovae; cf. P97), and checked for consistency after the fit. We have compared the results of Bayesian and classical, “frequentist,” fitting procedures. For the Bayesian fits, we have assumed a “prior” probability distribution that has zero probability for ?M < 0, but otherwise uniform probability in the four parameters ?M, ??, ?, and MB. For the frequentist fits, we have followed the classical statistical procedures described by Feldman & Cousins (1998), to guarantee frequentist coverage of our confidence regions in the physically allowed part of parameter space. Note that throughout the previous cosmology literature, completely unconstrained fits have generally been used that can (and do) lead to confidence regions that include the part of parameter space with negative values for ?M. The differences between the confidence regions that result from Bayesian and classical analyses are small. We present the Bayesian con- fidence regions in the figures, since they are somewhat more conservative, i.e. have larger confidence regions, in the vicinity of particular interest near ? = 0. The residual dispersion in SN Ia peak magnitude after correcting for the width-luminosity relation is small, about 0.17 magnitudes, before applying any color-correction. This was reported in Hamuy et al. (1996) for the low-redshift CalanTololo supernovae, and it is striking that the same residual is most consistent with the current 42 high-redshift supernovae (see Section 5). It is not clear from the current datasets, however, whether this dispersion is best modeled as a normal distribution (a Gaussian in flux space) or a log-normal distribution (a Gaussian in magnitude space). We have therefore performed the fits two ways: minimizing ? 2 measured using either magnitude residuals or flux residuals. The results are generally in excellent agreement, but since the magnitude fits yield slightly larger confidence regions, we have again chosen this more conservative alternative to report in this paper. We have analyzed the total set of 60 low- plus high-redshift supernovae in several ways, with the results of each fit presented as a row of Table 3. The most inclusive analyses are presented in the first two rows: Fit A is a fit to the entire dataset, while Fit B excludes two supernovae that are the most significant outliers from the average lightcurve width, s = 1, and two of the remaining supernovae that are the largest residuals from Fit A. Figure 4 shows that the remaining low- and high-redshift supernovae are well matched in their lightcurve width—the error-weighted means are hsiHamuy = 0.99 ± 0.01 and hsiSCP = 1.00 ± 0.01—making the results robust with respect to the width-luminosity-relation correction (see Section 4.5). Our primary analysis, Fit C, further excludes two supernovae that are likely to be reddened, and is discussed in the following section. Fits A and B give very similar results. Removing the two large-residual supernovae from Fit A yields indistinguishable results, while Figure 5(a) shows that the 68% and 90% joint confidence regions for ?M and ?? still change very little after also removing the two supernovae with outlier lightcurve widths. The best-fit mass-density in a flat universe for Fit A is, within a fraction of the uncertainty, the same value as for Fit B, ? flat M = 0.26+0.09 ?0.08 (see Table 3). The main difference between the fits is the goodness-of-fit: the larger ? 2 per degree of freedom for Fit A, ? 2 ? = 1.76, indicates that the outlier supernovae included in this fit are probably not part of a Gaussian distribution and thus will not be appropriately weighted in a ? 2 fit. The ? 2 per degree of freedom for Fit B, ? 2 ? = 1.16, is over 300 times more probable than that of fit A, and indicates that the remaining 56 supernovae are a reasonable fit to the model, with no large statistical errors remaining unaccounted for. Of the two large-residual supernovae excluded from the fits after Fit A, one is fainter than the best-fit prediction and one is brighter. The photometric color excess (see Section 4.1) for the fainter supernova, SN 1997O, has an uncertainty that is too large to determine conclusively whether it is reddened. The brighter supernova, SN 1994H, is one of the first seven highredshift supernovae originally analyzed in P97, and is one of the few supernovae without a spectrum to confirm its classifi- cation as a SN Ia. After re-analysis with additional calibration data and improved K-corrections, it remains the brightest outlier in the current sample, but it affects the final cosmological fits much less as one of 42 supernovae, rather than 1 of 5 supernovae in the primary P97 analysis.\r\n\r\nSYSTEMATIC UNCERTAINTIES AND CROSS-CHECKS\r\nWith our large sample of 42 high-redshift SNe, it is not only possible to obtain good statistical uncertainties on the measured parameters, but also to quantify several possible sources of systematic uncertainties. As discussed in P97, the primary approach is to examine subsets of our data that will be affected to lesser extents by the systematic uncertainty being considered. The high-redshift sample is now large enough that these subsets each contain enough supernovae to yield results of high statistical significance. 5 4.1. Extragalactic Extinction. 4.1.1. Color-Excess Distributions Although we have accounted for extinction due to our Galaxy, it is still probable that some supernovae are dimmed by host galaxy dust or intergalactic dust. For a standard dust extinction law (Cardelli, Clayton, & Mathis 1989) the color, B?V, of a supernova will become redder as the amount of extinction, AB, increases. We thus can look for any extinction differences between the low- and high-redshift supernovae by comparing their restframe colors. Since there is a small dependence of intrinsic color on the lightcurve width, supernova colors can only be compared for the same stretch factor; for a more convenient analysis, we subtract out the intrinsic colors, so that the remaining color excesses can be compared simultaneously for all stretch factors. To determine the restframe color excess E(B?V) for each supernova, we fit the rest-frame B and V photometry to the B and V SN Ia lightcurve templates, with one of the fitting parameters representing the magnitude difference between the two bands at their respective peaks. Note that these lightcurve peaks are ?2 days apart, so the resulting Bmax?Vmax color parameter, which is frequently used to describe supernova colors, is not a color measurement on a particular day. The difference of this color parameter from the Bmax?Vmax found for a sample of low-redshift supernovae for the same lightcurve stretchfactor (Tripp 1998; Kim et al. 1998; Phillips 1998) does yield the restframe E(B?V) color excess for the fitted supernova. For the high-redshift supernovae at 0.3 < z < 0.7, the matching R- and I-band measurements take the place of the restframe B and V measurements and the fit B and V lightcurve templates are K-corrected from the appropriate matching filters, e.g. R(t) = B(t)+KBR(t) (Kim, Goobar, & Perlmutter 1996; Nugent et al. 1998). For the three supernovae at z > 0.75, the observed R?I corresponds more closely to a restframe U ?B color than to a B?V color, so E(B?V) is calculated from restframe E(U ?B) using the extinction law of Cardelli, Clayton, & Mathis (1989). Similarly, for the two SNe Ia at z ? 0.18, E(B?V) is calculated from restframe E(V?R). Figure 6 shows the color excess distributions for both the low- and high-redshift supernovae, after removing the color excess due to our Galaxy. Six high-redshift supernovae are not shown on this E(B?V) plot, because six of the first seven highredshift supernovae discovered were not observed in both R and I bands. The color of one low-redshift supernova, SN 1992bc, is poorly determined by the V-band template fit and has also been excluded. Two supernovae in the high-redshift sample are > 3? red-and-faint outliers from the mean in the joint probability distribution of E(B?V) color excess and magnitude residual from Fit B. These two, SNe 1996cg and 1996cn (shown in light shading in Figure 6), are very likely reddened supernovae. To obtain a more robust fit of the cosmological parameters, in Fit C we remove these supernovae from the sample. As can be seen from the Fit-C 68% confidence region of Figure 5(a), these likely-reddened supernovae do not significantly affect any of our results. The main distribution of 38 high-redshift supernovae thus is barely affected by a few reddened events. We find identical results if we exclude the six supernovae without color measurements (Fit G in Table 3). We take Fit C to be our primary analysis for this paper, and in Figure 7, we show a more extensive range of confidence regions for this fit. 4.1.2. Cross-checks on Extinction The color-excess distributions of the Fit C dataset (with the most significant measurements highlighted by dark shading in Figure 6) show no significant difference between the low- and high-redshift means. The dashed curve drawn over the highredshift distribution of Figure 6 shows the expected distribution if the low-redshift distribution had the measurement uncertainties of the high-redshift supernovae indicated by the dark shading. This shows that the reddening distribution for the highredshift SNe is consistent with the reddening distribution for the low-redshift SNe, within the measurement uncertainties. The error-weighted means of the low- and high-redshift distributions are almost identical: hE(B?V)iHamuy = 0.033±0.014 mag and hE(B?V)iSCP = 0.035 ± 0.022 mag. We also find no significant correlation between the color excess and the statistical weight or redshift of the supernovae within these two redshift ranges. To test the effect of any remaining high-redshift reddening on the Fit C measurement of the cosmological parameters, we have constructed a Fit H-subset of the high-redshift supernovae that is intentional biased to be bluer than the low-redshift sample. We exclude the error-weighted reddest 25% of the highredshift supernovae; this excludes 9 high-redshift supernovae with the highest error-weighted E(B?V). We further exclude two supernovae that have large uncertainties in E(B?V) but are significantly faint in their residual from Fit C. This is a somewhat conservative cut since it removes the faintest of the highredshift supernovae, but it does ensure that the error-weighted E(B?V) mean of the remaining supernova subset is a good indicator of any reddening that could affect the cosmological parameters. The probability that the high-redshift subset of Fit H is redder in the mean than the low-redshift supernovae is less than 5%; This subset is thus very unlikely to be biased to fainter magnitudes by high-redshift reddening. Even with nonstandard, “greyer” dust that does not cause as much reddening for the same amount of extinction, a conservative estimate of the probability that the high-redshift subset of Fit H is redder in the mean than the low-redshift supernovae is still less than ?17%, for any high-redshift value of RB ? AB/E(B?V) less than twice the low-redshift value. (These same confidence levels are obtained whether using Gaussian statistics, assuming a normal distribution of E(B?V) measurements, or using bootstrap resampling statistics, based on the observed distribution.) The confidence regions of Figure 5(c) and the ? flat M results in Table 3 show that the cosmological parameters found for Fit H differ by less than half of a standard deviation from those for Fit C. We take the difference of these fits, 0.03 in ? flat M (which corresponds to less than 0.025 in magnitudes) as a ?1? upper bound on the systematic uncertainty due to extinction by dust that reddens. Note that the modes of both distributions appear to be at zero reddening, and similarly the medians of the distributions are quite close to zero reddening: hE(B?V)i median Hamuy = 0.01 mag and hE(B?V)i median SCP = 0.00 mag. This should be taken as suggestive rather than conclusive since the zeropoint of the relationship between true color and stretch is not tightly constrained by the current low-redshift SN Ia dataset. This apparent strong clustering of SNe Ia about zero reddening has been noted in the past for low-redshift supernova samples. Proposed explanations have been given based on the relative spatial distributions of the SNe Ia and the dust: Modeling by Hatano, Branch, & Deaton (1997) of the expected extinction of SN Ia disk and 6 bulge populations viewed at random orientations shows an extinction distribution with a strong spiked peak near zero extinction along with a broad, lower-probability wing to higher extinction. This wing will be further suppressed by the observational selection against more reddened SNe, since they are dimmer. (For a flux-limited survey this suppression factor is 10?aR[RBE(B?V)??(s?1)] ≈ 10?1.6E(B?V) , where aR is the slope of the supernova number counts.) We also note that the high-redshift supernovae for which we have accurate measurements of apparent separation between SN and host position (generally, those with Hubble Space Telescope imaging) appear to be relatively far from the host center, despite our high search sensitivity to supernovae in front of the host galaxy core (see Pain et al. 1996 for search efficiency studies; also cf. Wang, Höflich, & Wheeler 1997). If generally true for the entire sample, this would be consistent with little extinction. Our results, however, do not depend on the low- and highredshift color-excess distributions being consistent with zero reddening. It is only important that the reddening distributions for the low-redshift and high-redshift datasets are statistically the same, and that there is no correlation between reddening and statistical weight in the fit of the cosmological parameters. With both of these conditions satisfied, we find that our measurement of the cosmological parameters is unaffected (to within the statistical error) by any small remaining extinction among the supernovae in the two datasets.\r\n\r\n4.1.3. Analysis with Reddening Correction of Individual Supernovae\r\nWe have also performed fits using restframe B-band magnitudes individually corrected for host galaxy extinction using AB = RBE(B?V) (implicitly assuming that the extragalactic extinction is all at the redshift of the host galaxy). As a direct comparison between the treatment of host galaxy extinction described above and an alternative Bayesian method (Riess, Press, & Kirshner 1996), we applied it to the 53 SNe Ia with color measurements in our Fit C dataset. We find that our cosmological parameter results are robust with respect to this change, although this method can introduce a bias into the extinction corrections, and hence the cosmological parameters. In brief, in this method the Gaussian extinction probability distribution implied by the measured color-excess and its error is multiplied by an assumed a priori probability distribution (the Bayesian prior) for the intrinsic distribution of host extinctions. The most probable value of the resulting renormalized probability distribution is taken as the extinction, and following Riess (private communication) the second-moment is taken as the uncertainty. For this analysis, we choose a conservative prior (as given in Riess, Press, & Kirshner 1996) that does not assume that the supernovae are unextinguished, but rather is somewhat broader than the true extinction distribution where the majority of the previously observed supernovae apparently suffer very little reddening. (If one alternatively assumes that the current data’s extinction distribution is quite as narrow as that of previously observed supernovae, one can choose a less conservative but more realistic narrow prior probability distribution, such as that of Hatano, Branch, & Deaton (1997). This turns out to be quite similar to our previous analysis in Section 4.1.1, since a distribution like that of Hatano, Branch, & Deaton has zero extinction for most supernovae.) This Bayesian method with a conservative prior will only brighten supernovae, never make them fainter, since it only affects the supernovae with redder measurements than the zeroextinction E(B?V) value, leaving unchanged those measured to be bluer than this. The resulting slight difference between the assumed and true reddening distributions would make no difference in the cosmology measurements if its size were the same at low and high redshifts. However, since the uncertainties, ? high?z E(B?V) , in the high-redshift dataset E(B?V) measurements are larger on average than those of the low-redshift dataset, ? low?z E(B?V) , this method can over-correct the high-redshift supernovae on average relative to the low-redshift supernovae. Fortunately, as shown in Appendix A, even an extreme case with a true distribution all at zero extinction and a conservative prior would introduce a bias in extinction AB only of order 0.1 magnitudes at worst for our current low- and high-redshift measurement uncertainties. The results of Fit E are shown in Table 3 and as the dashed contour in Figure 5(d), where it can be seen that compared to Fit C this approach moves the best fit value much less than this, and in the direction expected for this effect (indicated by the arrows in Figure 5d). The fact that ? flat M changes so little from Case C, even with the possible bias, gives further confi- dence in the cosmological results. We can eliminate any such small bias of this method by assuming no Bayesian prior on the host-galaxy extinction, allowing extinction corrections to be negative in the case of supernovae measured to be bluer than the zero-extinction E(B?V) value. As expected, we recover the unbiased results within error, but with larger uncertainties since the Bayesian prior also narrows the error bars in the method of Riess, Press, & Kirshner (1996). However, there remains a potential source of bias when correcting for reddening: the effective ratio of total to selective extinction, RB, could vary, for several reasons. First, the extinction could be due to host galaxy dust at the supernova’s redshift or intergalactic dust at lower redshifts, where it will redden the supernova less since it is acting on a redshifted spectrum. Second, RB may be sensitive to dust density, as indicated by variations in the dust extinction laws between various sight-lines in the Galaxy (Clayton & Cardelli 1988; Gordon & Clayton 1998). Changes in metallicity might be expected to be a third possible cause of RB evolution, since metallicity is one dust-related quantity known to evolve with redshift (Pettini et al. 1997), but fortunately it appears not to significantly alter RB as evidenced by the similarity of the optical portions of the extinction curves of the Galaxy, the LMC, and the SMC (Pei 1992; Gordon & Clayton 1998). Three-filter photometry of high-redshift supernovae currently in progress with the Hubble Space Telescope will help test for such differences in RB. To avoid these sources of bias, we consider it important to use and compare both analysis approaches: the rejection of reddened supernovae and the correction of reddened supernovae. We do find consistency in the results calculated both ways. The advantages of the analyses with reddening corrections applied to individual supernovae (with or without a Bayesian prior on host-galaxy extinction) are outweighed by the disadvantages for our sample of high-redshift supernovae; although, in principle, by applying reddening corrections the intrinsic magnitude dispersion of SNe Ia can be reduced from an observed dispersion of 0.17 magnitudes to approximately 0.12 magnitudes, in practice the net improvement for our sample is not significant since uncertainties in the color measurements often dominate. We have therefore chosen for our primary analysis to follow the first procedure discussed above, removing the likely-reddened supernovae (Fit C) and then comparing color-excess means. The systematic difference for Fit H, which rejects the reddest and 7 the faintest high-redshift supernovae, is already quite small, and we avoid introducing additional actual and possible biases. Of course, neither approach avoids biases if RB at high redshift is so large [> 2RB(z = 0)] that dust does not redden the supernovae enough to be distinguished and this dust makes more than a few supernovae faint.\r\n\r\n4.2. Malmquist Bias and other Luminosity Biases.\r\nIn the fit of the cosmological parameters to the magnituderedshift relation, the low-redshift supernova magnitudes primarily determine MB and the width-luminosity slope ?, and then the comparison with the high-redshift supernova magnitudes primarily determines ?M and ??. Both low- and highredshift supernova samples can be biased towards selecting the brighter tail of any distribution in supernova detection magnitude for supernovae found near the detection threshold of the search (classical Malmquist bias; Malmquist 1924, 1936). A width-luminosity relation fit to such a biased population would have a slope that is slightly too shallow and a zeropoint slightly too bright. A second bias is also acting on the supernova samples, selecting against supernovae on the narrow-lightcurve side of the width-luminosity relation since such supernovae are detectable for a shorter period of time. Since this bias removes the narrowest/faintest supernova lightcurves preferentially, it culls out the part of the width-brightness distribution most subject to Malmquist bias, and moves the resulting best-fit slope and zeropoint closer to their correct values. If the Malmquist bias is the same in both datasets, then it is completely absorbed by MB and ? and does not affect the cosmological parameters. Thus, our principal concern is that there could be a difference in the amount of bias between the lowredshift and high-redshift samples. Note that effects peculiar to photographic SNe searches, such as saturation in galaxy cores, which might in principle select slightly different SNe Ia subpopulations should not be important in determining luminosity bias because lightcurve stretch compensates for any such differences. Moreover, Figure 4 shows that the high-redshift SNe Ia we have discovered have a stretch distribution entirely consistent with those discovered in the Calán/Tololo search. To estimate the Malmquist bias of the high-redshiftsupernova sample, we first determined the completeness of our high-redshift searches as a function of magnitude, through an extensive series of tests inserting artificial SNe into our images (see Pain et al. 1996). We find that roughly 30% of our highredshift supernovae were detected within twice the SN Ia intrinsic luminosity dispersion of the 50% completeness limit, where the above biases might be important. This is consistent with a simple model where the supernova number counts follow a power-law slope of 0.4 mag?1 , similar to that seen for comparably distant galaxies (Smail et al. 1995). For a flux-limited survey of standard candles having the lightcurve-width-corrected luminosity dispersion for SN Ia of ?0.17 mag and this numbercount power-law slope, we can calculate that the classical Malmquist bias should be 0.03 mag (see, e.g., Mihalas & Binney 1981, for a derivation of the classical Malmquist bias). (Note that this estimate is much smaller than the Malmquist bias affecting other cosmological distance indicators, due to the much smaller intrinsic luminosity dispersion of SNe Ia.) These high-redshift supernovae, however, are typically detected before maximum, and their detection magnitudes and peak magnitudes have a correlation coefficient of only 0.35, so the effects of classical Malmquist bias should be diluted. Applying the formalism of Willick (1994) we estimate that the decorrelation between detection magnitude and peak magnitude reduces the classical Malmquist bias in the high-redshift sample to only 0.01 mag. The redshift and stretch distributions of the highredshift supernovae that are near the 50%-completeness limit track those of the overall high-redshift sample, again suggesting that Malmquist biases are small for our dataset. We cannot make an exactly parallel estimate of Malmquist bias for the low-redshift-supernova sample, because we do not have information for the Calán/Tololo dataset concerning the number of supernovae found near the detection limit. However, the amount of classical Malmquist bias should be similar for the Calán/Tololo SNe since the amount of bias is dominated by the intrinsic luminosity dispersion of SNe Ia, which we find to be the same for the low-redshift and high-redshift samples (see Section 5). Figure 4 shows that the stretch distributions for the high-redshift and low-redshift samples are very similar, so that the compensating effects of stretch-bias should also be similar in the two datasets. The major source of difference in the bias is expected to be due to the close correlation between the detection magnitude and the peak magnitude for the low-redshift supernova search, since this search tended not to find the supernovae as early before peak as the high-redshift search. In addition, the number-counts at low-redshift should be somewhat steeper (Maddox et al. 1990). We thus expect the Calán/Tololo SNe to have a bias closer to that obtained by direct application of the the classical Malmquist bias formula, 0.04 mag. One might also expect “inhomogeneous Malmquist bias” to be more important for the low-redshift supernovae, since in smaller volumes of space inhomogeneities in the host galaxy distribution might by chance put more supernovae near the detection limit than would be expected for a homogeneous distribution. However, after averaging over all the Calán/Tololo supernova-search fields the total low-redshift volume searched is large enough that we expect galaxy count fluctuations of only ?4%, so the classical Malmquist bias is still a good approximation. We believe that both these low- and high-redshift biases may be smaller, and even closer to each other, due to the mitigating effect of the bias against detection of low-stretch supernovae, discussed above. However, to be conservative, we take the classical Malmquist bias of 0.04 mag for the low-redshift dataset, and the least biased value of 0.01 mag for the high-redshift dataset, and consider systematic uncertainty from this source to be the difference, 0.03 mag, in the direction of low-redshift supernovae more biased than high-redshift. In the other direction, i.e. for high-redshift supernovae more biased than low-redshift, we consider the extreme case of a fortuitously unbiased lowredshift sample, and take the systematic uncertainty bound to be the 0.01 mag bias of the high-redshift sample. (In this direction any systematic error is less relevant to the question of the existence of a cosmological constant.)\r\n\r\n4.3. Gravitational Lensing.\r\nAs discussed in P97, the clumping of mass in the universe could leave the line-of-sight to most of the supernovae underdense, while occasional supernovae may be seen through overdense regions. The latter supernovae could be significantly brightened by gravitational lensing, while the former supernovae would appear somewhat fainter. With enough supernovae, this effect will average out (for inclusive fits, such as Fit A, which include outliers), but the most over-dense lines of sight may be so rare that a set of 42 supernovae may only sample a slightly biased (fainter) set. The probability distribution of these amplifications and deamplifications has previously 8 been studied both analytically and by Monte Carlo simulations. Given the acceptance window of our supernova search, we can integrate the probability distributions from these studies to estimate the bias due to amplified or deamplified supernovae that may be rejected as outliers. This average (de)amplification bias is less than 1% at the redshifts of our supernovae for simulations based on isothermal spheres the size of typical galaxies (Holz & Wald 1998), N-body simulations using realistic mass power spectra (Wambsganss, Cen, & Ostriker 1998), and the analytic models of Frieman (1996). It is also possible that the small-scale clumping of matter is more extreme, e.g., if significant amounts of mass were in the form of compact objects such as MACHOs. This could lead to many supernova sightlines that are not just under-dense, but nearly empty. Once again, only the very rare line of sight would have a compact object in it, amplifying the supernova signal. To first approximation, with 42 supernovae we would see only the nearly empty beams, and thus only deamplifi- cations. The appropriate luminosity-distance formula in this case is not the Friedmann-Robertson-Walker (FRW) formula but rather the “partially filled beam” formula with a mass filling factor, ? ≈ 0 (see Kantowski 1998, and references therein). We present the results of the fit of our data (Fit K) with this luminosity-distance formula (as calculated using the code of Kayser, Helbig, & Schramm 1996) in Figure 8. A more realistic limit on this point-like mass density can be estimated, because we would expect such point-like masses to collect into the gravitational potential wells already marked by galaxies and clusters. Fukugita, Hogan, & Peebles (1997) estimate an upper limit of ?M < 0.25 on the mass which is clustered like galaxies. In Figure 8, we also show the confidence region from Fit L, assuming that only the mass density contribution up to ?M = 0.25 is point-like, with filling factor ? = 0, and that ? rises to 0.75 at ?M = 1. We see that at low mass density, the FriedmanRobertson-Walker fit is already very close to the nearly emptybeam (? ≈ 0) scenario, so the results are quite similar. At high mass density, the results diverge, although only minimally for Fit L; the best fit in a flat universe is ? flat M = 0.34+0.10 ?0.09.\r\n\r\n4.4. Supernova Evolution and Progenitor Environment Evolution\r\nThe spectrum of a SN Ia on any given point in its lightcurve reflects the complex physical state of the supernova on that day: the distribution, abundances, excitations, and velocities of the elements that the photons encounter as they leave the expanding photosphere all imprint on the spectra. So far, the high-redshift supernovae that have been studied have lightcurve shapes just like those of low-redshift supernovae (see Goldhaber et al. 1998), and their spectra show the same features on the same day of the lightcurve as their low-redshift counterparts having comparable lightcurve width. This is true all the way out to the z = 0.83 limit of the current sample (Perlmutter et al. 1998b). We take this as a strong indication that the physical parameters of the supernova explosions are not evolving significantly over this time span. Theoretically, evolutionary effects might be caused by changes in progenitor populations or environments. For example, lower metallicity and more massive SN Ia-progenitor binary systems should be found in younger stellar populations. For the redshifts that we are considering, z < 0.85, the change in average progenitor masses may be small (Ruiz-Lapuente, Canal, & Burkert 1997; Ruiz-Lapuente 1998). However, such progenitor mass differences or differences in typical progenitor metallicity are expected to lead to differences in the final C/O ratio in the exploding white dwarf, and hence affect the energetics of the explosion. The primary concern here would be if this changed the zero-point of the width-luminosity relation. We can look for such changes by comparing lightcurve rise times between low and high-redshift supernova samples, since this is a sensitive indicator of explosion energetics. Preliminary indications suggest that no significant rise-time change is seen, with an upper limit of ? 0. This is reflected in the high probability (99.8%) of ?? > 0. As discussed in Goobar & Perlmutter (1995), the slope of the contours in Figure 7 is a function of the supernova redshift distribution; since most of the supernovae reported here are near z ? 0.5, the confidence region is approximately fit by 0.8?M ? 0.6?? ≈ ?0.2 ± 0.1. (The orthogonal linear combination, which is poorly constrained, is fit by 0.6?M + 0.8?? ≈ 1.5 ± 0.7.) In P97, we emphasized that the well-constrained linear combination is not parallel to any contour of constant current-deceleration-parameter, q0 = ?M/2 ? ??; the accelerating/decelerating universe line of Figure 9 shows one such contour at q0 = 0. Note that with almost all of the confidence region above this line, only currently accelerating universes fit the data well. As more of our highest redshift supernovae are analyzed, the long dimension of the confidence region will shorten. Error Budget Most of the sources of statistical error contribute a statistical uncertainty to each supernova individually, and are included in the uncertainties listed in Tables 1 and 2, with small correlations between these uncertainties given in the correlated-error matrices (available at http://www-supernova.lbl.gov). These supernova-specific statistical uncertainties include the measurement errors on SN peak magnitude, lightcurve stretch factor, and absolute photometric calibration. The two sources of statistical error that are common to all the supernovae are the intrinsic dispersion of SN Ia luminosities after correcting for the width-luminosity relation, taken as 0.17 mag, and the redshift uncertainty due to peculiar velocities, which are taken as 300 km s?1 . Note that the statistical error in MB and ? are derived quantities from our four-parameter fits. By integrating the fourdimensional probability distributions over these two variables, their uncertainties are included in the final statistical errors. All uncertainties that are not included in the statistical error budget are treated as systematic errors for the purposes of this paper. In Sections 2 and 4, we have identified and bounded four potentially significant sources of systematic uncertainty: (1) the extinction uncertainty for dust that reddens, bounded at 2RB(z = 0)] and any SN Ia evolutionary effects that might change the zero point of the lightcurve width-luminosity relation. We have presented bounds and tests for these effects which give preliminary indications that they are not large sources of uncertainty, but at this time they remain difficult to quantify, at least partly because the proposed physical processes and entities that might cause the effects are not completely defined. To characterize the effect of the identified systematic uncertainties, we have refit the supernovae of Fit C for the hypothetical case (Fit J) in which each of the high-redshift supernovae were discovered to be 0.04 magnitudes brighter than measured, or, equivalently, the low-redshift supernovae were discovered to be 0.04 magnitudes fainter than measured. Figure 5(e) and Table 3 show the results of this fit. The best-fit flat-universe ? flat M varies from that of Fit C by 0.05, less than the statistical error bar. The probability of ?? > 0 is still over 99%. When we fit with the smaller systematic error in the opposite direction (i.e., high-redshift supernovae discovered to be 0.03 magnitudes fainter than measured), we find (Fit I) only a 0.04 shift in ? flat M from Fit C. The measurement error of the cosmological parameters has contributions from both the low- and high-redshift supernova datasets. To identify the approximate relative importance of these two contributory sources, we reanalyzed the Fit C dataset, first fitting MB and ? to the low-redshift dataset (this is relatively insensitive to cosmological model), and then fitting ?M and ?? to the high-redshift dataset. (This is only an approximation, since it neglects the small influence of the low-redshift supernovae on ?M and ??, and of the high-redshift supernovae on MB and ?, in the standard four-parameter fit.) Figure 5(f) shows this ?M–?? fit as a solid contour (labeled Fit M), with the 1-sigma uncertainties on MB and ? included with the systematic uncertainties in the dashed-line confidence contours. This approach parallels the analyses of Perlmutter et al. (1997e, 1998c, 1998b), and thus also provides a direct comparison with the earlier results. We find that the more important contribution to the uncertainty is currently due to the low-redshift supernova sample. If three times as many well-observed low-redshift supernovae were discovered and included in the analysis, then the statistical uncertainty from the low-redshift dataset would be 11 smaller than the other sources of uncertainty. We summarize the relative statistical and systematic uncertainty contributions in Table 4. 6. \r\n\r\nCONCLUSIONS AND DISCUSSION\r\nThe confidence regions of Figure 7 and the residual plot of Figure 2(b) lead to several striking implications. First, the data are strongly inconsistent with the ? = 0, flat universe model (indicated with a circle) that has been the theoretically favored cosmology. If the simplest inflationary theories are correct and the universe is spatially flat, then the supernova data imply that there is a significant, positive cosmological constant. Thus, the universe may be flat, or there may be little or no cosmological constant, but the data are not consistent with both possibilities simultaneously. This is the most unambiguous result of the current dataset. Second, this dataset directly addresses the age of the universe relative to the Hubble time, H ?1 0 . Figure 9 shows that the ?M–?? confidence regions are almost parallel to contours of constant age. For any value of the Hubble constant less than H0 = 70 km s?1 Mpc?1 , the implied age of the universe is greater than 13 Gyr, allowing enough time for the oldest stars in globular clusters to evolve (Chaboyer et al. 1998; Gratton et al. 1997). Integrating over ?M and ??, the best fit value of the age in Hubble-time units is H0t0 = 0.93+0.06 ?0.06 or equivalently t0 = 14.5 +1.0 ?1.0 (0.63/h) Gyr. The age would be somewhat larger in a flat universe: H0t flat 0 = 0.96+0.09 ?0.07 or equivalently t flat 0 = 14.9 +1.4 ?1.1 (0.63/h) Gyr. Third, even if the universe is not flat, the confidence regions of Figure 7 suggest that the cosmological constant is a signifi- cant constituent of the energy density of the universe. The best- fit model (the center of the shaded contours) indicates that the energy density in the cosmological constant is ?0.5 more than that in the form of mass energy density. All of the alternative fits listed in Table 3 indicate a positive cosmological constant with confidence levels of order 99%, even with the systematic uncertainty included in the fit or with a clumped-matter metric. Given the potentially revolutionary nature of this third conclusion, it is important to reexamine the evidence carefully to find possible loopholes. None of the identified sources of statistical and systematic uncertainty described in the previous sections could account for the data in a ? = 0 universe. If the universe does in fact have zero cosmological constant, then some additional physical effect or “conspiracy” of statistical effects must be operative—and must make the high-redshift supernovae appear almost 0.15 mag (?15% in flux) fainter than the low-redshift supernovae. At this stage in the study of SNe Ia, we consider this unlikely but not impossible. For example, as mentioned above, some carefully constructed smooth distribution of large-grain-size grey dust that evolves similarly for elliptical and spiral galaxies could evade our current tests. Also, the full dataset of well-studied SNe Ia is still relatively small, particularly at low redshifts, and we would like to see a more extensive study of SNe Ia in many different host-galaxy environments before we consider all plausible loopholes (including those listed in Table 4B) to be closed. Many of these residual concerns about the measurement can be addressed with new studies of low-redshift supernovae. Larger samples of well-studied low-redshift supernovae will permit detailed analyses of statistically significant SN Ia subsamples in differing host environments. For example, the width-luminosity relation can be checked and compared for supernovae in elliptical host galaxies, in the cores of spiral galaxies, and in the outskirts of spiral galaxies. This comparison can mimic the effects of finding high-redshift supernovae with a range of progenitor ages, metallicities, etc. So far, the results of such studies with small statistics has not shown any difference in width-luminosity relation for this range of environments. These empirical tests of the SNe Ia can also be complemented by better theoretical models. As the datasets improve, we can expect to learn more about the physics of SN Ia explosions and their dependence on the progenitor environment, strengthening the confidence in the empirical calibrations. Finally, new well-controlled, digital searches for SNe Ia at low redshift will also be able to further reduce the uncertainties due to systematics such as Malmquist bias. 6.1. Comparison with Previous Results A comparison with the first supernova measurement of the cosmological parameters in P97 highlights an important aspect of the current measurement. As discussed in Section 3, the P97 measurement was strongly skewed by SN 1994H, one of the two supernovae that are clear statistical outliers from the current 42-supernova distribution. If SN 1994H had not been included in the P97 sample, then the cosmological measurements would have agreed within the 1? error bars with the current result. (The small changes in the K-corrections discussed in Section 2 are not a significant factor in arriving at this agreement.) With the small P97 sample size of seven supernovae (only five of which were used in the P97 width-corrected analysis), and somewhat larger measurement uncertainties, it was not possible to distinguish SN 1994H as the statistical outlier. It is only with the much larger current sample size that it is easy to distinguish such outliers on a graph such as Figure 2(c). The fact that there are any outliers at all raises one cautionary flag for the current measurement. Although neither of the current two outliers is a clearly aberrant SN Ia (one has no SN Ia spectral confirmation and the other has a relatively poor constraint on host-galaxy extinction), we are watching carefully for such aberrant events in future low- and high-redshift datasets. Ideally, the one-parameter width-luminosity relationship for SNe Ia would completely account for every single wellstudied SN Ia event. This is not a requirement for a robust measurement, but any exceptions that are discovered would provide an indicator of as-yet undetected parameters within the main SN Ia distribution. Our first presentation of the cosmological parameter measurement (Perlmutter et al. 1998c), based on 40 of the current 42 high-redshift supernovae, found the same basic results as the current analysis: A flat universe was shown to require a cosmological constant, and only a small region of low-mass-density parameter space, with all the systematic uncertainty included, could allow for ? = 0. (Fit M of Figure 5(f) still shows almost the same confidence region, with the same analysis approach). The current confidence region of Figure 7 has changed very little from the corresponding confidence region of Perlmutter et al. (1998c), but since most of the uncertainties in the lowredshift dataset are now included in the statistical error, the remaining systematic error is now a small part of the error budget. The more recent analysis of 16 high-redshift supernovae by Riess et al. (1998) also show a very similar ?M-?? con- fidence region. The best fits for mass density in a flatuniverse are ? flat M = 0.28 ± 0.10 or ? flat M = 0.16 ± 0.09 for the two alternative analyses of their 9 independent, well-observed, spectroscopically-confirmed supernovae. The best fits for the 12 age of the universe for these analyses are H0t0 = 0.90+0.07 ?0.05 and H0t0 = 0.98+0.07 ?0.05. To first order, the Riess et al. result provides an important independent cross-check for all three conclusions discussed above, since it was based on a separate high-redshift supernova search and analysis chain (see Schmidt et al. 1998). One caveat, however, is that their ?M-?? confidence-region result cannot be directly compared to ours to check for independent consistency, because the low-redshift-supernova datasets are not independent: a large fraction of these supernovae with the highest weight in both analyses are from the Calán/Tololo Supernova Survey (which provided many well-measured supernovae that were far enough into the Hubble flow so that their peculiar velocities added negligible redshift-uncertainty). Moreover, two of the 16 high-redshift supernovae included in the Riess et al. confidence-region analyses were from our sample of 42 Supernova Cosmology Project supernovae; Riess et al. included them with an alternative analysis technique applied to a subset of our photometry results. (In particular, their result uses the highest-redshift supernova from our 42-supernova sample, which has strong weight in our analysis due to the excellent Hubble Space Telescope photometry.) Finally, although the analysis techniques are mostly independent, the K corrections are based on the same Nugent et al. (1998) approach discussed above. 6.2. Comparison with Complementary Constraints on ?M and ?? Significant progress is being made in the measurement of the cosmological parameters using complementary techniques that are sensitive to different linear combinations of ?M and ??, and have different potential systematics or model dependencies. Dynamical methods, for example, are particularly sensitive to ?M, since ?? affects dynamics only weakly. Since there is evidence that dynamical estimates of ?M depend on scale, the most appropriate measures to compare with our result are those obtained on large scales. From the abundance—indeed the mere existence—of rich clusters at high redshift, Bahcall & Fan (1998) find ?M = 0.2 +0.3 ?0.1 (95% confidence). The CNOC collaboration (Carlberg et al. 1996, 1998) apply evolution-corrected mass-to-light ratios determined from virial mass estimates of X-ray clusters to the luminosity density of the universe and find ?M = 0.17 ± 0.07 for ?? = 0 (?90% confidence), with small changes in these results for different values of ?? (cf. Carlberg 1997). Detailed studies of the peculiar velocities of galaxies (e.g., Willick et al. 1997; Willick & Strauss 1998; Riess et al. 1997b; but see Sigad et al. 1998) are now giving estimates of ? = ? 0.6 M /bIRAS ≈ 0.45±0.11 (95% confidence)1 , where b is the ratio of density contrast in galaxies compared to that in all matter. Under the simplest assumption of no large-scale biasing for IRAS galaxies, b = 1, these results give ?M ≈ 0.26±0.11 (95% confidence), in agreement with the other dynamical estimates— and with our supernova results for a flat cosmology. A form of the angular-size distance cosmological test has been developed in a series of papers (cf. Guerra & Daly 1998, and references therein) and implemented for a sample of fourteen radio galaxies by Daly, Guerra, & Wan (1998). The method uses the mean observed separation of the radio lobes compared to a canonical maximum lobe size—calculated from the inferred magnetic field strength, lobe propagation velocity, and lobe width—as a calibrated standard ruler. The confidence region in the ?M–?? plane shown in Daly, Guerra, & Wan (1998) is in broad agreement with the SN Ia results we report; they find ?M = 0.2 +0.3 ?0.2 (68% confidence) for a flat cosmology. QSO gravitational lensing statistics are dependent on both volume and relative distances, and thus are more sensitive to ??. Using gravitational lensing statistics, Kochanek (1996) finds ?? < 0.66 (at 95% confidence for ?M + ?? = 1), and ?M > 0.15. Falco, Kochanek, & Munoz (1998) obtained further information on the redshift distribution of radio sources which allows calculation of the absolute lensing probability for both optical and radio lenses. Formally their 90% confidence levels in the ?M–?? plane have no overlap with those we report here. However, as Falco, Kochanek, & Munoz (1998) discuss, these results do depend on the choice of galaxy sub-type luminosity functions in the lens models. Chiba & Yoshii (1998) emphasized this point, reporting an analysis with E/S0 luminosity functions that yielded a best-fit mass density in a flat cosmology of ? flat M = 0.3 +0.2 ?0.1 , in agreement with our SN Ia results. Several papers have emphasized that upcoming balloon and satellite studies of the Cosmic Background Radiation (CBR) should provide a good measurement of the sum of the energy densities, ?M + ??, and thus provide almost orthogonal information to the supernova measurements (White 1998; Tegmark et al. 1998). In particular, the position of the first acoustic peak in the CBR power spectrum is sensitive to this combination of the cosmological parameters. The current results, while not conclusive, are already somewhat inconsistent with over-closed (?M + ?? >> 1) cosmologies and “near-empty” (?M +?? ? < 0.4) cosmologies, and may exclude the upper right and lower left regions of Figure 7 (see, e.g., Lineweaver 1998; Efstathiou et al. 1998). 6.3. Cosmological Implications If, in fact, the universe has a dominant energy contribution from a cosmological constant, there are two coincidences that must be addressed in future cosmological theories. First, a cosmological constant in the range shown in Figure 7 corresponds to a very small energy density relative to the vacuum-energydensity scale of particle-physics energy zero-points (see Carroll, Press, & Turner 1992, for a discussion of this point). Previously, this had been seen as an argument for a zero cosmological constant, since presumably some symmetry of the particlephysics model is causing cancelations of this vacuum energy density. Now, it would be necessary to explain how this value comes to be so small, yet non-zero. Second, there is the coincidence that the cosmological constant value is comparable to the current mass-energy density. As the universe expands, the matter energy density falls as the third power of the scale, while the cosmological constant remains unchanged. One therefore would require initial conditions in which the ratio of densities is a special, infinitesimal value of order 10?100 in order for the two densities to coincide today. (The cross-over between mass-dominated and ?-dominated energy density occurred at z ≈ 0.37, for a flat ?M ≈ 0.28 universe, whereas the cross-over between deceleration and acceleration occurred when (1 + z) 3?M/2 = ??, that is at z ≈ 0.73. This was approximately when SN 1997G exploded, over 6 billion years ago.) It has been suggested that these cosmological coincidences could be explained if the magnitude-redshift relation we find for SNe Ia is due not to a cosmological constant, but rather to 1This is an error-weighted mean of Willick et al. (1997) and Riess et al. (1997b), with optical results converted to equivalent IRAS results using bOpt/bIRAS = 1.20 ± 0.05 from Oliver et al. (1996). 13 a different, previously unknown physical entity that contributes to the universe’s total energy density (see, e.g., Steinhardt 1996; Turner & White 1997; Caldwell, Dave, & Steinhardt 1998). Such an entity can lead to a different expansion history than the cosmological constant does, because it can have a different relation (“equation of state”) between its density ? and pressure p than that of the cosmological constant, p?/?? = ?1. We can obtain constraints on this equation-of-state ratio, w ? p/?, and check for consistency with alternative theories (including the cosmological constant with w = ?1) by fitting the alternative expansion histories to data; White (1998) has discussed such constraints from earlier supernovae and CBR results. In Figure 10, we update these constraints for our current supernova dataset, for the simplest case of a flat universe and an equation of state that does not vary in time (cf. Garnavich et al. 1998b, for comparison with their high-redshift supernova dataset, and Aldering et al. 1998 for time-varying equations of state fit to our dataset). In this simple case, a cosmological-constant equation of state can fit our data if the mass density is in the range 0.2 ? < ?M ? < 0.4. However, all the cosmological models shown in Figure 10 still require that the initial conditions for the new energy density be tuned with extreme precision to reach their current-day values. Zlatev, Wang, & Steinhardt (1998) have shown that some time-varying-w theories naturally channel the new energy density term to “track” the matter term, as the universe expands, leading—without coincidences—to values of an effective vacuum energy density today that are comparable to the mass energy density. These models require w ? > ?0.8 at all times up to the present, for ?M ≥ 0.2. The supernova dataset presented here and future complementary datasets will allow us to explore these possibilities. The observations described in this paper were primarily obtained as visiting/guest astronomers at the Cerro Tololo InterAmerican Observatory 4-meter telescope, operated by the National Optical Astronomy Observatory under contract to the National Science Foundation; the Keck I and II 10-m telescopes of the California Association for Research in Astronomy; the Wisconsin-Indiana-Yale-NOAO (WIYN) telescope; the European Southern Observatory 3.6-meter telescope; the Isaac Newton and William Herschel Telescopes, operated by the Royal Greenwich Observatory at the Spanish Observatorio del Roque de los Muchachos of the Instituto de Astrofisica de Canarias; the Hubble Space Telescope, and the Nordic Optical 2.5-meter telescope. We thank the dedicated staff of these observatories for their excellent assistance in pursuit of this project. In particular, Dianne Harmer, Paul Smith and Daryl Willmarth were extraordinarily helpful as the WIYN queue observers. We thank Gary Bernstein and Tony Tyson for developing and supporting the Big Throughput Camera at the CTIO 4-meter; this wide- field camera was important in the discovery of many of the high-redshift supernovae. David Schlegel, Doug Finkbeiner, and Marc Davis provided early access to, and helpful discussions concerning, their models of Galactic extinction. Megan Donahue contributed serendipitous HST observations of SN 1996cl. We thank Daniel Holz and Peter Höflich for helpful discussions. The larger computations described in this paper were performed at the U. S. Department of Energy’s National Energy Research Science Computing Center (NERSC). This work was supported in part by the Physics Division, E. O. Lawrence Berkeley National Laboratory of the U. S. Department of Energy under Contract No. DE-AC03-76SF000098, and by the National Science Foundation’s Center for Particle Astrophysics, University of California, Berkeley under grant No. ADT-88909616. A. V. F. acknowledges the support of NSF grant No. AST-9417213 and A. G. acknowledges the support of the Swedish Natural Science Research Council. The FranceBerkeley Fund and the Stockholm-Berkeley Fund provided additional collaboration support. APPENDIX EXTINCTION CORRECTION USING A BAYESIAN PRIOR Bayes Theorem provides a means of estimating the a posteriori probability distribution, P(A|Am), of a variable A given a measurement of its value, Am, along with a priori information, P(A), about what values are likely: P(A|Am) = P(Am|A)P(A) R P(Am|A)P(A)dA (A1) In practice P(A) often is not well known, but must be estimated from sketchy, and possibly biased, data. For our purposes here we wish to distinguish between the true probability distribution, P(A), and its estimated or assumed distribution, often called the Bayesian prior, which we denote as P(A). Riess, Press, & Kirshner (1996; RPK) present a Bayesian method of correcting SNe Ia for host galaxy extinction. For P(A) they assume a one-sided Gaussian function of extinction, G(A), with dispersion ?G = 1 magnitude: P(A) = G(A) ? ? ??? ??? s 2 π?2 G e ?A 2 /2? 2 G for A ≥ 0 0 for A < 0 (A2) which reflects the fact that dust can only redden and dim the light from a supernova. The probability distribution of the measured extinction, Am, is an ordinary Gaussian with dispersion ?m, i.e., the measurement uncertainty. RPK choose the most probable value of P(A|Am) as their best estimate of the extinction for each supernova: 14 Aˆ G = mode(P(A|Am)) = ? ??? ??? Am? 2 G ? 2 G + ? 2 m for Am > 0 0 for Am ≤ 0 (A3) Although this method provides the best estimate of the extinction correction for an individual supernova provided P(A) = P(A), once measurement uncertainties are considered its application to an ensemble of SNe Ia can result in a biased estimate of the ensemble average extinction whether or not P(A) = P(A). An extreme case which illustrates this point is where the true extinction is zero for all supernovae, i.e., P(A) is a delta function at zero. In this case, a measured value of E(B?V) < 0 (too blue) results in an extinction estimate of Aˆ G = 0, while a measured value with E(B?V) ≥ 0 results in an extinction estimate Aˆ G > 0. The ensemble mean of these extinction estimates will be hAˆ Gi = ?m √ 2π ( ? 2 G ? 2 G + ? 2 m ), (A4) rather than 0 as it should be. (This result is changed only slightly if the smaller uncertainties assigned to the least extincted SNe Ia are incorporated into a weighted average.) The amount of this bias is dependent on the size of the extinction-measurement uncertainties, ?m = RB?E(B?V) . For our sample of high-redshift supernovae, typical values of this uncertainty are ?m ? 0.5, while for the low-redshift supernovae, ?m ? 0.07. Thus, if the true extinction distribution is a delta-function at A = 0, while the one-sided prior, G(A), of Equation A2 is used, the bias in hAˆ Gi is about 0.13 mag in the sense that the high-redshift supernovae would be overcorrected for extinction. Clearly, the exact amount of bias depends on the details of the dataset (e.g., color uncertainty, relative weighting). the true distribution P(A), and the choice of prior P(A). This is a worst-case estimate, since we believe that the true extinction distribution is more likely to have some tail of events with extinction. Indeed, numerical calculations using a one-sided Gaussian for the true distribution, P(A), show that the amount of bias decreases as the Gaussian width increases away from a delta function, crosses zero when P(A) is still much narrower than P(A), and then increases with opposite sign. One might use the mean of P(A|Am) instead of the mode in equation A-3, since the bias then vanishes if P(A) = P(A), however this mean-calculated bias is even more sensitive to P(A) 6= P(A) than the mode-calculated bias. We have only used conservative priors (which are somewhat broader than the true distribution, as discussed in Section 4.1), however it is instructive to consider the bias that results for a less conservative choice of prior. For example, an extinction distribution with only half of the supernovae distributed in a one-sided Gaussian and half in a delta function at zero extinction is closer to the simulations given by Hatano, Branch, & Deaton (1997). The presence of the delta-function component in this less conservative prior assigns zero extinction to the vast majority of supernovae, and thus cannot produce a bias even with different uncertainties at low and high redshift. This will lower the overall bias, but it will also assign zero extinction to many more supernovae than assumed in the prior, in typical cases in which the measurement uncertainty is not significantly smaller than the true extinction distribution. A restrictive prior, i.e. one which is actually narrower than the true distribution, can even lead to a bias in the opposite direction from a conservative prior. It is clear from Bayes Theorem itself that the correct procedure for determining the maximum-likelihood extinction, A˜, of an ensemble of supernovae is to first calculate the a posteriori probability distribution for the ensemble: P(A|{Ami}) = P(A) PP(Ami |A) R P(A) PP(Ami |A)dA (A5) and then take the most probable value of P(A|{Ami}) for A˜. For the above example of no reddening, this returns the correct value of A˜ = 0. In fitting the cosmological parameters generally one is not quite as interested in the ensemble extinction as in the combined impact of individual extinctions. In this case P(A|{Ami}) must be combined with other sources of uncertainty for each supernova in a maximum–likelihood fit, or the use of a Bayesian prior must be abandoned. In the former case a ? 2 fit is no longer appropriate since the individual P(A|{Ami})’s are strongly non-Gaussian. Use of a Gaussian uncertainty for Aˆ G based on the second–moment of P(A|{Ami}) may introduce additional biases.", user_id: 6, journal_id: 7, field_id: 16, institution_id: 8});

paper11 = Paper.create!({title: "Dark Energy and Extending the Geodesic Equations of Motion: Its Construction and Experimental Constraints", body: "Abstract\r\nWith the discovery of Dark Energy, ?DE, there is now a universal length scale, ?DE = c/(?DEG) 1/2 , associated with the universe that allows for an extension of the geodesic equations of motion. In this paper, we will study a specific class of such extensions, and show that contrary to expectations, they are not automatically ruled out by either theoretical considerations or experimental constraints. In particular, we show that while these extensions affect the motion of massive particles, the motion of massless particles are not changed; such phenomena as gravitational lensing remain unchanged. We also show that these extensions do not violate the equivalence principal, and that because ?DE = 14010800 820 Mpc, a specific choice of this extension can be made so that effects of this extension are not be measurable either from terrestrial experiments, or through observations of the motion of solar system bodies. A lower bound for the only parameter used in this extension is set. PACS 95.36.+x · 04.20.Cv · 04.25.-g \r\n\r\nIntroduction\r\nThe recent discovery of Dark Energy (see [1], [2] and references therein) has broadened our knowledge of the universe, and has demonstrated once again that it can hold surprises for us. This discovery has, most assuredly, also brought into sharp relief the degree of our understanding of the universe. In this paper, we will study one specific implication of this discovery: With the discovery of Dark Energy, ?DE, there is now a universal length scale, ?DE = c/(?DEG) 1/2 , 1 , 2 associated with the universe that allows for extensions of the geodesic equations of motion (GEOM). We find that contrary to expectations, these extensions are not automatically ruled out by theoretical considerations, nor are they ruled out by experimental constraints either through terrestrial experiments or through solar system tests of general relativity. Indeed, we show in this paper that one specific extension of the GEOM is a viable alternative to the GEOM, and we obtain a lower bound for the only free parameter used in its construction, a power-law exponent, ??. There are good theoretical and physical reasons for studying the range of extensions of the geodesic equations of motion that are allowed. Arguments for the use of the geodesic equations of motion to describe the motion of massive test particles in curved spacetime are based on various statements of the equivalence principle, and the principle of general covariance (see chapter 4 of [5]), along with arguments in favor of simplicity and aesthetics. Importantly, these arguments are made in addition to those made in favor of Einstein’s field equation. Namely, these is no unique way of deriving the geodesic equations of motion from the field equations. Indeed, in 1938 Einstein, Infield and Hoffman attempted to show that as a consequence of the field equations, massive test particles will travel along geodesics in the spacetime [6]. These attempts have continued to the present day [7], [8]. Extensions and modifications of the GEOM have been made before, of course. On the level of Newtonian dynamics, Modified Newtonian Dynamics (MOND) [9] has been proposed as an alternate explanation of the galactic rotation curves. On the relativistic level, there has been recent efforts [10] to develop a general framework to study modifications to the GEOM in the weak field, linearized gravity limits. The major impetus for this work has been to describe a series of dynamical anomalies—the Pioneer anomaly (see [11] and [12]), the flyby anomaly [13], and the lengthening of the Astronomical Unit [14]—that have been observed at the Solar system scale. The focus of this paper is to establish the underlying theoretical framework that can be used to describe structures and dynamics at the galactic length scale and above. In a future paper [15], this framework will be applied to an analysis of the galactic rotation curves, and the impact that this extension has on phenomena at cosmological length scales will be studied. As such, we focus here on the Dark Energy energy length scale, and on how the existence of this scale allows for extensions of the GEOM. Indeed, we find that with this length scale, ?DE, extensions of the GEOM are not difficult to construct. The quotient c 2R/?DEG is dimensionless, and functionals of this quotient can easily be used to extend the GEOM. What is more relevant is whether or not the resultant equations of motion will be a physically viable alternative to the GEOM. As such we will be guided in our extension of the GEOM by the four conditions listed below. They are deliberately chosen to be conservative in scope, and thus stringent in their application. Somewhat surprisingly, we will show that there is at least one extension of the GEOM that satisfies all four. First, we require that the extension preserve the equivalence principle, which is one of the underlying principles on which general relativity is founded.\r\nIn the following sections of the paper, we will explicitly see that this preservation is assured by the fact that ?DE is the same for all test particles. This universal nature of ?DE is crucial. While other length scales—say, the proton mass—could be used for the extension, the resultant equations of motion would depend on this mass. They could not then be applied to the motion of protons without explicitly violating the uniqueness of free fall condition. Second, we require that the extension not change the equations of motion for massless test particles; such particles must still follow the GEOM. All astronomical observations—of which gravitational lensing is playing an increasingly important role—are based on the motion of photons of various wavelengths. Modifications to the equations of motion for photons will require a reinterpretation of these observations, a daunting step not to be taken without good reason. We will show that by considering a class of extensions that is based on conformally scaling the rest mass of the test particle, we arrive at extended GEOMs that, on the one hand, will not change the motion of massless test particles, but will, on the other, change the motion of massive ones. Being conformal, the motion of photons will not be affected by this class of extensions, and they will still travel along null geodesics; phenomena such as gravitational lensing will remain unchanged. While in form this class of extensions resembles a scalar field theory that is non-minimally and nonlinearly coupled to the scalar curvature, R, such theories are constructed at the quantum level. Our extension of the GEOM is done at the classical, ~ = 0, level, with the scale of the coupling set by ?DE. The third condition involves the attempts [6], [7], [8] at proving that the GEOM are the unique consequence of the Einstein field equations (see also page 72 of [5]). These proofs would seem to rule out any physically relevant extension of the GEOM, and by necessity, our extension of the GEOM cannot be precluded by such proofs. That the extension is possible is because these proofs focus on the motion of test particles in regions where the Einstein tensor, Gµ? , vanishes. We will see that in these regions the extended GEOM reduce to the GEOM, and thus do not violate these proofs. Indeed, we will explicitly construct the energy-momentum tensor for an inviscid fluid of massive particles propagating under the extended GEOM.\r\nThe fourth condition is the most stringent of the four. With the exception of the as-yet unexplained anomalies described above, we require that the extension of the GEOM not produce effects that are measurable either in terrestrial experiments, or through the motion of bodies in the solar system that have traditionally been used to test general relativity. While stringent, we will nevertheless show explicitly that a choice of extension can be made which satis- fies it. Physically, this choice is possible because at (7.21+0.83 ?0.84) x 10?30 g/cm3 [16], ?DE is orders of magnitude smaller than the density of matter, ?limit, either currently achievable in terrestrial experiments (where densities exceed 10?18 g/cm3 ), or present in the solar system (where the density of matter in Mercury’s orbit exceeds 10?23 g/cm3 ). Correspondingly, at 14010800 820 Mpc ?DE is more than three times larger than the observed size of the universe, and is orders of magnitude larger than the solar system. Nevertheless, we find that even though the disparity between the magnitude of ?DE and ?limit—or, equivalently, between ?DE and the size of the solar system—is large, a nonlinear function of c 2R/?DEG is needed in constructing the extension for its effects not to have already been seen in terrestrial experiments. The simplest of these extensions has only one free parameter, ??, a power-law exponent that determines the behavior of the function at densities both much larger than ?DE, and much smaller than it. Lower bounds for ?? are set by requiring that the extension does not produce observable effects in current terrestrial experiments. While it may be possible to apply the analysis in this paper to the explanation of Solar system anomalies such as the Pioneer anomaly, the focus of this research is on phenomenon at the galactic scale or longer. It is for this reason that we require our extension to be constrained only by experiments and observations that are currently well-understood, and for which the underlying physics is well-known. We leave to future work the question of whether or not our analysis can be applied to explaining the Pioneer and other Solarsystem-scale anomalies.\r\n\r\nConcluding Remarks\r\nWe have shown that because of the existence of a universal length scale, ?DE, it is now possible to construct an extension of the GEOM. This extension preserves the equivalence principal, does not change the motion of massless test particles, and does not produce effects that would be detectable in either terrestrial experiments, or through observing the motion of bodies in the solar system. Our extension of the GEOM is thus a physically viable alternative to the GEOM. The question remains as to whether these equations of motion have any physical relevance. In short, is anything gained by using this extension? Because ?DE = 14010800 820 Mpc, we would expect that any effects from the extended GEOM will become apparent at much longer length scales than those considered here. Indeed, given the size of ?DE the only reason why we would expect the extended GEOM to be relevant at all is because D is a nonlinear function of the energy-momentum tensor of ambient matter. This question of relevance will be addressed in a future paper [15] where the extended GEOM is applied to the motion of stars in the rotation curves of galaxies, and to the density of matter at cosmological length scales. These are the scales at which we expect the effects from the extension to come into play, and where its relevance can be assessed. Finally, as noted in [21], Eq. (19) can be solved in general to give an equation of motion for particles, v ??? vµ = ?µp/(? + p/c2 ), and we see that the presence of any pressure term in the energy-momentum tensor results in deviations from geodesic motion. Given that ?DE can also be used to construct a pressure, it is natural to ask whether the effects of the extended GEOM can be obtained through the introduction of an ad hoc pressure term in the energy-momentum tensor. Such an ad hoc term can only be introduced to the energy-momentum tensor for matter, however; for the reasons given in the introduction, the equations of motion for massless particles cannot be changed. In addition, because the behavior of any massive particle approaches that of a massless one in the ultrarelativistic limit, this ad hoc pressure term must be constructed so that irrespective of frame this term contributes a negligible amount to the energy of the particle in this limit. Moreover, even if such a construction can be accomplished at the ultrarelativistic limit, hurdles remain at the nonrelativistic limit. While it is possible to construct in the nonrelativistic limit an appropriate ad hoc pressure using ?DE and D, when the resultant equations of motion are applied to the same systems as the extended GEOM in [15], effects are predicted at the cosmological scale that either do not agree with experiment or are not physically reasonable. This occurs even though the pressure is chosen so that at galactic scales predicted effects will be in broad agreement with observations. For these reasons, it is doubtful that introducing ad hoc pressure term in place of the extended GEOM will be succussful.", user_id: 6, journal_id: 8, field_id: 16, institution_id: 9});

paper12 = Paper.create!({title: "The primary transcriptome of the major human pathogen Helicobacter pylori", body: "Genome sequencing of Helicobacter pylori has revealed the potential proteins and genetic diversity of this prevalent human pathogen, yet little is known about its transcriptional organization and noncoding RNA output. Massively parallel cDNA sequencing (RNA-seq) has been revolutionizing global transcriptomic analysis. Here, using a novel differential approach (dRNA-seq) selective for the 5′ end of primary transcripts, we present a genome-wide map of H. pylori transcriptional start sites and operons. We discovered hundreds of transcriptional start sites within operons, and opposite to annotated genes, indicating that complexity of gene expression from the small H. pylori genome is increased by uncoupling of polycistrons and by genome-wide antisense transcription. We also discovered an unexpected number of ~60 small RNAs including the ϵ-subdivision counterpart of the regulatory 6S RNA and associated RNA products, and potential regulators of cis- and trans-encoded target messenger RNAs. Our approach establishes a paradigm for mapping and annotating the primary transcriptomes of many living species.\r\n\r\nAbout 50% of all humans are infected with Helicobacter pylori, a microaerophilic, Gram-negative ϵ-proteobacterium that thrives in the acidic environment of the stomach, and is associated with severe inflammation, peptic ulcer disease and gastric cancer1, 2. The 1.67 megabase pairs genome of H. pylori strain 26695 carries 1,576 open reading frames (ORFs), but surprisingly few genes of transcriptional regulators3, 4. Moreover, only ~55 transcriptional start sites (TSS; compiled in Supplementary Table 1) were known in this important human pathogen, and the principal organization of its transcriptome remained to be elucidated. Small noncoding RNAs (sRNAs), an otherwise abundant class of post-transcriptional regulators in bacteria5, 6, also seemed to be lacking in H. pylori, perhaps reflecting the absence of the common sRNA chaperone, Hfq, in all ϵ-proteobacteria7.\r\n\r\nGlobal analyses using tiling arrays and RNA-seq have provided invaluable insights into the gene expression patterns and sRNA output of diverse bacteria, including several pathogens8, 9. Yet, these studies did not directly detect TSS owing to a lack of discrimination between primary and processed transcripts. Specifically, primary transcripts including most mRNAs and sRNAs carry a 5′ tri-phosphate (5′PPP) group, whereas processed transcripts such as mature ribosomal and transfer RNAs (rRNA, tRNA) have a 5′ mono-phosphate (5′P). Using a novel dRNA-seq approach to selectively identify native 5′PPP ends we present a single-nucleotide resolution map of the primary transcriptome of H. pylori and unravel the unexpectedly complex RNA output from this small and compact genome.\r\n\r\nDifferential RNA-seq\r\nOur dRNA-seq approach discriminates primary from processed 5′ ends by sequencing differential cDNA library pairs: one library denoted (-) from untreated total bacterial RNA, and the other (+) enriched for primary transcripts by terminator exonuclease treatment that degrades 5′P but not 5′PPP RNA (Supplementary Fig. 1). We primarily analysed H. pylori strain 26695 grown to mid-logarithmic phase (ML-/+ libraries), or under acid stress at pH 5.2 (AS-/+) resembling the host environment. To increase data depths, bacteria were also grown in contact with responsive gastric epithelial cells (AG-/+) or non-responsive liver cells (HU-/+), or in cell culture medium alone (PL-/+) (Supplementary Fig. 2). Following 454 pyrosequencing, ~217 million bases of cDNA (Supplementary Table 2) were mapped to the H. pylori chromosome (Fig. 1a).\r\n\r\ndRNA-seq confirmed the known acid induction10, 11, 12 of major H. pylori virulence loci such as the urease (ure) operon or the cag pathogenicity island (Fig. 1b), as evident from a three- to fourfold higher cDNA coverage of the ureA, ureI or cag16 transcripts in the AS- vs ML- libraries (Supplementary Table 3). Crucially, the exonuclease treatment revealed TSS by means of a characteristic redistribution of a gene’s cDNAs towards a sawtooth-like profile with an elevated sharp 5′ flank. For example, the AS+ cDNAs clustered towards the nuclease-protected primary 5′ end of ureA mRNA, matching the known TSS13, 14, whereas the AS- cDNAs were uniformly distributed over ureA (Fig. 1b). Thus, the selective destruction of processed 5′P transcripts enriches TSS-specific cDNAs (Supplementary Fig. 2). Similar patterns mark the cagA TSS15 and reveal primary and processed 5′ ends of tRNA-Phe (Fig. 1c). Altogether, 69 H. pylori TSS determined by independent methods were matched by dRNA-seq with high accuracy (Fig. 1d).\r\n\r\nGenome-wide TSS and operon maps\r\nAnnotation of 5′ ends enriched in (+) vs (-) libraries and satisfying other plausible criteria identified a total of 1,907 TSS (Supplementary Table 4). These were grouped into five categories (Fig. 2a): primary TSS having the most cDNAs within ≤500 bp upstream of annotated mRNA start codons or processed sRNAs; secondary TSS associated with the same gene but with fewer cDNAs; internal TSS within an annotated gene on the same strand; antisense TSS situated inside or within ≤100 bp of an oppositely encoded gene; and orphan TSS without annotated genes in proximity. Consequently, multiple associations of TSS are not uncommon (Fig. 2a).\r\n\r\nH. pylori was thought to lack the extensive operon structure3, 16 typical of other bacterial genomes. We complemented our TSS map with DOOR17 and conventional RNA-seq analyses to assign 87.5% of all H. pylori genes to 337 primary operons (Supplementary Table 5), presenting the first operon map based on knowledge of transcriptional initiation. dRNA-seq readily detected internal TSS of downstream cistrons within longer primary operons, predicting 126 additional suboperons and 66 monocistrons overlapping the 3′ part of polycistrons in H. pylori. Independent validation of such suboperonic signals (Supplementary Fig. 4) confirmed an acid-induced internal TSS in cag23 (Fig. 1b), supporting the known upregulation of cag22–cag18 from the primary cag25–18 operon under acid stress10. Likewise, internal TSS reveal potential uncoupling of suboperons starting with ftsH (cell division) or copP (copper transport) from the physiologically unrelated HP1067 (cheY) chemotaxis gene in the HP1067–HP1074 operon18.\r\n\r\nBacterial promoters usually contain specific sequences for binding of RNA polymerase (RNAP)-associated σ factors, for example, the -35 (TTGACA) and -10 (TATAAT) boxes of the housekeeping σ70 in Escherichia coli19. Correspondingly, motif searches at the 1,907 TSS revealed an extended Pribnow box (tgnTAtaAT) as the -10 motif of the housekeeping σ80 in H. pylori (Fig. 2b; for σ28 and σ54, see Supplementary Tables 6–8 and Supplementary Fig. 5). Intriguingly, the -35 motif is replaced by a periodic AT-rich signal upstream of position -14. Thus, consistent with earlier analysis of much fewer promoters in H. pylori20 or related Campylobacter jejuni21, our global TSS map shows that transcription in ϵ-proteobacteria initiates at extended Pribnow boxes downstream of periodic AT-rich stretches.\r\n\r\nMassive antisense transcription\r\nThe H. pylori transcriptome is highly complex (Fig. 2a), and 27% of the primary TSS are also antisense TSS, indicating that—similar to E. coli22—antisense transcription occurs across the entire H. pylori genome (Fig. 3a, Supplementary Fig. 6 and Supplementary Table 9). Because the antisense TSS are uncorrelated with local GC content (Fig. 3a), they are unlikely to reflect promiscuous transcription initiation at AT-rich hexamers. Furthermore, analysis of biological replicates (ML-/+ libraries), control experiments using actinomycin D to suppress unspecific cDNA synthesis (Supplementary Information), and independent northern blot probing (Supplementary Fig. 7), consistently show that the many detected antisense TSS are not artefacts of library construction. Rather, their high number might indicate that transcriptional initiation is an important cause of global antisense transcription in H. pylori, in addition to possible imperfect termination22.\r\n\r\nAt least one antisense TSS is associated with ~46% of all ORFs, including many housekeeping genes such as valS (valyl-tRNA synthetase) or rpl21 (ribosomal protein L21), although there is no general bias towards core or variable H. pylori genes23 (data not shown). Moreover, ~28% of the tRNAs, and the 5′ leaders of 23S and 16S rRNA precursors have antisense TSS. Notably, as H. pylori lacks endoRNases E/G and other common processing factors of stable RNAs3, antisense-guided cleavage involving the dsRNA-specific RNase III (ref. 3) might compensate for this paucity.\r\n\r\nWe identified antisense TSS for 22 of 34 putative phase-variable genes24 featuring homopolymeric tracts and dinucleotide repeats, and with functions in lipopolysaccharide biosynthesis, surface structure and DNA restriction/modification (Supplementary Table 10). Of these, the two fucT copies (HP0651/0379) encode the fucosyltransferases that modify the major Lewis antigen of H. pylori. Our discovery of antisense TSS adjacent to the 5′ poly(C) tracts involved in switching on/off the fucT genes by slipped-strand mispairing25, 26 raises the possibility of antisense regulation of surface structure variations and host interactions. Moreover, acid-stress-induced antisense RNAs opposite to known acid-stress-repressed genes (for example, rpl21, HP1186, HP0637; refs 10, 11) would indicate similar control at low pH (Supplementary Fig. 7).\r\n\r\n5′ UTRs and leaderless mRNAs\r\nThe 5′UTR (untranslated region) ranging from TSS to start codon determines the translational efficiency of messengers. In striking accordance with the structurally observed ribosome contacts27, our TSS annotation reveals that most (~50%) of the 5′UTRs are 20–40 nucleotides (nt) in length (Fig. 2c), and support the AAGGag motif28, 29 located ~6 nt (median distance) upstream of start codons as the consensus Shine–Dalgarno sequence in H. pylori (Fig. 2c). We found correlations of 5′UTR length with cellular function. For example, nucleotide- and nucleoside-related genes almost invariably have ~30-nt-long 5′UTRs, as if optimized for translation. In contrast, regulatory genes of cellular processes such as cell division, pathogenesis or transformation possess significantly longer 5′UTRs (Supplementary Fig. 8). Structural alignment of the H. pylori 5′UTRs with Rfam database families detected a thiamine pyrophosphate riboswitch upstream of pnuC. In support of the previously predicted transcriptional attenuation mechanism30, both RNA-seq and northern blot probing observed a short (~100 nt) transcript from this candidate riboswitch (Supplementary Fig. 9). Although no other known riboswitches were detected, conforming to their general paucity in Gram-negative species, there are 337 UTRs long enough (>60 nt) to harbour novel cis-regulatory RNA structures31.\r\n\r\nAlthough leaderless mRNAs are considered rare and primarily phage-associated in Gram-negative species32, we found that ~2.2% of all H. pylori mRNAs have a 5′UTR <10 nt (Supplementary Table 11). At 26 genes, including the dnaA, recR and hemH housekeeping genes, transcription initiates exactly at an AUG start codon essential for stable ribosome binding of leaderless mRNAs32.\r\n\r\nSome primary TSS lay downstream of previously annotated start codons, as exemplified by rocE (Fig. 2d). Yet, sequence conservation among Helicobacter strains strongly supported the rocE TSS mapped by dRNA-seq, as well as a new start codon ~30 bp downstream. Similarly, we propose corrections for 18 more genes (Supplementary Table 12), complementing re-annotations by genome comparison33.\r\n\r\nAn unexpected wealth of Helicobacter sRNAs\r\nPrevious annotations in H. pylori predicted stable tRNAs, rRNAs, transfer-messenger RNA (tmRNA), RNase P and signal recognition particle RNA (SRP RNA), all of which were here confirmed to be expressed. Moreover, the dRNA-seq data predicted hundreds of additional sRNA candidates (denoted HPnc) from intergenic regions, antisense to ORFs, and also sense within ORFs (Fig. 3a; Supplementary Fig. 10 and Supplementary Table 13). We have so far validated the expression of ~60 new sRNAs by independent northern blot experiments (Supplementary Figs 10–14 and Supplementary Table 14), among these are all five members of a ~200 nt sRNA family whose multiplicity is reminiscent of the Qrr sRNAs that control quorum sensing and virulence in Vibrio bacteria34.\r\n\r\nWe have also identified 6S RNA (~180 nt), an abundant and ubiquitous riboregulator of RNAP. 6S RNA notoriously failed to be discovered in the ϵ-subdivision31, 35, 36, perhaps because it is expressed antisense to HP1219 (Fig. 3b,c), a poorly conserved hypothetical ORF (Supplementary Fig. 15). Structural probing experiments in vitro (Fig. 3d) and conservation analysis (Supplementary Fig. 16) indicate that H. pylori 6S RNA adopts the characteristic structure of a long hairpin with a central asymmetric bulge by which E. coli 6S RNA sequesters RNAP35, 36, 37. To disentangle itself, RNAP uses 6S RNA as template for transcription of 14–20 nt RNA products (pRNAs)37. We detected two classes of pRNAs in H. pylori (Fig. 3b), one starting with the corresponding bulge-internal adenosine of E. coli pRNAs37, and the other (pRNA*) originating from the opposite strand as previously observed with certain 6S RNA mutants in vitro (K. Wassarman, personal communication). Our in vivo detection of pRNAs in a remote relative of E. coli shows that 6S RNA regulation of RNAP activity is a widely conserved mechanism.\r\n\r\nSeveral of the new H. pylori sRNAs seem as abundant as 6S RNA (Fig. 3a), and most of them are conserved at the sequence level among Helicobacter species but not outside the ϵ-subdivision (data not shown). In global structural clustering analysis assaying conservation of functional secondary structure rather than primary sequence, we observed that whereas the γ-proteobacterial sRNAs of E. coli and Salmonella form large groups of similar structures, the H. pylori sRNAs fall in small groups exhibiting specific structural motifs (Supplementary Fig. 17). Thus, except for 6S RNA and housekeeping RNAs, ϵ-proteobacteria including H. pylori might have evolved a unique sRNA repertoire.\r\n\r\nMany sRNAs in other bacteria repress trans-encoded mRNAs by short base-pairing in the 5′UTR5, 6. Here, the TargetRNA program38 predicted an interaction of the abundant HPnc5490 sRNA with the 5′UTR of tlpB encoding a canonical chemotaxis receptor of H. pylori (Fig. 4a). The involvement of accessible loop residues of HPnc5490, and the calculated RNA duplex strength (ΔG = -34.3 kcal mol-1) added confidence to this prediction. An HPnc5490 deletion mutant was generated, and observed to have increased levels of the ~60 kDa TlpB protein (Fig. 4b) and the tlpB-HP0102 operon mRNA, yet normal expression of the remaining canonical chemotaxis receptor genes, tlpA and tlpC (Fig. 4c). Thus, HPnc5490 probably regulates tlpB as a trans-antisense RNA.\r\n\r\nWe identified a family of six structurally related ~80 nt sRNAs expressed antisense to small ORFs of homologous 22–30 amino acid peptides (Fig. 4d, e and Supplementary Fig. 18), henceforth referred to as IsoA1-6 (RNA inhibitor of small ORF family A) and aapA1-6 (antisense RNA-associated peptide family A), respectively. Five of the aapA ORFs produced stable mRNAs in vivo (Fig. 4e). In vitro translation assays yielded the expected small peptides, except for aapA2 mRNA whose Shine–Dalgarno sequence is mutated in strain 26695 (not shown). Furthermore, translation of aapA1 or aapA3 was strongly and specifically inhibited in the presence of the cognate IsoA1 or IsoA3 sRNAs (Fig. 4f), thus revealing candidates of cis-antisense regulation in H. pylori.\r\n\r\nThe AapA peptides are conserved in other H. pylori strains (Supplementary Fig. 19) and might interact with membranes, as suggested by their predicted high hydrophobicity and α-helical structure (Fig. 4d and Supplementary Fig. 20), as well as similarities to Antimicrobial Peptide Database39 entries such as human defensin LL-37. Therefore, the aapA–isoA loci might be toxin-antitoxin systems that slow down growth of H. pylori or other organisms in the gastric mucosa, protect against phages, or facilitate the proposed (though controversial) altruistic autolysis of H. pylori40 which was postulated to involve as yet unknown <3.5 kDa hydrophobic peptides41. Whereas the AapA peptides remain to be detected in vivo, our prediction of additional conserved 10–60 amino acid peptides (Supplementary Table 15 and Supplementary Figs 20–21) shows that small ORFs are more common in Helicobacter species than appreciated. Moreover, the intriguing similarities of three antisense RNA-associated peptides (aapC1/2, aapD) of H. pylori with the hydrophobic Ibs family42 of E. coli indicate that such loci might be spread via horizontal gene transfer.\r\n\r\nConcluding remarks\r\nOur single nucleotide resolution TSS map constitutes the third global reference data set for the model organism H. pylori strain 26695, complementing its genome sequence3, 4 and global protein–protein interaction map43. The data provide new insights into the organization of the H. pylori transcriptome, and provide a framework for better analysis of individual genes. Knowledge of the vast majority of H. pylori TSS and operons will help evaluate unclear phenotypes of transposon insertions44, 45, and eliminate unwanted antisense transcripts in heterologous expression constructs of H. pylori vaccine candidates. Altogether, ~100 sRNAs are known in E. coli5, the model organism of bacterial RNA research. Corrected by genome size, H. pylori rivals E. coli despite the lack of a conserved Hfq protein. Combined with the success of artificial antisense RNAs in H. pylori46, our results show that many RNA-mediated regulations are yet to be discovered in ϵ-proteobacterial pathogens.\r\n\r\nOther RNA-seq studies detected termini of bacterial transcripts8 but could not unequivocally assign TSS due to lack of 5′ group discrimination. As 5′PPP ends mark native transcripts in all eubacteria, dRNA-seq should help improve the genome annotations of other organisms, alone or through metatranscriptomics47. It could also complement the popular CAGE48 technique for eukaryotic mRNAs because their cap structure blocks terminator exonuclease. Moreover, an improved dRNA-seq protocol might permit detection of processed 5′ hydroxyl ends that unlike the more prominent 5′P ends are not presently captured in the (-) library. Semi-quantitative analysis of TSS coverage revealed considerable gene expression changes in H. pylori grown along with eukaryotic cells (Supplementary Table 16). Thus, dRNA-seq has the potential to unravel gene expression in pathogens and perhaps also their hosts during infections.", user_id: 3, journal_id: 1, field_id: 8, institution_id: 10});

paper13 = Paper.create!({title: "Robust Growth of Escherichia coli", body: "Summary\r\nThe quantitative study of the cell growth [1, 2, 3, 4 and 5] has led to many fundamental insights in our understanding of a wide range of subjects, from the cell cycle [6, 7, 8 and 9] to senescence [10]. Of particular importance is the growth rate, whose constancy represents a physiological steady state of an organism. Recent studies, however, suggest that the rate of elongation during exponential growth of bacterial cells decreases cumulatively with replicative age for both asymmetrically [11] and symmetrically [12 and 13] dividing organisms, implying that a “steady-state” population consists of individual cells that are never in a steady state of growth. To resolve this seeming paradoxical observation, we studied the long-term growth and division patterns of Escherichia coli cells by employing a microfluidic device designed to follow steady-state growth and division of a large number of cells at a defined reproductive age. Our analysis of approximately 105 individual cells reveals a remarkable stability of growth whereby the mother cell inherits the same pole for hundreds of generations. We further show that death of E. coli is not purely stochastic but is the result of accumulating damages. We conclude that E. coli, unlike all other aging model systems studied to date, has a robust mechanism of growth that is decoupled from cell death.\r\n\r\nResults and Discussion\r\nTo follow a large number of cells inheriting the same pole and their progeny for many generations, we employed a high-throughput, continuous, microfluidic liquid-culture device that we built by using a standard soft-lithographic technique that others had developed for cell biology studies [14, 15, 16 and 17]. Our device consists of a series of growth channels, oriented at right angles to a trench through which growth medium is passed at a constant rate (Figure 1A). This constant flow results in diffusion of fresh medium into the growth channels as well as removal of cells as they emerge from the channels into the main trench (Figure 1A). We measured the timescale of nutrient uptake by E. coli by using the fluorescent glucose analog (2-NBDG) and found that diffusion into the channels is much faster (∼1 s) than the timescale of nutrient uptake (∼2–3 min; Supplemental Experimental Procedures, available online), ensuring steady-state conditions for all cells. The cell at the end of the growth channel, distal to the trench, is referred to as the “old-pole mother cell” (or mother cell) because one of its poles, abutting the end of the channel, is inherited from one generation to the next ( Figure 1A). The diameter of the growth channels prevents the mother cell from moving around. The replicative age of the mother cell, defined as the number of consecutive divisions from the young-pole daughter cell [ 12], increases by one generation at each cell division ( Figure 1B). It is noteworthy that this device, which we call the “mother machine,” allows us to follow cells for numbers of generations that are orders of magnitude greater than has been possible with other single-celled organisms, including Saccharomyces cerevisiae [ 18] and E. coli [ 12 and 13] (see Experimental Procedures; Movie S1 and Movie S2).\r\nWe studied two distantly related strains of E. coli, B/r and MG1655, which constitutively express yellow fluorescent protein (YFP) from a chromosomal copy of the yfp gene, allowing visualization of the cells via live microscopy ( Figure 1C). A typical time series of a single growth channel from the beginning of the experiment until death of the mother cell is shown in the top panel of Figure 1D (which we constructed from the time series images by following the growth channel indicated by the dotted yellow box in Figure 1C; see Movie S2). This temporal montage shows the fluorescence level (YFP) of the mother cell and her progeny over time during the reproductive lifetime of the mother cell ( Figure 1D [middle panel]). A cell length-versus-time curve was constructed for every cell in all of our experiments (e.g., Figure 1D, bottom panel). This curve is well approximated by a straight line in a semi-log plot (see the inset of Figure 1D). That is, each interval between birth and division can be fitted via a single exponential function to give the growth rate of the cell at that replicative age. The spikes that appear at random intervals in the size distribution are the result of limited filamentation, as discussed in detail below.\r\nThe growth rate of individual cells showed a striking long-term stability over hundreds of generations, as indicated by the average-growth-rate-versus-replicative-age curves of the old-pole mother cells (Figure 2). The growth rate remained constant under our experimental conditions, for both MG1655 and B/r. In contrast to this long-term stability, the growth rate of the old-pole mother cell showed only weak correlation between two consecutive cell cycles. Mother cells exhibited fast fluctuations with a timescale of less than one generation and a Gaussian distribution (Figure 2 inset; Figure 3A). The daughter cells also showed the same growth-rate statistics as the mother cells, as we summarize in Figures S1 and S2. In other words, the cell “forgets” immediately upon division how fast it was growing in the previous cell cycle.\r\nThe observed stable growth is mirrored by the stable protein synthesis reflected in the long-term constant fluorescence level of the mother cell and its progeny (Figure 1D, top two panels). Like the growth rate, the YFP fluorescence level also shows a short-time correlation of one to two generations, consistent with previous findings in E. coli and human cells [ 19 and 20] ( Figure 3B). Our results showing the long-term stability of growth and protein synthesis, accompanied by their short-term memory, argue strongly against a built-in growth-based aging mechanism in E. coli. In other words, in E. coli cultures, all cells will be in the same steady state of growth and will be indistinguishable from one another regardless of their replicative age.\r\nAlthough our experiments unambiguously show that growth and protein synthesis are characterized by short-term correlations, surprisingly, further analysis revealed an unexpected long-term correlation that spans dozens of generations. Specifically, at a critical replicative age of the first 50 generations, we noted a striking increase in filamentation of the mother cells of MG1655 (the “spikes” seen in Figure 1D bottom panel; Figure 3C; Figure S3). Importantly, the filamentation rate of the daughter cells remained practically constant, and thus the increased filamenation of the mother cell cannot be due to illumination. This means that the mother cell must inherit an unknown “factor” that serves as a long-term memory from one generation to the next and causes filamentation independently of growth and protein synthesis. Indeed, filamentation in Figure 1D occurs at intervals such that its distribution follows a power law characterized by a long tail (Figure 3D). (Note that random events will produce an exponential [“memory-less”] distribution.) Such a long-term effect could not have been detected by more conventional timelapse experiments of an exponentially growing population because it requires observation of the mother cell's inheriting the same old pole for hundreds of generations.\r\nBecause filamentation is a hallmark of the SOS response in bacteria, we asked how its suppression would affect our observation of filamentation. For this purpose we constructed an MG1655 derivative carrying a lexA allele, lexA3, whose protein product constitutively represses SOS gene expression even under conditions of DNA damage. Although the lexA3 mutant behaved virtually the same as MG1655 in terms of a constant growth rate, its filamentation rate, which was constant at approximately 1%, was significantly reduced, as expected. Note that B/r lacks sulA, a key SOS gene that inhibits cell division during the SOS response, and also shows a similar low filamentatin rate ( Figure S3). A more important difference between lexA3 and MG1655 is that, with a constant death rate of 2.7% per cell per generation, the population of the lexA3 mutant cells decayed exponentially ( Figure 4).\r\nThese findings have important implications for the cause of cell death. That is, the death of the lexA3 mutant is random and requires the SOS response for survival. The much slower death rate of wild-type MG1655 cannot simply be due to a purely stochastic, age-independent fluctuation in DNA damage or metabolism; otherwise, we would have observed an exponential decay like that of the lexA3 mutant ( Figure 4). Instead, death of MG1655 is probably caused by a growth-independent inheritance and accumulation of a lethal “factor” as indicated by the long-term correlation observed in the mother cell described above. It is possible that this “factor” corresponds to protein aggregates that are asymmetrically distributed in E. coli and which are described in recent work [ 13 and 21]. An alternative but not mutually exclusive idea is that the physically aging cell wall at the pole accumulates defects as a result of its metabolic inertness [ 22], which also could be linked to the lethal element.\r\nIn previous work by Stewart et al. [12], it was found that the growth rate of the mother cell decreased cumulatively with replicative age, about 2% per generation. Although our results show otherwise, this could be due to the differences in the experimental conditions, e.g., two-dimensional surface on an agar pad (Stewart et al.) versus one-dimensional growth channel where fresh liquid medium is constantly supplied (current study). In addition, we excluded the data from the first ten generations of replicative age to ensure that our results reflect steady-state growth conditions. Nevertheless, we note that the average generation times of the mother cells of B/r, MG1655, and lexA3 mutant are in precise agreement with the generation time measured from the growth curves of the liquid culture (see Experimental Procedures). This strongly argues that, in our study, it is unlikely that there is a decrease of the growth rate of the mother cell regardless of its replicative age, i.e., all cells are in the same steady state of growth.\r\nIn summary, using the microfluidic mother machine, we have shown a striking constant growth rate of the mother cells of E. coli and their immediate sister cells for hundreds of generations. Also, from the qualitative difference in the death rate between MG1655 and its lexA3 mutant derivative, we concluded that the death of E. coli cells cannot be due to random events such as DNA damage but must be a consequence of growth-independent accumulation of a lethal element. These observations have been made possible because the mother machine allows us to follow a large number of cells for a long time at the single-cell level in a precisely controlled environment and produces amounts of data comparable to data from studies at a population level (e.g., FACS). Our experimental approach can be directly and immediately applied to a wide range of problems.\r\nIn our view, the most important lesson from our study is that E. coli must have a very robust mechanism of growth. The next major challenge, then, is to understand the origin of the stability of bacterial growth. Understanding it at the systems level may shed a new light on an important related question, i.e., how replication and division are coupled via growth and coordinated robustly in bacteria in the absence of eukaryotic-like checkpoints [ 23].\r\n\r\nExperimental Procedures\r\nGrowth Condition, Microscopy, and Microfluidics\r\nCultures were grown overnight in Luria-Bertani (LB) at 37°C. The next day, 30 μl of the overnight culture was back diluted in 3 ml of fresh LB at 37°C. At OD450 = 0.2 to 0.3 (or OD600 = 0.1 to 0.15), the cell culture was 10× concentrated by centrifugation for injection into the mother machine. The cells were loaded by diffusion until more than 80% of the channels were filled with the cells. Fresh LB medium was infused by a syringe pump. For each experiment, images were acquired from 10–12 fields at 1 min intervals via NIS-Elements software and a Nikon Eclipse Ti fluorescence microscope equipped with a motorized stage and a CCD camera (Photometrics CoolSnap HQ2). We tested a wide range of dosages by varying the exposure time (1.5–4.0 s) and the intensity of the illumination light by using neutral density filters (ND32 to ND128; ND128 means that only 1/128 of the illumination light is used for imaging). Above ND32 and up to 2 s of exposure time, the growth rate and generation time measured in the mother machine precisely agreed with that measured from the growth curve for both E. coli strains B/r and MG1655 used in our studies: MG1655 = 20.9 ± 0.3 min, MG1655 lexA3 = 20.7 ± 0.8 min, B/r D = 22.6 ± 0.4 min.\r\nOur device consists of 4000 growth channels and an automated microscope stage, which we use to continuously scan 10–12 fields of view for 72 hr at 1 min intervals (Movie S1). Because each field of view contains ∼102 cells at 100× magnification (Figure 1C), we acquired and processed images of ∼106–107 individual cells per experiment. See Supplemental Experimental Procedures for more details.\r\n\r\nImage Analysis and Data Acquisition\r\nUsing C++, we designed custom software was to analyze time-lapse images. Our software has a user-friendly interface similar to that of ImageJ, as shown below. Because each experiment generated about 50,000–100,000 images, each containing ∼102 cells, we analyzed typically ∼107 cells per each time-lapse experiment. The current version of our software can complete analysis in about 3–5 hr on a standard desktop PC, which is significantly faster than other software developed with more high-level programming languages such as Matlab. We performed segmentation of cells directly on fluorescence images by finding basins of intensity along the channel direction.\r\n\r\nBacterial Strains\r\nThe wild-type strains of Escherichia coli MG1655 and B/r D were modified so that they expressed the gene encoding the yellow fluorescent protein (YFP) under the control of the constitutive promoter λPR (gene construct from M. Elowitz [ 24]). The YFP gene, along with a chloramphenicol resistance gene, was inserted in the intC locus by P1 transduction from M. Elowitz's MRR strain (Elowitz 2002) and selection for chloramphenicol resistance. The lexA3 allele, present in strain RB258 [ 25], was introduced into MG1655, along with the closely linked marker malE::Tn5, by P1 transduction, with selection for kanamycin resistance. The MG1655 strain used is the poorly motile strain that does not contain an IS1 insertion sequence element in the regulatory region of the flhD promoter [ 26] (CGSC 6300 of the E. coli Genetic Stock Center).\r\n\r\nAutocorrelation Function\r\n\r\nThe normalized autocorrelation function A(Δt) has been calculated as follows:\r\nequation(1)\r\nA(Δt)=i〈(I(t+Δt)−〈I(t+Δt)〉t)·(I(t)−〈I(t)〉t)〉/i〈〈(I(t)−〈I(t)〉t)2〉t〉,\r\nwhere I(t) denotes the quantity of interest at time t (e.g., YFP intensity, cell length). 〈〉t and 〈〉i denote average over time and cells, respectively. From the typical timescale of decay of the (normalized) autocorrelation function, we can estimate how long the memory of the process lasts, for example, by measuring how fast it drops from 1 to 0.5. If A(Δt) decays exponentially as exp(−t/τ), the inverse decay constant τ is defined as the correlation time of the process. However, if A(Δt) decays slowly, e.g, as a power-law t-α, where α is the exponent, there is no intrinsic timescale associated with the process. In this case, the process is said to have a long-term memory.\r\n\r\nFilamentation\r\nWe considered a cell to be filamentous if its new-born cell size was larger than the population average by more than 2σ, where σ is the standard deviation of the cell-size distribution. In our experiments, filaments were visually obvious (Figures 1C and 1D) and well-separated from the normal cells in the size distributions (Figure S2B), and our results are insensitive to the choice of the threshold. To compute the filamentation intervals, we only counted intervals between new filamentations developed from a normal sized cell. For example, the double spikes around 1250 min in Figure 1D are counted as a single filamentation event.", user_id: 3, journal_id: 9, field_id: 8, institution_id: 11});

paper14 = Paper.create!({title: "High-Resolution Analysis of Parent-of-Origin Allelic Expression in the Mouse Brain", body: "Abstract\r\nGenomic imprinting results in preferential expression of the paternal or maternal allele of certain genes. We have performed a genome-wide characterization of imprinting in the mouse embryonic and adult brain. This approach uncovered parent-of-origin allelic effects of more than 1300 loci. We identified parental bias in the expression of individual genes and of specific transcript isoforms, with differences between brain regions. Many imprinted genes are expressed in neural systems associated with feeding and motivated behaviors, and parental biases preferentially target genetic pathways governing metabolism and cell adhesion. We observed a preferential maternal contribution to gene expression in the developing brain and a major paternal contribution in the adult brain. Thus, parental expression bias emerges as a major mode of epigenetic regulation in the brain.\r\n\r\nParent-of-origin effects influence gene expression and trait inheritance in offspring.\r\nGenomic imprinting is a form of epigenetic regulation that results in the preferential expression of the paternally or maternally inherited allele of certain genes (1). Currently, fewer than 100 imprinted genes have been identified, and the evolutionary pressures that underlie imprinting are debated (2, 3). Clinical and experimental data suggest roles for imprinting in regulating brain development and function (4). In humans, Prader-Willi syndrome (PWS) and Angelman syndrome (AS) result from a deletion of the paternal or maternal copy of 15q11-q13, respectively. PWS is associated with hyperphagia, stubbornness, and compulsive traits (5), whereas AS is associated with absent speech, happy affect, and inappropriate laughter (6). Further, studies of parthenogenetic (PG) and androgenetic (AG) chimeras in the mouse have suggested preferential maternal contribution to the development of the cortex, but preferential paternal contribution to the hypothalamus (7, 8). Such biased roles have yet to be clearly demonstrated. Moreover, despite tantalizing reports, our understanding of the neural systems governed by imprinted genes and of the scope and features of imprinted loci expressed in the brain is very limited.\r\nImprinting refers to functional differences between the maternal and paternal chromosomes or alleles (9) and is also used more strictly to define complete allele-specific silencing (10). Known imprinted genes have been shown to display all-or-none and biased allelic expression according to the gene and tissue considered (11, 12). We report here a genome-wide analysis of parental allelic effects involving complete silencing or parental biases in gene expression in the murine embryonic day 15 (E15) brain, and in the adult male and female cortex [medial prefrontal cortex (mPFC)] and hypothalamus [preoptic area (POA)]. Together with a companion study (13), our data suggest that substantial maternal and paternal biases in gene expression originate from the X chromosomes and autosomes, respectively. These results may shed light on gene regulatory processes underlying brain function, evolution, and disease.\r\n\r\nImprinted gene expression in the adult CNS.\r\nTo gain insight into neural systems affected by imprinting, we performed an in silico study of the expression pattern of known imprinted genes in the adult brain (14). The expression pattern of 45 known imprinted genes was investigated across 118 distinct adult brain regions in the Allen Brain Atlas (Fig. 1 and fig. S1). A heat map based on the relative number of known imprinted genes expressed in a given brain region identified 26 out of 118 brain regions as hotspots for the expression of imprinted genes, whereas the expression hotspots of 20 randomly selected control genes with known biallelic expression were located mainly in cortical and olfactory regions and appeared entirely distinct from that of imprinted genes (Fig. 1 and fig. S1). Brain regions predicted from earlier studies to be enriched for imprinted gene expression indeed emerged as hotspots, such as the medial preoptic area (MPOA), which regulates mating, maternal behavior, and thermoregulation (15). From our data, aminergic systems and neural systems associated with feeding and motivated behaviors constituted the largest source of imprinting hotspots. These included the arcuate nucleus, dorsal raphe, substantia nigra pars compacta, ventral tegmental area, dorsal hypothalamic area, locus ceruleus, and nucleus accumbens (16, 17). These findings enticed us to perform a more detailed and large-scale analysis to characterize and compare parent-of-origin effects governing gene expression in distinct brain regions.\r\n\r\nA high-resolution approach to analyze imprinting.\r\nWe used Illumina RNA-sequencing (RNA-Seq) technology to characterize the transcriptome of brain tissues from F1 hybrids resulting from reciprocal crosses of CAST/EiJ (CAST) and C57BL/6J (C57) mice [F1 initial cross (F1i): CAST mother × C57 father; F1 reciprocal cross (F1r): C57 mother × CAST father]. Single-nucleotide polymorphisms (SNPs) were identified by separately sequencing the CAST and C57 transcriptomes of the original parents (or parental strains for the E15 brains), and the subsequent base calls were used to distinguish transcription from maternal and paternal alleles in F1i and F1r [table S1 and figs. S2 and S3 and supporting online material (SOM) (14)]. We characterized parent-of-origin effects governing gene expression in the E15 brain, as well as the adult male and female mPFC and POA. For the current study, male and female samples were treated as biological replicates. This approach is appropriate for the detection of parental effects that are independent of the sex of the offspring.\r\nImprinting was assessed by chi-square tests in both initial and reciprocal crosses as described in the SOM. The total number of SNP sites exhibiting a significant parent-of-origin effect was determined for a range of chi-square P-value cutoffs (0.001 to 0.2) and compared with the number expected by chance (Fig. 2A). We selected a cutoff of P < 0.05 for each cross [E15 false-discovery rate (FDR) = 0.06, POA FDR = 0.1, mPFC FDR = 0.1]. Our approach yields highly accurate and reproducible results, as demonstrated by multiple controls detailed in the SOM (14). Scatter plots of the –log (P) for the F1i and F1r data for each SNP site clearly indicated exclusive selection of paternally and maternally expressed loci relative to the total data set (Fig. 2B and fig. S4). Overall, SNPs identified by our approach (excluding mitochondrial and X-chromosome SNP sites) exhibited a robust parental expression bias with a mean of 87 ± 15% (mean ± SD). Parent-specific biases emerged as a continuum from the data set, which suggested that imprinting may manifest as relative allele-specific expression bias, rather than strict monoallelic transcription, or that allelic bias is cell-type specific and is partially masked by cellular heterogeneity in brain samples (Fig. 2B and fig. S4). As our approach includes sequencing of transcriptomes from parents and hybrid offspring, as well as increased sequence depth, this likely contributes to differences in results between our study and previous studies (18, 19).\r\n\r\nGenome-wide analysis of imprinting.\r\nImprinted genes and genes with imprinted features were identified by the presence of one or more SNP sites exhibiting a significant paternal or maternal expression bias, as described above. This approach enabled us to identify 1308 candidate imprinted loci, among which were 824 genes annotated in the University of California Santa Cruz genome database (UCSC) (5.7% of the ~14,520 genes assessed) (Fig. 2C and table S2) and 484 putative noncoding RNAs (ncRNAs) annotated in the functional RNA database (fRNAdb) (4.1% of the 11,545 ncRNAs assessed) (Fig. 2C and table S3). Of these, 604 have known human orthologs. Of the 86 previously known imprinted genes, 72 were expressed in one or more brain regions and contained SNPs above the 10-read minimum cutoff. Among those, 47 were called imprinted, whereas the remaining 25 exhibited biallelic expression in all brain regions tested. Of the 484 ncRNAs associated with parental allelic effects on the basis of alignments to the fRNAdb, we classified 82 as “known” based on genomic positions directly or closely associated with previously known imprinted ncRNAs, including Apeg3, Copg2as, Air, Nespas, H19, Peg12, Snurf/Snrpn/Ube3aas, Gtl2, and Rian (20).\r\nA gene ontology analysis revealed that biological processes associated with parental allelic effects are mostly related to metabolic processes in the developing brain (e.g., primary metabolic process, FDR = 4.11E-14), and to cell adhesion in the adult brain (e.g., cell adhesion, FDR = 1.45E-8) (table S4). These findings are striking in light of previous work that identified roles for imprinted genes in growth, feeding, metabolism, and thermoregulation (2). We report here and in our companion study (13) parental allelic effects at key conserved regulators of metabolism, such as interleukin-18 (Il18) (13) and the mitochondrial ribosomal protein Mrpl48 (21), as well as cell adhesion, such as cadherin 15 (cdh15).\r\n\r\nCharacterization of gene clusters with parent-of-origin allelic effects.\r\nAnalysis of the genomic distribution of all loci identified in our study shows a scattered distribution across all chromosomes (fig. S5). An algorithm was applied that searched for >2 imprinted genes and/or ncRNAs residing within a 1-Mb window. This window size correctly identified previously characterized imprinted gene clusters (e.g., H19-IGF2, Mest-Copg2, and Dlk1-Gtl2), with the exception of the 4-Mb-long PWS-AS cluster that splits into two clusters (table S5). This analysis identified 204 putative imprinted gene clusters, which encompass 65% of the genes and ncRNAs identified in our study. The presence of imprinted ncRNAs has been demonstrated to play a critical role in the regulation of imprinting for many known imprinted gene clusters (1), and 106 (52%) of these candidate clusters contained both coding and putative noncoding loci (table S5). For a summary of data for known imprinted gene clusters, see fig. S6.\r\nOur approach identified features in imprinted gene clusters known to be associated with brain functions and disorders. For example, Peg13 and Kcnk9 [linked to Birk-Barel mental retardation (22)] were found to be part of a larger cluster that includes 1810044A24Rik [also called Trappc9 and linked to mental retardation (23)], several maternally expressed ncRNAs, and a maternally expressed gene (MEG), Eif2c2 (argonaute2) (Fig. 3, A and B). From our data, it appears that 1810044A24Rik undergoes isoform-specific imprinting, which is revealed by SNPs within the unique exon and 3′ untranslated region (3′UTR) of the uc007wbn.1 isoform, that are all paternally expressed. SNPs located in the exons shared by all other isoforms (uc007wbp.1, uc007wbm.1, and uc007wbl.1) are maternally expressed.\r\nIn the PWS-AS cluster, we uncovered a large region between Snrpn and Ndn that hosts numerous paternally expressed imprinted ncRNAs, including two predicted microRNAs (mir-344 and mir-344-2) (Fig. 3C). Sequenom DNA analysis of allele-specific expression with an independent cohort of animals replicated the Illumina RNA-Seq results and clearly revealed strict paternal expression of the DOKist4 gene within this region (Fig. 3D).\r\n\r\nBrain region– and developmental stage–specific parent-of-origin allelic effects.\r\nA total of 553 UCSC genes associated with parental allelic effects were uncovered in the E15 brain, compared with 256 in the adult POA (P < 0.001; χ2 analysis) and 153 in the adult mPFC (P < 0.0001; χ2 analysis) (Fig. 4, A and B). Sixty-one percent of genes identified in the E15 brain were MEGs, which revealed a significant maternal bias in the developing brain [paternally expressed genes (PEGs), 215; MEGs, 338; P < 0.0001; χ2 analysis) (Fig. 4A). In contrast, a paternal bias was observed in both the adult POA (PEGs, 172; MEGs, 84; P < 0.0001; χ2 analysis) and the adult mPFC (PEGs, 109; MEGs, 44; P < 0.0001; χ2 analysis), such that ~70% of genes identified in the adult brain were PEGs. The observed parental allelic biases were statistically significant through a range of different P-value cutoffs (P < 0.03, P < 0.05, and P < 0.1) that increased the total number of genes by more than threefold, which indicated a robust signal-to-noise ratio in the data. The biases were not present at higher P-value cutoffs (P < 0.9).\r\nOf the 824 UCSC annotated genes associated with parental allelic effects in the E15 brain, POA, or mPFC, 769 (93%) were expressed and had SNP site read depths above the cutoff of 10 in all of the three target brain tissues. However, most demonstrated a significant parental expression bias in only one of the target tissues (Fig. 4B). A majority was found exclusively in the E15 brain, including 73% of all MEGs. Further, only five PEGs were shared between the adult POA and mPFC, and 74% of the genes imprinted in all three samples were PEGs. These results suggest that parental influence over gene expression is highly spatially and temporally regulated in the brain.\r\nTwo examples of this phenomenon are detailed here and in the SOM (figs. S7 and S8). The Igf2-H19 locus has been linked to colorectal and other forms of cancers (24), Beckwith-Wiedemann syndrome (BWS) (24), and Silver-Russell syndrome (25). H19 is a maternally expressed ncRNA (26), and Igf2 is a canonical PEG that promotes placental and embryonic growth (2). In endodermal and mesodermal cell lineages, the reciprocal parental expression of the two genes is due to a competition for promoter access to a shared set of enhancers located downstream of H19 (27, 28). Maternal H19 expression is directly involved in regulating the paternal expression of Igf2 (29). Previous studies have suggested that imprinting at this locus is more complex in the brain (29–31).\r\nOur data document maternal expression of H19 and paternal bias of Igf2 in the E15 brain (Fig. 4, C and D). H19 is not expressed in the adult mPFC or POA, and 80% of Igf2 transcription in the adult male and female POA and mPFC originates from the maternal allele (Fig. 4, C and D). These data were confirmed by Sequenom DNA analysis on a distinct cohort of animals (Fig. 4D). Similarly, a gene cluster encompassing Grb10 and dopa (3,4-dihydroxyphenylalanine) decarboxylase (Ddc) displays spatiotemporally regulated parental allelic effects (figs. S7 and S8).\r\nThese examples, and the reproducibility of the parental allelic biases in independent male, female samples, and by Sequenom DNA analysis, highlight the extraordinary complexity of parental influence over transcription in the CNS.\r\n\r\nComplex parent-of-origin allelic effects in the brain.\r\nThree general categories of genes with parent-of-origin expression bias emerged from our analysis in known loci, as well as newly identified loci, which we term consensus, complex, and single SNP loci (Fig. 5A and tables S6 to S12). Consensus loci have multiple SNPs, at least one SNP site above the P-value cutoff of 0.05 in each cross, and 100% of SNPs agree with the direction of the parental expression bias in both the F1i and F1r cross. Complex loci have multiple SNPs, with one or more SNPs above the P-value cutoff and one or more SNP sites that differ (i.e., biallelic expression, strain, or opposite parental bias). Finally, a subset of genes had a single SNP site or multiple SNPs within 32 base pairs of each other (the size of a single read). Thirty-five of the 47 previously known imprinted genes displayed consensus imprinting in at least one brain region (table S6). However, several of these same genes also exhibited complex imprinting in other samples, such that 41 known imprinted genes were identified as complex in one or more brain regions. Seven known imprinted genes were identified on the basis of a single SNP site (Fig. 5A). Detailed analysis of the positions of SNPs with parental allelic bias within complex loci revealed genes in which monoallelic SNPs are confined to a specific exon (195 genes), to the 3′UTR (final exon) (57 genes), or to both a specific exon and the 3′UTR region (39 genes) (Fig. 5B), which suggests that, in these genes, the parental allelic effect is restricted to only one or a few transcript isoforms. In a subset of these cases, the same parental bias is confirmed by multiple SNPs in the exon or 3′UTR (Fig. 5B). A large proportion of the genes exhibited parental effects in the last exon (including 3′UTR region), but involved disagreements between SNP sites in the same region of the gene [classified as “other” (560 genes)]. In some cases, as detailed below, these disagreements appear to be related to the fact that only a subset of the SNPs for a given complex gene are able to distinguish a specific imprinted isoform from other overlapping transcripts arising from the same locus.\r\nCadherin 15 (cdh15), a gene prospectively linked to intellectual disability in humans (32), emerges as a consensus imprinted locus, in which all three SNPs display preferential expression of the paternal allele in independent male and female samples (Fig. 5C) and by Sequenom DNA analysis on an independent cohort of animals (Fig. 5C). Other notable consensus imprinted genes include Bcl2l1, a major regulator of apoptosis linked to cancer (33), and Eif2c2 (also called argonaute2), involved in microRNA and short-interfering RNA (siRNA)–mediated gene silencing (34) (table S6).\r\nDetailed analysis of complex loci revealed remarkable and so far unsuspected features of parent-of-origin transcription bias (tables S7 to S11). In the Inpp5f locus, three isoforms have previously been described (Fig. 5D) with preferential paternal expression of Inpp5f_v2 and Inpp5f_v3, while Inpp5f_v1 was reported biallelic (35). In our analysis, SNP sites aligning to the Inpp5f_v2 and Inpp5f_v3 isoforms confirmed strict paternal expression. Four SNP sites located in exons shared by the Inpp5f_v1 isoform and an overlapping UCSC annotated transcript (mKIAA0966) indicated a modest and nonsignificant paternal bias in expression in the adult mPFC and E15 brain. However, in the adult male and female POA, 73% of transcription at these sites (P < 0.01, in F1i and F1r cross) originated from the maternal allele. A single SNP found in the first exon of Inpp5f_v1 indicated a modest, nonsignificant maternal expression bias in POA. Thus, our approach resolved complex regional-, developmental stage– and isoform-specific parental bias in the transcriptome.\r\nRecently, a highly complex form of imprinting has been described for the gene H13, such that some H13 isoforms are maternally expressed, whereas others are paternally expressed (36). Our analysis confirmed these results (fig. S9). Here we find that Herc3, a host gene for the known PEG Nap1l5, showed features indicative of isoform-specific imprinting in a manner similar to that for H13 (fig. S10). Additional examples of complex parent-of-origin effects in the CNS transcriptome are presented in the SOM for Lsm14a, Pafah1b3, and Ndel1 (fig. S11). Other notable complex loci include cdh2 (neuronal-cadherin), which plays a central role in brain morphogenesis (37), as well as arnt2 (aryl hydrocarbon receptor nuclear translocator 2), a gene with multiple isoforms that regulates hypothalamic development in concert with other imprinted genes, such as Ndn (38). Many genes identified in our analysis exhibited complex patterns of parental allelic effects for which the underlying mechanism and functional significance are not yet clear.\r\nFinally, several loci in our data set did not display the classical pattern associated with parent-of-origin expression biases but, instead, displayed significant differences in the relative expression of the maternal and paternal alleles in F1i versus F1r offspring, which we refer to as cross-effects. These effects were analyzed separately, and the findings are detailed in the supplemental data (fig. S12).\r\n\r\nDiscussion.\r\nOur study documents over ~1300 protein-coding genes and putative ncRNAs associated with parental allelic effects in expression in the brain. The resolution and reproducibility of our approach is highlighted by the correct detection of maternally inherited mtDNA and male X-linked loci, highly correlated parental bias among male and female samples from the same adult brain regions, and, finally, by independent confirmation using Sequenom DNA analysis for select examples. From our study, parent-of-origin effects in the brain emerges as a complex and widespread form of epigenetic regulation characterized by brain region-, developmental stage–, and isoform-specific parental allelic effects. These findings build substantially on earlier studies that identified imprinted genes in which monoallelic expression is restricted to a developmental stage (32, 39), tissue (40, 41), or cell type (42). Such complex regulation is likely to involve the combined effects of specific parent-of-origin allelic DNA methylation patterns and histone modifications, as well as tissue- and cell type–specific promoters and enhancers (41, 43). Recent work suggests that alternative polyadenylation sites may also contribute to the generation of distinct maternal and paternal isoforms (36). It will be of interest to determine whether other emerging epigenetic mechanisms that appear to influence the expression of alternative exons and 3′UTRs in the transcriptome, such as nucleosome positioning and histone modifications (44, 45), might be relevant to the complex parent-of-origin effects uncovered in our data.\r\nEarly studies of imprinting gave rise to the concept of a maternal influence centered in the cortex and a paternal influence centered in the hypothalamus (7, 8). A slightly different picture emerged from our study, such that significant maternal influence was uncovered in the embryonic brain, whereas a robust paternal bias was observed in both adult cortex (mPFC) and hypothalamus (POA). Our companion study suggests maternal control over adult brain gene expression residing on the X chromosome (13). Our findings may provide insights into brain evolution, function, and neurological disease due to the prominent involvement of X-linked genes in neurological function (46) and the unique susceptibility of imprinted loci to mutation and dysregulation (47).", user_id: 3, journal_id: 10, field_id: 8, institution_id: 12});

paper15 = Paper.create!({title: "Use of the CRISPR/​Cas9 system as an intracellular defense against HIV-1 infection in human cells", body: "Abstract\r\nTo combat hostile viruses, bacteria and archaea have evolved a unique antiviral defense system composed of clustered regularly interspaced short palindromic repeats (CRISPRs), together with CRISPR-associated genes (Cas). The CRISPR/​Cas9 system develops an adaptive immune resistance to foreign plasmids and viruses by creating site-specific DNA double-stranded breaks (DSBs). Here we adapt the CRISPR/​Cas9 system to human cells for intracellular defense against foreign DNA and viruses. Using HIV-1 infection as a model, our results demonstrate that the CRISPR/​Cas9 system disrupts latently integrated viral genome and provides long-term adaptive defense against new viral infection, expression and replication in human cells. We show that engineered human-induced pluripotent stem cells stably expressing HIV-targeted CRISPR/​Cas9 can be efficiently differentiated into HIV reservoir cell types and maintain their resistance to HIV-1 challenge. These results unveil the potential of the CRISPR/​Cas9 system as a new therapeutic strategy against viral infections.\r\n\r\nIntroduction\r\nViral infections underlie a variety of different human diseases, including life-threatening AIDS1. Currently, treatment for such diseases focuses on drugs and vaccines that specifically target the viral proteins or inhibit host–viral interactions2, 3. However, the nature of lentiviral infections, whereby the virus, such as human immunodeficiency virus (HIV), invades immune cells and integrates into the host genome to establish its latent infection, has created a huge obstacle with respect to developing efficient vaccines4, 5. These lentiviral features and the lack of immune response to eliminate the latent viral genome from reservoirs constitute the major challenges that need to be overcome, to develop efficient therapies6, 7, 8.\r\nThe clustered regularly interspaced short palindromic repeat (CRISPR)/​Cas9 system is known to play a major role in the adaptive immune response to foreign plasmids and viruses in about 40% of bacteria9, 10, 11. Recently, several research groups have successfully applied the type II CRISPR system—​SpCas9 protein from Streptococcus pyogenes with guided RNA (gRNA)—for targeted genome editing in diverse cell types and organisms, including human cells12, 13, 14. Most recently, a couple of studies have demonstrated the excision of the HIV-1 provirus from the host cell genome using gene-editing tools15, 16, 17, 18. Here we apply the CRISPR/​Cas9 system to directly target and disrupt the reverse-transcribed products of the lentiviral RNA genome during their life cycle within host cells. We screen multiple potential gRNA target sites in the HIV genome and identify optimized targets that enable effective and long-term protection against HIV-1 infection in primary human T cells and human pluripotent stem cell (hPSC)-derived HIV reservoir cell types. The strategy presented here may open a new avenue for research and novel clinical strategies against viral infectious diseases.\r\n\r\nResults\r\nOn early entry into their target cells, lentiviruses reverse transcribe their single-stranded RNA genome into double-stranded DNA (dsDNA) by a virally encoded reverse transcriptase19. The resulting viral DNA is then transported into the cell nucleus and integrated into the host genome as a latent provirus, thereby avoiding detection from the host’s immune system8. During these early events in the viral life cycle, the lentivirus is released from its capsid (Fig. 1a). We hypothesized that this exposed virus genome would be susceptible to targeted disruption by sequence-specific DNA nucleases inside the host cells. To test this, we first used replication-incompetent pseudotyped lentiviruses as the target to restrict our analysis to a single round of viral infection. Target gRNAs were designed against the enhanced green fluorescent protein (EGFP) coding region as well as the non-coding long terminal repeat (LTR) of an EGFP reporter lentivirus (Fig. 1b). These gRNAs were designed to only target the sequences unique to the viral reporter and not present in the human genome. To directly monitor ​Cas9 nuclease expression inside cells, we first constructed a human codon-optimized ​Cas9-2A-mCherry reporter (h​Cas9-mCh), which has been confirmed to be functionally equivalent to the wild-type h​Cas9 in an EGFP reporter rescue assay similar to a previously reported one20 (Supplementary Fig. 1a). Therefore, the expression of h​Cas9 can be tracked by the mCherry signal.\r\nThese gRNAs, together with h​Cas9, caused a significant reduction in the percentage of cells counted as GFP positive as well as in GFP fluorescence intensity in infected cells. The reduction ranged from 18% to 72%, depending on the target sites of gRNA (Fig. 1c, Supplementary Fig. 1d,f,h and Supplementary Tables 1 and 2). Meanwhile, pretreatment with either h​Cas9 or gRNA individually did not result in any disruption of EGFP expression from viruses (Supplementary Fig. 1b,c), indicating that neither h​Cas9 nor gRNA individually inhibits viral gene expression without specific targeting. We further examined the antiviral target specificity by comparing CRISPR/​Cas9-mediated disruption of different lentiviruses (lentivirus that has either EGFP or mCherry coding sequence within the same backbone; Supplementary Fig. 2a,b). By targeting different regions, our results indicate that ​Cas9, guided by different gRNAs, accurately distinguishes between these two lentiviral vectors.\r\nOur data suggest two possible mechanisms for the ​Cas9-mediated inactivation of viral gene expression. First, ​Cas9 could directly target the viral genomic DNA, when the virus enters the cell and reverse transcribes into dsDNA before integration into the host genome (Fig. 1a, step 1). Second, ​Cas9 could disrupt the proviral elements already integrated in the host genome (Fig. 1a, step 2). To distinguish between these possibilities, we repeated the above-mentioned experiment with a non-integrative EGFP lentivirus as the target. Intriguingly, our results show that ​Cas9 inactivates viral EGFP expression to a similar extent regardless of the integration status of the lentivirus (Fig. 1d–g). Moreover, instead of integrating into the host genome, lentiviruses can transiently present in a circular double-stranded format in the host cells. The CRISPR/CRISPR-associated genes (Cas) system has been reported to functionally inactivate invading plasmids in bacterial cells10; we therefore examined whether the CRISPR/​Cas9 system can also be used to inactivate circular foreign plasmids (double-stranded circular DNA) in human cells. By using the same backbone of EGFP reporter in previous lentivirus assays (Supplementary Fig. 1d,f,h), the CRISPR/​Cas9 system showed its ability to inactivate the expression of invading plasmids at a comparable level, to disrupt the infectious lentivirus (Supplementary Fig. 1e,g,i).\r\n\r\nDisruption/eradication of integrated proviral genome\r\nTo further examine whether the proviral genome of lentivirues can be disrupted or eradicated from the human genome by the CRISPR/​Cas9 system, we established several stable HEK293 cell lines bearing different numbers of integrated proviruses. After transfection of CRISPR/​Cas9 into these cells, the fluorescent signal from the virally expressed GFP gradually reduced and finally reached the same level as that of the uninfected negative control cells (Fig. 2a,f). The time-course results shown here also indicate that although expressed transiently, CRISPR/​Cas9 can mediate permanent inhibition of viral expression due to disruption of proviruses at the DNA level, which is different than the transient repression of viral expression by other methods, such as RNA interference21, 22, 23. Meanwhile, the molecular analysis showed that the disruption of GFP expression was caused by either insertion/deletion or full-length excision (Fig. 2b–e). Our result also showed that the CRISPR/​Cas9 system could efficiently disrupt the activity of proviruses regardless of copy numbers (Fig. 2b,d). This effect was also contingent on target gRNA specificity, as we showed by using different gRNAs to differentially target either EGFP or mCherry proviruses (Supplementary Fig. 2c,d). In addition, after a secondary delivery of the CRISPR/​Cas9 system, the levels of viral expression were further decreased, suggesting that a potential low-dose chronic treatment regiment, which may be less cytotoxic, could be effective in eradicating proviruses over time (Fig. 2g). In summary, these results indicate that the CRISPR/​Cas9 system can mediate targeted disruption of both pre-integration viruses and integrated proviruses with dsDNA in either linear or circular format. More comprehensive mechanisms of CRISPR/Cas system-mediated foreign DNA disruption in both bacterial and human cells remain to be further studied.\r\n\r\nTargeting site screening against HIV-1 genome\r\nAs there can be important differences between how viral vectors, wild-type and wild-type-like viruses infect cells, we tested whether the CRISPR/​Cas9 system can disrupt the generic HIV-1 viral genome during viral infection. After filtering out sequences with high homology to the human genome (see Methods), we selected and screened multiple gRNA-targeting sites within the HIV-1 genome, including the structural (​gag and ​env), enzymatic (​pol) and accessory genes (​vif and ​rev), as well as LTRs (Fig. 3a and Supplementary Table 2). The GFP expression levels of VSV.G-HIV-1NL4-3-ΔE-GFP in the cells that were treated with HIV-specific gRNA and h​Cas9 were 48%∼92% lower than the cells transfected with empty gRNA vector. However, this reduction did not occur when we used mock gRNA with h​Cas9 (Fig. 3b). We also noted that gRNAs targeting LTR sequences (especially the R region) were more effective than others, indicating the importance of the LTR-R region in HIV expression.\r\nNext, we examined the CRISPR/​Cas9 antiviral system in latently infected T-cell lines containing a full-length integrated HIV genome. The A2 and 10.6 J-lat clones contain a GFP open reading frame in place of the ​nef gene and a frameshift mutation in the ​env gene24. The latent viral load was greatly reduced by co-transfection of ​Cas9 and anti-LTR gRNAs, as evidenced by a six- to sevenfold reduction in viral GFP reactivation by ​Phorbol 12-myristate 13-acetate (​PMA) and ​Tumor-necrosis factor-alpha (​TNF-alpha) (Supplementary Fig. 3a). The GFP reduction correlated with the disruption of the viral genome in the targeting regions (Supplementary Fig. 3b).\r\n\r\nMultiplexed targeting of HIV-1 genome by CRISPR/​Cas9\r\nIn microbial CRISPR systems, when a plasmid or virus enters the bacterial host, fragments of the foreign DNA can be seized as ‘spacers’ and assembled with identical ‘repeats’ to form tandem arrays that become the templates for multiplexed foreign DNA targeting11, 25. This led us to think that the ability of the CRISPR/Cas system to perform multiplexed genome engineering is a major strength that could be leveraged to develop an antiviral method in human cells. Thus, we next examined multiplexed disruption of viral infection by co-delivery of h​Cas9 and multiple gRNAs. As the results show in Fig. 3c, the multiplex CRISPR/​Cas9 system abated the infectious virus or proviral genome inside the host cells more completely when compared with the singly targeted ​Cas9. Meanwhile, cell viability also increased with the multiplex CRISPR/​Cas9 system, which is consistent with more effective elimination of the toxic infectious virus (Fig. 3d). We further examined the CRISPR/​Cas9-mediated protection against infectious wild-type HIV, HIV-1NL43-GFP, which recapitulates the early and late events in the viral life cycle, including production of viral RNAs and release of virions from host cells. Both the release of ​p24 viral protein and production of GFP were decreased, compared with controls, especially in the double gRNA systems (Fig. 3e). This suggests that the multiplex CRISPR/​Cas9 system is highly effective in suppressing wild-type HIV replication and reactivation in human cells.\r\n\r\nStable expression of ​Cas9 against HIV-1 in physiological cells\r\nTo test the possibility of conferring intracellular immunity against lentiviral infections using the CRISPR/​Cas9 system, we constructed several ​Cas9/gRNA stable cell lines by using piggyBac (PB) transposon-mediated genome engineering systems. Our results show that these stable lines are sufficiently protected against subsequent viral infections (Supplementary Fig. 3c–g). The level of antiviral protection conferred by stably integrated ​Cas9/gRNA was sufficient to inactivate the lentiviral expression in a similar manner to those obtained by transient transfection (Fig. 1). To further investigate whether the CRISPR/​Cas9 system can immunize cells against replicated wild-type HIV-1 over a longer period of time, we tracked viral infectivity in a human T-cell line for 14 days. Sup-T1 cells with stably integrated ​Cas9 and gRNA targeting a variety of HIV-1 genome sequences were infected with HIV-1NL43-GFP (Fig. 4a). Although the infection of HIV-1 increased over time in the control gRNA group, the groups with HIV-1-targeted gRNAs effectively reduced the level of viral expression. In particular, the groups with combinations of gRNAs targeting the U3 and R regions of the HIV-1 LTR maintained a low level of viral expression even over 14 days of HIV-1 infection, although most host cells had been infected and had a poor survival rate in the no CRISPR treatment control population (Fig. 4b). This prolonged inhibition of viral expression is consistent with a disruption of viral replication in multiple cycles of viral infection. To demonstrate the disruption of HIV infection in a more physiological context, we applied the CRISPR/​Cas9 antiviral system to human primary ​CD4+ T cells. Using more than five independent T-cell donors, our results showed that CRISPR/​Cas9 targeting HIV-1 LTR R regions efficiently reduced virus production by more than threefold compared with the controls (Fig. 4c).\r\nTo test whether the CRISPR/​Cas9 system could confer HIV-1 resistance to haematopoietic lineages that could serve as latent HIV reservoirs, such as monocyte/macrophage lineages26, several piggyBac-mediated anti-HIV-1 hPSC lines were generated and confirmed for ​Cas9 protein expression by western blotting (Fig. 4d). These CRISPR/​Cas9-hPSCs can be differentiated into monocytes/macrophages using a feeder-free protocol27, 28 (Fig. 4e). A relatively homogenous population of monocytes/macrophages was efficiently differentiated from the PB-CRISPR/​Cas9 hPSCs (Fig. 4f,g). The differentiated cells were inoculated with an M-tropic virus clone, HIV-1R5-Ren_Luc, for 3 days before the analysis (Fig. 4h). The results show that engineered hPSCs can confer resistance to HIV-1 infection in derived monocytes/macrophages.\r\nThe fact that PB-CRISPR/​Cas9 hPSCs could be stably maintained for multiple passages and efficiently differentiated suggests that the HIV-1-targeted CRISPR/​Cas9 system does not have overt genotoxicity. To further study this point, we evaluated the off-target effect of the PB-CRISPR/​Cas9 hPSCs against the most efficient LTR-T2 target region. From the analysis of the top five off-target candidates with high sequence similarity in the exonic regions of the human genome, there was no significant off-target effect in any of the analysed clones of hPSCs (Supplementary Table 3). Meanwhile, there was no detectable off-target effect in the PB-CRISPR/​Cas9 HEK293 cells when we examined the top five off-target candidates with high sequence homology to either gLTR-T1 or gLTR-T2 in these lines (Supplementary Table 3).\r\n\r\nDiscussion\r\nThe present work indicates that the bacterial CRISPR/​Cas9 adaptive immune machinery can be adapted into human cells as a novel anti-virus tool. Our data show that CRISPR/​Cas9 can functionally target either the viral coding or non-coding regions during either pre-integration or provirus stages. When DSBs are created by CRISPR/​Cas9, presumably exonucleases inside host cells could degrade the viral genome near the DSBs, due to a lack of protection from LTR sequence or LTR-binding proteins in the broken ends. Meanwhile, targeting coding regions can directly disable viral genes through mutations, insertions or deletions33. In contrast, when targeting non-coding regions (for example, LTR regions in this study), the structural disruption can be induced in a pre-integration stage, whereas the proviral genome excision can also be achieved in the provirus stage. Our results represent the different targeting/disruption strategies and efficiencies in different stages (pre-integration and provirus), and in different targeting sites as well (coding and non-coding regions). In general, targeting the LTR sequence has a higher impact on HIV-1 expression, especially the LTR-R region (Fig. 3). The LTR-R region contains the TAR sequence that is relatively conserved among the HIV-1 subtypes, which could serve as a common target site for anti-viral disruptions17, 34, 35. This consequence matches the fact that LTR serves as a critical and universal element for lentivirus expressional regulations by the transcriptional machinery from both virus-encoded proteins and the host cells during the HIV infections36, 37.\r\nRegardless of the stage or region targeted, our results show a significant reduction of viral expression by ​Cas9-mediated antiviral immunity. By using a multiplexed CRISPR/​Cas9 system, we achieved an elevated level of disruption and excision of pre-integrated proviral genome. Presumably, using CRISPR/​Cas9 directed against multiple conserved target sequences simultaneously can minimize the emergent concern of viral variants developing resistance to singly guided CRISPR/​Cas9. In addition, inserting the stably expressed CRISPR/​Cas9 system into a T-cell line conferred long-term protection against HIV-1 infection. With recent successful developments, gene-editing technologies have shown great promise in anti-HIV therapy for both pre-clinical studies and ongoing clinical trials38, 39, 40. As our data show, the system could work on physiologically relevant HIV-1 reservoir cell types and we expect that this system can be further exploited to develop alternative antiviral therapies in the future.", user_id: 3, journal_id: 1, field_id: 2, institution_id: 13});

paper16 = Paper.create!({title: "Attomolar Detection of Botulinum Toxin Type A in Complex Biological Matrices", body: "Abstract\r\nBackground\r\nA highly sensitive, rapid and cost efficient method that can detect active botulinum neurotoxin (BoNT) in complex biological samples such as foods or serum is desired in order to 1) counter the potential bioterrorist threat 2) enhance food safety 3) enable future pharmacokinetic studies in medical applications that utilize BoNTs.\r\nMethodology/Principal Findings\r\nHere we describe a botulinum neurotoxin serotype A assay with a large immuno-sorbent surface area (BoNT/A ALISSA) that captures a low number of toxin molecules and measures their intrinsic metalloprotease activity with a fluorogenic substrate. In direct comparison with the “gold standard” mouse bioassay, the ALISSA is four to five orders of magnitudes more sensitive and considerably faster. Our method reaches attomolar sensitivities in serum, milk, carrot juice, and in the diluent fluid used in the mouse assay. ALISSA has high specificity for the targeted type A toxin when tested against alternative proteases including other BoNT serotypes and trypsin, and it detects the holotoxin as well as the multi-protein complex form of BoNT/A. The assay was optimized for temperature, substrate concentration, size and volume proportions of the immuno-sorbent matrix, enrichment and reaction times. Finally, a kinetic model is presented that is consistent with the observed improvement in sensitivity.\r\nConclusions/Significance\r\nThe sensitivity, specificity, speed and simplicity of the BoNT ALISSA should make this method attractive for diagnostic, biodefense and pharmacological applications.\r\n\r\nIntroduction\r\nBotulinum neurotoxins (BoNT)s are the most poisonous substances known [1], [2]. They cause the human illnesses of infant [3]–[5], wound [6], foodborne [7] and iatrogenic botulism [8]–[11], but are also used to treat a variety of medical conditions [12], [13]. The potential abuse of BoNT in bioweapons is feared [1], [14]. The enormous potency of the toxin is reflected by its estimated human lethal i.v. dose of only 1-2 ng/kg body weight [1], [2]. Hence, the detection of low, but nonetheless dangerous amounts of BoNT in complex clinical specimens or foods represents an extreme analytical challenge.\r\nAs produced by Clostridium bacteria, BoNT is present within ∼300, 500 or 900-kDa protein complexes together with non-toxic components, known as neurotoxin associated proteins (NAPs) [15]–[20]. Seven structurally distinct serotypes of BoNT (A to G) have been discovered. The neurotoxin itself is a 150-kDa zinc-binding metalloprotease (holotoxin) that is endogenously cleaved into a 100-kDa heavy and a 50-kDa light chain that are connected by a reducible disulphide bond [21] and by a belt-like extension of the heavy chain that loops around the light chain [22]. The catalytic site is located on the light chain [23]. Reduction of the chain-bridging disulphide bond allows for chain separation and exposure of the catalytic site, which enhances the toxin's activity [22], [24], [25]. The phenomenal potency of BoNT results from its ability to enzymatically cleave one or more of the three SNARE proteins that are involved in fusing acetylcholine-containing synaptic vesicles with the terminal motor neuron membrane and trigger muscle contraction [21], [26]–[28].\r\nThe definitive diagnosis of botulism requires the detection of BoNTs in a clinical specimen. The most commonly used method to accomplish this task is the live-mouse bioassay [29]–[31] that can detect as little as 10 pg of BoNT holotoxin [32], and, because of its sensitivity, simplicity and robustness, it is considered the “gold-standard”. Other, generally faster, methods for detecting BoNT include various enzyme-linked immunosorbent assays (ELISAs) [30], a cantilever-based micromechanosensor [33], protein-based fluorescence resonance energy transfer (FRET) sensors [34], enzyme-amplified protein micro-arrays [35], mass spectrometric assays [36]–[39], immuno-PCR detection [40], and recently, a real-time PCR-based assay that utilizes reporter DNA-filled liposomes that bind to immobilized BoNT/A via gangliosides [41], [42]. Table 1 lists detection limits and the types of samples for which BoNT assays were demonstrated. Most assays, except for a PCR-based one, are unable to detect less than 1 pg/mL BoNT in a complex sample, such as a body fluid.\r\n\r\nResults\r\nAssay Design\r\nBoNT/A ALISSA consists of two main steps. First, BoNT/A is captured and enriched on a bead-based immuno-affinity matrix and molecules that bind the matrix non-specifically are washed away. Second, the enzymatic activity of the immobilized BoNT/A is determined by cleavage of a specific fluorogenic substrate. Our enrichment matrix consists of protein A-conjugated sepharose beads to which we coupled and crosslinked polyclonal anti-BoNT/A antibodies (Figure 1A). These immobilized antibodies capture BoNT/A molecules with high affinity and they do not inhibit BoNT/A's enzymatic function. During synthesis of the bead-based immunomatrix it was critically important to use a neutral wash buffer after binding and crosslinking of the antibody to the protein A beads. When an acidic wash buffer (pH 2.8) was used instead, the antibodies were altered such that they became inactive when exposed to nanomolar concentrations of the toxin, probably as a result of toxin-mediated unspecific proteolytic cleavage (Figure S1).\r\nOur assay utilizes a fluorogenic peptide, SNAPtide (U.S. patent 6,504,006, List Biological Laboratories), which is a molecular beacon derivative of SNAP25, the natural substrate of BoNT/A [27], [28]. SNAPtide is cleaved by BoNT/A between a fluorophore and a quencher (a FRET pair), thereby releasing the unquenched fluorophore (Figure 1B and Figure S2C). The SNAPtide used here contains a conjugated fluorescein thiocarbamoyl (FITC) quenched by a 4-(dimethylaminoazo) benzene-4-carboxyl (DABCYL)-moiety. The immobilized polyclonal rabbit antibody used does not inhibit the specific proteolytic activity of BoNT/A and exhibits binding affinity to the light and heavy chain of BoNT/A, as confirmed by Western blot (Figure S2A,B).\r\nAssay Optimization\r\nWe optimized the conditions of a prototype bead-based assay to maximize its sensitivity and specificity for one- and ten-attomolar concentrations of toxin in 1-mL sample volumes (Figure 2). Therefore, we repeatedly determined the assay's sensitivity with serial dilutions of BoNT/A in 10% fetal bovine serum (FBS), while evaluating the effect of the following parameters: antibody-to-protein A crosslinking conditions, wash buffers used post-crosslinking of antibodies to beads, number of beads, toxin-antibody binding times and temperatures, wash buffers for removal of molecules that bind non-specifically to the beads, SNAPtide concentration, SNAPtide conversion time and the effect of temperature during the reaction. For each BoNT/A dilution, the fluorescence intensity was plotted against the varying parameter (Figure 2). Due to the asymptotic nature of the resulting curves, there are no optima for several parameters. However, by analyzing the change in signal gain as a function of a given parameter, we identified efficient values for each parameter for which the steepest increase in signal gain has readily been achieved. In consequence, the assay's performance has become robust and predictable.\r\nThe assay was efficient and highly sensitive when 100 µL/well SNAPtide in 1 µM-concentration was used (Figure 2A). A reaction time of at least one hour for the conversion of the fluorogenic SNAPtide at room temperature (25°C) was appropriate (Figure 2B). Within limits, the signal-gain of the assay could be enhanced by increasing the number of beads mixed with the sample (Figure 2C) and by extending the enzyme enrichment time (Figure 2D). The most efficient bead concentrations were between 100,000 and 120,000 beads/mL, which correspond to a bead-bed volume of approximately 8.7–10.4 µl when left to settle. Further increase of the bead concentration to 500,000/mL raised the signal intensity by only another 28% (Figure 2C). Sufficient binding of BoNT to the bead-bound antibodies requires 3 hrs at 25°C and just 1 hr at 37°C. The measured toxin activity was diminished at 55°C (Figure 2E), most likely due to toxin deactivation44 as opposed to decreased antibody binding. An increase in temperature from 25°C to 37°C during the SNAPtide-conversion reaction also improved the signal somewhat (Figure 2F), and reliable readings were obtained for 1 hour reaction times.\r\nAssay performance\r\nThe pre-activated toxin, obtained through short incubations with 5 mM DTT, produced slightly higher signals when compared to the non-pre-activated toxin (Figure 3A). However, the subsequent reaction with the fluorogenic reporter had to be performed in 1.25 mM DTT, in order to avoid denaturation of the immunoaffinity matrix and because prolonged exposure to the more concentrated reductive agent considerably inactivated the toxin considerably (tested on bead-free toxin; data not shown).\r\nSensitivity\r\nThe 150-kDa BoNT/A holotoxin (from two different commercial sources) and the 500-kDa type A toxin complex were serially diluted and tested by BoNT/A ALISSA in 10% FBS (Figure 3A). Robust signals of several thousand relative fluorescence units (RFU) above background were still observed for concentrations of one attomol/L toxin in 1-mL sample volumes. Signals for the toxin complex were always stronger than for identical molar concentrations of holotoxin. The practical detection limit in 10% FBS is 1 attomol/L, which corresponds to 0.5 fg of the 500-kDa toxin complex in a 1-mL sample (Figure 2 and ​and3).3). For a comparison with other assays see Table 1. For practical reasons, we had used diluted FBS to optimize our assay. To test if the ALISSA can be utilized in other more relevant complex samples, we determined the assay's sensitivity for the toxin complex in spiked undiluted human serum, carrot juice, reconstituted non-fat powdered milk, fresh milk and in GP-diluent (Figure 3B). GP-diluent is used in the mouse bioassay for BoNT detection. Although the discernible fluorescence was less intense than in toxin-spiked samples with 10% FBS, BoNT/A was still detected for 1 attomol/L toxin complex, with signal intensities of ∼14,800, ∼14,750, ∼3,100, ∼2500 and ∼650 RFU above background in undiluted human serum, 50% carrot juice, GP-diluent, non-fat milk and fresh milk, respectively. Overall, the ALISSA signals correlated proportionally with the toxin concentration over several orders of magnitude (Figure 3).\r\nSpecificity and kinetics\r\nWe evaluated specificity and also compared the sensitivity and kinetics of the bead-based ALISSA to those of the bead-free conversion of the reporter peptide. To test the effect of non-specific agents, we used FBS samples mixed with: 1) beads conjugated to purified unspecific rabbit IgG; 2) trypsin, because it can also cleave SNAPtide, but it cannot be enriched on the beads; 3) BoNT complex type B; 4.) BoNT complex type E; 5) type A toxoid, which is a non-toxic, antibody-binding formaldehyde inactivated derivative of BoNT/A; and 6) a toxin-free control (Figure 4A,B). The bead-based assay produced low intensity signals with the non-specific agents (trypsin, BoNT/A toxoid, BoNT/B and E), and only at the highest tested concentrations (10–100 pmol/L). The bead-free reaction mixture produced signals only with trypsin and with BoNT/A for concentrations of 1 pmol/L or greater, and these signals were weak. Surprisingly, in the bead-free reaction, equimolar trypsin concentrations produced even stronger signals than the BoNT/A complex. This was not the case in the bead-based assay. Toxin complexes of type B and E, for which the SNAPtide substrate does not contain specific cleavage sites, produced signals that were nearly undetectable at the 10 and 100 picomolar concentrations. The intensities of these type B and E signals were even lower than the intensities of the signals obtained with the bead-based assay (Figure 4A,B). It is noteworthy that the bead-based detection of BoNT/A produced much higher signals, at any given toxin concentration, than did the bead-free reaction mixture. Discernible signals for the bead-free reaction mixture were obtained only for BoNT/A concentrations greater than or equal to 1 pmol/L. In contrast, strong signals were obtained with BoNT/A at concentrations as low as 1 attomol/L the bead-based assay used, suggesting that the bead-based assay is at least a million-fold more sensitive than the bead-free assay. This remarkable enhancement of the substrate cleavage reaction, when BoNT/A was immobilized on the beads, prompted us to determine the kinetic parameters of the SNAPtide conversion reaction. For comparative purposes, a fixed concentration of BoNT/A complex (100 pmol/L) was used in 1-mL sample volumes for both the reactions with the bead-free toxin and with the bead-immobilized toxin. At this concentration, BoNT/A was easily detected with either method. The hydrolysis of SNAPtide by BoNT/A obeyed Michaelis-Menten kinetics and was characterized by a linear relationship between the reciprocal substrate concentration and the activity of the enzyme (Figure 4C,D). The Km of the immobilized enzyme was 3.2-fold lower than for the free enzyme, indicating a somewhat higher enzyme/substrate affinity. The main effect of binding of the toxin to the beads was found in the rate of catalysis: The immobilized BoNT/A hydrolyzed the SNAPtide substrate at a maximal conversion rate that was 18-fold greater than that of the free toxin. For the free (non-immobilized) and the immobilized enzymes the corresponding values for Vmax at 25°C were 0.79±0.04 µM/min/µg and 14.49±0.27 µM/min/µg, respectively.\r\n\r\nDiscussion\r\nThe BoNT/A ALISSA avoids interference with other sample components by using a highly BoNT/A-specific affinity matrix and by using a BoNT/A-specific substrate to exploit the natural proteolytic activity of the toxin. Both steps also amplify the signal by 1) localized enrichment of the toxin and 2) through enzymatic conversion of billions of substrate molecules per toxin molecule. The capture matrix is designed to stably enrich the toxin, while retaining its enzymatic activity and by purifying the toxin from other unspecific, sample-contained, proteases. Like the Endopep-MS method [36]–[39], we used a beaded protein A matrix to bind anti-BoNT/A antibodies via their FC-portions, orienting the antibody binding domains away from the bead surface and into the surrounding fluid, which we expected to provide high accessibility for toxin molecules.\r\nThe plateaus seen in the assay's response curves, used to optimize the substrate concentration (Figure 2A) and the size and volume proportions of the immunosorbent matrix (Figure 2C), represent saturation effects that indicate when the substrate concentration is no longer rate-limiting or how much antibody is needed to capture most of the toxin molecules, respectively. We have determined that the antibody binding capacity of the beads was 50 µg antibody per one million beads, and therefore, we estimated the antibody's dissociation constant kD at half maximum saturation to be approximately 15 nM (Figure 2C). It should be possible to further improve the assay's sensitivity by using antibodies with higher binding affinities. High affinity anti-BoNT antibodies have also been used as antitoxins to neutralize systemic botulinum toxin in botulism patients [46], [47]. It is important to point out that this mode of “neutralization” should not be confused with inactivation of the toxin's enzymatic activity by steric hindrance of the catalytic site as a result of antibody binding. The antibody-mediated “neutralization” of the toxin in the human body relies on the formation of an antibody-antigen complex and its subsequent hepatic accumulation and clearance [48], [49].\r\nThe use of a standard curve to measure the concentration-dependent intensity of the fluorescence signal of an un-quenched calibration peptide (Figure S3) enabled us to determine the molar conversion rate for the substrate molecules. For the 10 attomolar toxin concentration, we calculated a substrate conversion rate of approximately two billion substrate molecules per one immobilized toxin molecule per hour. The reaction is limited by the rate at which the toxin becomes inactivated. Several factors may contribute to the inactivation of the toxin: 1) chelation of the zinc atom [50] by DTT, 2) denaturation of the toxin by the reducing buffer [25], or 3) proteolytic degradation of the toxin either through autoproteolysis [51], [52] or by a contaminant protease.\r\nThe optimal temperature for the assay is 37°C (Figure 2E,F), which coincides with the temperature at which the natural action of the toxin occurs [53] and at which binding to the IgG antibody appears to be optimal. Higher temperatures inactivate the toxin [53], [54]. The pH of the sample should be approximately neutral (between 6 and 8). Further improvement of the assay's sensitivity may be feasible by reducing the background fluorescence of the uncleaved SNAPtide. The FITC/DABCYL donor/acceptor pair used in this study already exhibits some fluorescence due to a non-optimal overlap of the FITC emission spectrum with the absorption spectrum of DABCYL (Figure S4). A peptide-conjugated FRET pair with a 2,4-dinitrophenyl acceptor and a 4-methyl-7-dimethylamino-coumarin donor has been described as a substrate for BoNT/A [55]. This and other FRET pairs with a better spectral overlap, potentially lower background fluorescence, and good kinetic properties may be tested as fluorogenic substrates in the future.\r\nOur kinetic studies revealed an approximately 18-fold increase in the maximum conversion rate vmax and a three-fold higher affinity to the substrate (three-fold lower kM) for the immobilized toxin than for the free toxin in solution (Figure 4C,D). Similar improvements in enzymatic activity have been reported for other immobilized enzymes, such as immobilized trypsin, and the effect is attributed to the increased reaction surface area and the control of diffusion through more frequent substrate-enzyme interactions[56]. We have also detected a weak interaction between the uncleaved substrate and the bead surface (Figure S5). This weak interaction may contribute to a higher local concentration of SNAPtide on the bead surface and a shorter time of diffusion along the bead surface for a SNAPtide molecule to encounter the active site of a toxin molecule.\r\nThe average bead surface area in the ALISSA assay is approximately 7.85 cm2 per sample (based on a 50 µm average bead diameter) whereas the antigen-binding surface area in a conventional ELISA with a 96-well flat-bottom polystyrene microplate measures only about 0.256 cm2 per well (BD Falcon plate, cat. #353279). The available reaction surface area in the ALISSA is therefore about 30-fold larger than in an ELISA. In addition, it is possible that immobilized BoNT/A is better protected from proteolysis and aggregation. Once immobilized, molecules of the unstable BoNT/A light chain should be sufficiently separated from each other to diminish their autocatalytic degradation. The use of a bead-based assay allows for stringent wash steps that diminish interference with other proteases, as demonstrated for BoNT/A in comparison with equimolar concentrations of trypsin, BoNT/B and BoNT/E.\r\nThe ALISSA performed with comparable sensitivities in undiluted human serum, 50% carrot juice (adjusted to pH 7.5 with binding buffer), reconstituted powdered milk, fresh milk and GP-diluent. In direct comparison with the mouse assay the ALISSA was considerably faster and four to five orders of magnitude more sensitively (Table 2.). A more accurate comparison would require a significantly larger number of mice to obtain a precise mouse-LD50 (MLD50). Here we used the MLD50 provided by the toxin manufacturer, and found that the value given was largely consistent with our experimental results. Ultimately, the BoNT ALISSA might help to reduce animal use for the associated lethal test procedure. A rough estimate on the economy of the assay reveals an average reagent cost of ∼$15 per sample (Table S1), which is expected to be much lower than the costs associated with utilization of an animal facility to ensure constant availability of live animals for diagnostic purposes.\r\n\r\nConclusion\r\nThe BoNT/A ALISSA is an inexpensive, simple and robust procedure that ensures high analytical specificity and attomolar sensitivity for the detection of BoNT/A in complex biological samples. Future modification of our assay to encompass other BoNT serotypes, and even other classes of toxins, should become feasible as soon as the necessary substrate reagents become available.", user_id: 3, journal_id: 11, field_id: 2, institution_id: 14});

paper17 = Paper.create!({title: "S-Nitrosation of Aminothiones", body: "Abstract\r\nNitrosation reactions span a diverse range of applications, from biochemistry to industrially important processes. This study examines nitrosation of aminothiones in acidic solutions and re-evaluates currently accepted diffusion limits and the true nature of the nitrosating agent for nitrous acid initiated reactions. Experimental measurements from stopped-flow UV/vis spectrophotometry afforded derivation of equilibrium constants and reaction enthalpies. Apparent Keq corresponds to 559–382 M–2 for thioacetamide (TA, 15–25 °C) and 12600–5590 M–2 for thiourea (TU, 15–35 °C), whereas the reaction enthalpies amount to −27.10 ± 0.05 kJ for TA and −29.30 ± 0.05 kJ for TU. Theoretical calculations via a thermochemical cycle agree well with reaction free energies from experiments, with errors of −2–4 kJ using solvation method SMD in conjunction with hybrid meta exchange–correlation functional M05-2X and high-accuracy multistep method CBS-QB3 for gas-phase calculations. The kinetic rates increase with acidity at activation energies of 54.9 (TA) and 66.1 kJ·mol–1 (TU) for the same temperature range, confirming activation-controlled reactions. At pH 1 and below, the main decomposition pathway for the S-nitroso species leads to formation of nitric oxide.\r\n\r\nIntroduction\r\nThe discovery of nitric oxide (NO) as a signaling molecule in many biological functions sparked interest in nitrosation reactions in the 1990s.(1) In recent years, continued interest in nitrosation reactions expanded to development of NO-releasing biomedical materials(2) and regulation of endogenous S-nitroso species(3) as well as to theoretical calculations covering these reactions and subsequent decomposition pathways.(4) Relevant applications of nitrosation reactions extend to azo pigments used in color photography and in cloth dyes(5) and also to chemical gassing of emulsion explosives in mining and construction industries. During chemical gassing of emulsion explosives, a substrate and a nitrosating agent ideally react to generate nitrogen (N2) gas bubbles in situ, providing sensitization of the emulsion to detonation.(6, 7) However, decomposition of nitrosated compounds leads to NOx or N2 depending on the structure of substrate. Thus, it is important to determine reaction kinetics and mechanistic pathways of nitrosation of substrates that form N2 and NOx for process optimization. The motivation in studying nitrosation reactions in aminothiones thiourea (TU) and thioacetamide (TA) stems from two reasons. First, nitroso-group transfer to sulfur nucleophiles was found to be more effective compared to the corresponding nitrogen or carbon nucleophiles of the same basicity,(8) and reaction at sulfur is also faster than O-nitrosation due to its greater nucleophilicity.(9) Second, S-nitrosothiol decomposition via transnitrosation to an amine group presents a potential pathway producing N2.(10) These combined attributes of aminothiones potentially allow fast formation of N2 where NO is not produced.\r\nIn acidic aqueous solutions, nitrous acid may form nitrosonium ion (NO+), nitrous acidium (H2ONO+), and dinitrogen trioxide (N2O3), and the effective nitrosating agents depend highly on pH.(11-13) The ion structure of H2ONO+ characterizes an electrostatic complex between a free nitrosonium ion and a water molecule,(14) and it dehydrates under very acidic conditions.(15) At pH 1 and below, nitrosation proceeds via nitrosonium ion or nitrous acidium.(16)\r\nAt a much higher pH, dinitrogen trioxide (N2O3) from eq 4 predominates as a nitrosating agent. N2O3 arises as a byproduct of disproportionation reaction of nitrous acid, leading to the formation of nitric oxide and nitrate through eqs 5 and 6.(17, 18)\r\nFor TU and substituted alkylthioureas in highly acidic solutions, eq 7 generically expresses the reversible nitrosation reaction of aminothione substrate RS forming an S-nitroso compound RSNO+. For these species, RS is of the type R′CSNH2 (e.g., R′ = NH2, CH3). Collings and co-workers noted that the rate law is typical of a reaction involving a nitrosonium ion with charged or neutral nucleophiles.(19) Rate constants for some alkylthioureas approach the ∼6900 M–2·s–1 value for TU, implying a diffusion-controlled limit consistent with the suggestion by Ridd that reactions are dependent on the rate of encounter of an electrophile with a neutral or an anionic nucleophile.(20) Nitrosation also occurs via N2O3, and the rate law is second order in nitrous acid for such a case. This is well reported for nitrosation of thiols(21) and primary amines(6) but has not been studied in detail with TU and TA as substrates.\r\nThis study focuses on the initial S-nitrosation in TU and TA in acidic solutions, which are precursors to subsequent gas formation pathways. Theoretical calculations verify experimental results while gas phase analyses of products assist in elucidating the nitrosation pathways in these compounds.\r\n\r\nResults and Discussion\r\nFour species exist in acidic conditions for nitrite-initiated nitrosation reactions: HNO2, H2ONO+, NO+, and N2O3. The Supporting Information discusses pH-dependent composition, with only the first three relevant at pH of 1 and lower. However, HNO2 nitrosation in the H+-catalyzed pathway arises only by either NO+ or H2ONO+. The splitting of HNO2 to OH– and NO+ requires a fairly large bond dissociation energy (918 kJ), and only proton-catalyzed heterolysis to NO+ occurs at ambient temperatures.(14) The H2ONO+ pathway possibly dominates, as dehydration of nitrous acidium ion occurs only at highly acidic conditions (e.g., 45% HClO4).(15) Nonetheless, both pathways involve indistinguishable rate laws, and eqs 8 and 9 represent the overall reactions.\r\nAt pH of around 2.08, Al-Mallah et al.(22) postulated, but then discounted, the direct N-nitrosation of TU that results in the formation of an unstable nitrosamine decomposing to nitrogen. Based on their measured rate constant of 0.2 mM–1·s–1 at 25 °C and the observation that the nitrosation has no first-order dependence on acidity, Al-Mallah et al.(22) concluded that an unreasonably high pKa for deprotonation of TU would be required at the amine site. If reaction H+ + HNO2 + CS(NH2)NH– → CS(NH2)NHNO + H2O proceeds at an encounter rate of 15000 M–2·s–1 that is typical for anionic nucleophiles at the same temperature, section A13 of the Supporting Information demonstrates the pKa of 4.88 for deprotonation of TU. This means that at pH of around 2.08, very little CS(NH2)NH– exists to support a mechanism that comprises direct N-nitrosation of deprotonated TU. In reality, the pKa might be even higher as seen from its tentative prediction outlined in section A3 of the Supporting Information. At pH of 3.9, da Silva et al.(6) found very good agreement between a mechanism based on N-nitrosation and their experimental data of decreasing nitrite ion concentration with time, but without providing spectroscopic evidence for the direct formation of the N-nitroso moiety. Thus, we conclude this paragraph by observing that direct N-nitrosation of TU is unlikely to occur at pH below 1, as investigated in this article.\r\nIn acidic solutions, TU and TA can be protonated at the sulfur atom. Moreover, protonation may also occur at the nitrogen atom in TU, but theoretical calculations point to sulfur site preference.(23) Taking into account this protonation equilibrium, the rate law assumes a form that simplifies back to the generic rate law for eq 7 at Ka ≫ [H+] as discussed further in section A3 of the Supporting Information. The ChemAxon Marvin(24) pKa prediction for the protonated sulfur sites is −3.0 for both TA and TU. Several studies in the past determined these pKa’s both experimentally and theoretically. For TA, Sandström(25) and Edward et al.(26) quoted values of −1.76 and around −2.5, respectively. In the case of TU, conflicting pKa values in the literature range from −1.58 to 2.03, and Schiessl et al.(23) presented evidence that −1.3 is correct for aqueous solutions. Thus, at the pH of experiments both substrates are not protonated, and the generic rate law for eq 7 remains unaffected.\r\nMolar Absorptivity and Equilibrium Constant\r\nEquation 7 expresses a generic reversible nitrosation reaction of a substrate RS forming an S-nitroso compound RSNO+. Neglecting parallel HNO2 reactions and where [HNO2]0 depicts the initial nitrite concentration, the concentration of HNO2 equates to [HNO2] = [HNO2]0 – [RSNO+]. Note that RSNO+ reacts further but at a much longer time scale than that considered in this study. Equation 11 expresses a linear equation for calculation of apparent equilibrium constant Keq as in the approach by Collings et al.(19) This approach applies equilibrium conditions for a reaction wherein the acid (i.e., [H+]) and substrate are present in excess; i.e., [RS] ≫ [HNO2] and [H+] ≫ [HNO2]. From the Beer–Lambert law defining absorbance A in terms of extinction coefficient ε and path length L, plots of 1/A with 1/[RS], in section A10 of Supporting Information, yield ε and Keq. Table 1 lists derived values for S-nitrosothioacetamide and S-nitrosothiourea formation at 15–25 °C and 15–45 °C, respectively.\r\nFor TU, the molar absorption coefficients up to 35 °C fall within literature values of 96 and 113 M–1·cm–1.(22, 27) The decreasing trend of these coefficients at higher temperatures results from the increased rate of S-nitrosothiourea decomposition, which interferes with the initial S-nitrosation. In the case of TA, the absorptivity remains stable at ∼190 M–1·cm–1 with variation in temperature, ionic strength, and acidity. Although this is twice the only published value of 98 M–1·cm–1, values up to 194 M–1·cm–1 have been reported for S-nitroso adducts of alkylthioureas at the same wavelength.(22, 28)\r\nIn both substrates, a drop in Keq with increasing temperature indicates exothermicity of forward reactions. Equation 12 develops from the definition of the equilibrium constant in terms of the Gibbs free energy change (Kt = e–ΔGθ/RT) and ΔGθ = ΔHθ + TΔSθ.\r\nHence, the linear plot of ln Kt with 1/T enables calculation of standard enthalpy ΔHθ and entropy ΔSθ change for the reaction. These linear plots involve (true) thermodynamic equilibrium constants (Kt). However, apparent equilibrium constants (Keq) serve as reasonable approximates. The enthalpy changes of reaction for both species are very close, coherent with structure similarity. For TU, interference from the decomposition pathway limits the linear plots to 35 °C, resulting in −29.3 kJ for an enthalpy change of reaction consistent with published value of −30 kJ.(19) Thermodynamically, S-nitrosation of TA appears less favorable with −27.1 kJ reaction enthalpy; this constitutes the first value reported for this species. Consistently, the relative entropies depict a more positive value for TU.\r\nIn solutions of high ionic concentrations, the effective concentration or activity of ionic species varies significantly from actual concentrations due to electrostatic interactions of ions and requires corrections in terms of activity coefficients. Approximate activity coefficients often employ semiempirical equations such as one proposed by Robinson and by Guggenheim and Bates(29) instead of the more involved specific interaction theory requiring empirical interaction coefficients for individual ions in the solution or the more elaborate Pitzer equation. The main difficulty in these approaches lies in accounting for the interaction of RSNO+ species and the judicious use of empirical parameters in both SIT (i.e., εi) and Pitzer (i.e., β0) equations. Hence, our analysis anchors on an alternate graphical approach using a simpler extended Debye–Hückel equation.(30) Table 2 illustrates an increase in the apparent equilibrium constants with ionic strength, a similar trend observed in nitrosyl thiocyanate formation.(31) This results in true thermodynamic equilibrium constants of 86 and 2270 M–2 for reactions 8 (for S-nitrosothioacetamide) and 9 (for S-nitrosothiourea), respectively.\r\nDecomposition Products\r\nThe early work of Werner(41) proposed that decomposition of aliphatic RSNO+ moiety results in the formation of disulfide (RSSR)2+ and nitric oxide (eqs 14 and 15, Table 4). Collings et al.(27) observed that this reaction involves a rate law whereby the first term represents a reaction between the free substrate and the S-nitroso adduct, while the second term corresponds to a simple bimolecular reaction of two RSNO+ molecules contributing to the second-order kinetics(19) as in the case of TU. In a parallel decomposition pathway, a subsequent intramolecular transnitrosation of S-nitrosothiourea may occur to form N2, a pathway proposed to dominate at lower acidities and be largely irreversible (eq 11 in Table 4). Results of NOx chemiluminescence analysis in Figure 5 show that decomposition to NO proceeds at a much faster rate for S-nitrosothioacetamide. Under the same conditions, nitrous acid disproportionation to NO accounts for less than 6% in 5 min where the yield is more than 80% for both substrates. Moreover, no N2 product has been detected using micro-GC at this acidity. This precludes N-nitrosation at the amine sites as well an intramolecular transnitrosation as this would have resulted in subsequent formation of N2 in either case. At pH 1 and below, formation of NO constitutes the dominant decomposition pathway of the S-nitrosothioacetamide and S-nitrosothiourea.\r\n\r\nConclusion\r\nThermodynamically, S-nitrosation of TA occurs less favorably at a reaction enthalpy of −27.7 kJ compared to −29.6 kJ for TU. The more positive entropy involved for nitrosation of TU suggests that it is a better nucleophile, in coherence with its stronger electron donating amine group as opposed to the methyl group in TA. This is further supported by the much higher Fukui index for thiourea and thus higher susceptibility for nucleophilic attack. Apparent equilibrium constants increase with ionic strength and, accounting for ionic effects, translate to thermodynamic equilibrium constants of 86 and 2269 M–2·s–1 for TA and TU, respectively, at 25 °C. Equivalent reaction Gibbs free energies concur with theoretical calculations with errors as low as ±4 kJ for the SMD/M05-2X method. In terms of kinetics, the formation of S-nitrosothiourea entails a much higher kinetic rate constant of 24000 M–2·s–1 in contrast with the 15800 M–2·s–1 constant for the generation of S-nitrothioacetamide at 25 °C. These values exceed the current perceived encounter limit for diffusion-controlled electrophilic nitrosation of neutral species. Revisiting the analysis of the true nature of nitrosating agent establishes that nitrosation occurs via the nitrous acidium pathway at around pH 1. Moreover, the expected encounter limit for this pathway exceeds the observed kinetic rate constants in literature by several orders, and reactions do not occur in diffusion-controlled regimes. Reaction rates increase with temperature at activation energies of 54.9 and 66.1 kJ·mol–1 for the formation of S-nitrosothioacetamide and S-nitrosothiourea, respectively, confirming that such processes occur within a reaction control regime. Finally, these S-nitroso species are short-lived, with the main decomposition pathways leading to scission of the S–N bond to release NO at pH 1 and below.", user_id: 4, journal_id: 3, field_id: 13, institution_id: 15});

paper18 = Paper.create!({title: "NMR Chemical Shifts of Common Laboratory Solvents as Trace Impurities", body: "In the course of the routine use of NMR as an aid for organic chemistry, a day-to-day problem is the identification of signals deriving from common contaminants (water, solvents, stabilizers, oils) in less-than-analytically-pure samples. This data may be available in the literature, but the time involved in searching for it may be considerable. Another issue is the concentration dependence of chemical shifts (especially 1H); results obtained two or three decades ago usually refer to much more concentrated samples, and run at lower magnetic fields, than today's practice.\r\nWe therefore decided to collect 1H and 13C chemical shifts of what are, in our experience, the most popular “extra peaks” in a variety of commonly used NMR solvents, in the hope that this will be of assistance to the practicing chemist.\r\n\r\nExperimental Section\r\nNMR spectra were taken in a Bruker DPX-300 instrument (300.1 and 75.5 MHz for 1H and 13C, respectively). Unless otherwise indicated, all were run at room temperature (24 ± 1 °C). For the experiments in the last section of this paper, probe temperatures were measured with a calibrated Eurotherm 840/T digital thermometer, connected to a thermocouple which was introduced into an NMR tube filled with mineral oil to approximately the same level as a typical sample. At each temperature, the D2O samples were left to equilibrate for at least 10 min before the data were collected.\r\nIn order to avoid having to obtain hundreds of spectra, we prepared seven stock solutions containing approximately equal amounts of several of our entries, chosen in such a way as to prevent intermolecular interactions and possible ambiguities in assignment. Solution 1:  acetone, tert-butyl methyl ether, dimethylformamide, ethanol, toluene. Solution 2:  benzene, dimethyl sulfoxide, ethyl acetate, methanol. Solution 3:  acetic acid, chloroform, diethyl ether, 2-propanol, tetrahydrofuran. Solution 4:  acetonitrile, dichloromethane, dioxane, n-hexane, HMPA. Solution 5:  1,2-dichloroethane, ethyl methyl ketone, n-pentane, pyridine. Solution 6:  tert-butyl alcohol, BHT, cyclohexane, 1,2-dimethoxyethane, nitromethane, silicone grease, triethylamine. Solution 7:  diglyme, dimethylacetamide, ethylene glycol, “grease” (engine oil). For D2O. Solution 1:  acetone, tert-butyl methyl ether, dimethylformamide, ethanol, 2-propanol. Solution 2:  dimethyl sulfoxide, ethyl acetate, ethylene glycol, methanol. Solution 3:  acetonitrile, diglyme, dioxane, HMPA, pyridine. Solution 4:  1,2-dimethoxyethane, dimethylacetamide, ethyl methyl ketone, triethylamine. Solution 5:  acetic acid, tert-butyl alcohol, diethyl ether, tetrahydrofuran. In D2O and CD3OD nitromethane was run separately, as the protons exchanged with deuterium in presence of triethylamine.\r\n\r\nResults\r\nProton Spectra (Table 1). A sample of 0.6 mL of the solvent, containing 1 μL of TMS,1 was first run on its own. From this spectrum we determined the chemical shifts of the solvent residual peak2 and the water peak. It should be noted that the latter is quite temperature-dependent (vide infra). Also, any potential hydrogen-bond acceptor will tend to shift the water signal downfield; this is particularly true for nonpolar solvents. In contrast, in e.g. DMSO the water is already strongly hydrogen-bonded to the solvent, and solutes have only a negligible effect on its chemical shift. This is also true for D2O; the chemical shift of the residual HDO is very temperature-dependent (vide infra) but, maybe counterintuitively, remarkably solute (and pH) independent.\r\nWe then added 3 μL of one of our stock solutions to the NMR tube. The chemical shifts were read and are presented in Table 1. Except where indicated, the coupling constants, and therefore the peak shapes, are essentially solvent-independent and are presented only once.\r\nFor D2O as a solvent, the accepted reference peak (δ = 0) is the methyl signal of the sodium salt of 3-(trimethylsilyl)propanesulfonic acid; one crystal of this was added to each NMR tube. This material has several disadvantages, however:  it is not volatile, so it cannot be readily eliminated if the sample has to be recovered. In addition, unless one purchases it in the relatively expensive deuterated form, it adds three more signals to the spectrum (methylenes 1, 2, and 3 appear at 2.91, 1.76, and 0.63 ppm, respectively). We suggest that the residual HDO peak be used as a secondary reference; we find that if the effects of temperature are taken into account (vide infra), this is very reproducible. For D2O, we used a different set of stock solutions, since many of the less polar substrates are not significantly water-soluble (see Table 1). We also ran sodium acetate and sodium formate (chemical shifts:  1.90 and 8.44 ppm, respectively).\r\n\r\nCarbon Spectra\r\nTo each tube, 50 μL of the stock solution and 3 μL of TMS1 were added. The solvent chemical shifts3 were obtained from the spectra containing the solutes, and the ranges of chemical shifts show their degree of variability. Occasionally, in order to distinguish between peaks whose assignment was ambiguous, a further 1−2 μL of a specific substrate were added and the spectra run again.\r\nFor D2O solutions there is no accepted reference for carbon chemical shifts. We suggest the addition of a drop of methanol, and the position of its signal to be defined as 49.50 ppm; on this basis, the entries in Table 2 were recorded. The chemical shifts thus obtained are, on the whole, very similar to those for the other solvents. Alternatively, we suggest the use of dioxane when the methanol peak is expected to fall in a crowded area of the spectrum. We also report the chemical shifts of sodium formate (171.67 ppm), sodium acetate (182.02 and 23.97 ppm), sodium carbonate (168.88 ppm), sodium bicarbonate (161.08 ppm), and sodium 3-(trimethylsilyl)propanesulfonate [54.90, 19.66, 15.56 (methylenes 1, 2, and 3, respectively), and −2.04 ppm (methyls)], in D2O.\r\n\r\nTemperature Dependence of HDO Chemical Shifts.\r\nWe recorded the 1H spectrum of a sample of D2O, containing a crystal of sodium 3-(trimethylsilyl) propanesulfonate as reference, as a function of temperature. The data are shown in Figure 1. The solid line connecting the experimental points corresponds to the equation which reproduces the measured values to better than 1 ppb. For the 0 - 50oC range, the simpler\r\ngives values correct to 10 ppb. For both equations, T is the temperature in °C.", user_id: 4, journal_id: 3, field_id: 13, institution_id: 16});

paper19 = Paper.create!({title: "Tetraarylborate polymer networks as single-ion conducting solid electrolytes", body: "A new family of solid polymer electrolytes based upon anionic tetrakis(phenyl)borate tetrahedral nodes and linear bis-alkyne linkers is reported. Sonogashira polymerizations using tetrakis(4-iodophenyl)borate, tetrakis(4-iodo-2,3,5,6-tetrafluorophenyl)borate and tetrakis(4-bromo-2,3,5,6-tetrafluorophenyl)borate delivered highly cross-linked polymer networks with both 1,4-diethynylbeznene and a tri(ethylene glycol) substituted derivative. Promising initial conductivity metrics have been observed, including high room temperature conductivities (up to 2.7 × 10−4 S cm−1), moderate activation energies (0.25–0.28 eV), and high lithium ion transport numbers (up to tLi+ = 0.93). Initial investigations into the effects of important materials parameters such as bulk morphology, porosity, fluorination, and other chemical modification, provide starting design parameters for further development of this new class of solid electrolytes.\r\n\r\nIntroduction\r\nEmerging battery technologies using lithium metal or high-energy alloys at the anode promise cells with unprecedented energy densities.1 Their successful development will allow more power to be generated from renewable but intermittent sources.2 The redesign of many current cell components that are incompatible with these materials constitutes a major challenge for current research,3 and includes identifying replacements for the electrolytes now used in lithium-ion intercalation cells.4 Commercial devices rely on organic electrolyte solutions with lithium salts of simple non-coordinating anions (e.g. LiPF6) dissolved in highly polar and coordinating solvents, such as organic carbonates.4 These solutions present numerous safety and performance concerns.5 The lack of mechanical resistance in the electrolyte leads to device short circuits from lithium dendrite growth upon repeated charge/discharge cycles.6 Additionally, mobile counteranions in solution polarize the electrolyte, which decreases the operating voltage of the cell, potentially detracting from its lifetime and capacity as anions that have migrated to the anode decompose into insoluble materials such as LiF.7\r\nSeveral strategies are now being pursued to address these limitations. Anchoring the counteranions into a polymeric structure renders them immobile, providing so-called ‘single-ion’ conducting electrolytes.8 In theory, this approach prevents depletion of anions near the anode while charging. Such depletion produces a substantial electric field, which has been predicted to increase the rate of lithium dendrite formation.9 It has also been suggested that a mechanically resistant solid electrolyte with sufficient shear modulus (G′ > 7 GPa) could prevent lithium dendrites from crossing the cell and contacting the cathode.10 Indeed, a particular block copolymer (PS-b-PEO) that used a rigid polystyrene block to reinforce the conductive poly(ethylene oxide) fraction displayed improved resistance to dendrite penetration,11a although low modulus cross-linked PE-PEO materials also exhibited excellent dendrite growth resistance.11b Solid electrolytes that apply both strategies might provide excellent protection against both dendrite growth and cell failure from mechanical trauma.12\r\nAmong single-ion conducting electrolytes based upon organic polymers, anionic tetracoordinate borate centers have been studied in a number of contexts (Fig. 1). For example, borates are often incorporated into linear polymers, condensed from multifunctional alcohols13 and/or carboxylic acids.14 Capping or plasticizing agents such as oxalic acid (1) or polyethylene glycols (2) further modify their performance. A noteworthy and exceptionally anion-dense material utilized tartaric acid (3) as the boron-coordinating component.15 Although these approaches yield high anion densities, they also present stable coordination sites for lithium, which favor tight ion pairing that slows Li+ conduction. The recent work of Colby16 reports borate centers that do not interact with lithium strongly. Calculations suggested that siloxane polymers bearing tetraarylborate substituents (4) or their perfluorinated analogs (5) would interact weakly with Li+ to provide highly conductive electrolytes. However, conductivities well below 10−6 S cm−1 were first observed, which increased to only 10−5 S cm−1 upon addition of a plasticizer. For these materials, it is possible that the distance between borate centers is too large for efficient site-to-site Li+ hopping, which calculations have predicted to be a critical feature for effective single-ion polymer electrolytes.17\r\nRecently, we reported the synthesis of porous organic polymers that display exceptional ammonia adsorption, apparently as a result of the interpenetration of individual networks (Fig. 2).18 Interpenetration of the networks places two or more carboxylic acid functional groups in close proximity, allowing for the cooperative enhancement of effective acidity. Making a conceptual substitution, we hypothesized that the tetraarylborates incorporated into a similar interpenetrated network would be held sufficiently close to provide highly conductive solid electrolytes. Herein, we report our successful realization of such materials and demonstrate that they are amenable to straightforward chemical modification, making these polymers an intriguing platform for solid electrolyte development.\r\nAt the outset of our investigations, only a single example of a fourfold cross coupling reaction occurring at a tetraarylborate center had been reported (i.e., 6 → 7, Scheme 1).19 We investigated the polymerization of both lithium tetraarylborate 6, as well as its triethylammonium analog 8. Buchwald's second generation XPhos precatalyst20 was used under Sonogashira cross-coupling conditions similar to those known to be compatible with potassium aryltrifluoroborates,21 which provided productive polymerizations with 1,4-diethynylbenzene (9). The resulting insoluble polymers exhibited elemental analyses and infrared spectra consistent with the expected structures, suggesting a high extent of reaction. In contrast to previous reports of neutral phenylene ethynylene-linked porous polymers,22 these polymers were non-porous, as determined by nitrogen gas adsorption measurements performed at 77 K. In addition, the lack of peaks arising from powder X-ray diffraction suggests that the polymers do not adopt a specific network structure (e.g., diamondoid, etc.). We assume an irregular, densely packed and cross-linked material. Although these materials display no permanent porosity, the triethylammonium cations initially delivered with monomer 8 could be easily exchanged with LiOH, offering a means to use other basic metal salts (e.g., NaOH, KOH) to generate a family of solid electrolytes from a single parent polymer. \r\nAccordingly, we focused our initial investigations on polymers derived from triethylammonium borate building blocks. Notably, materials polymerized from DMSO solutions (10a) showed a moderate ionic conductivity of 3.6 × 10−5 S cm−1 at 27 °C (Fig. 3) after a rigorous sequence of ion exchange (11a), washing with low boiling solvents (MeOH, THF), drying in vacuo, and readsorption of small quantities of propylene carbonate. During our initial attempts to improve the conductivity of this material by optimizing the synthetic procedure, we were confronted by a striking result: while polymers produced in DMF solution (10b and 11b) presented elemental analysis and infrared spectra indistinguishable from the polymers produced in DMSO, they were universally non-conductive (<10−8 S cm−1). SEM images of these materials, conversely, did provide noteworthy contrast (Fig. 4). Conductive materials synthesized in DMSO have a smooth, continuous appearance, whereas the nonconductive polymers prepared in DMF appear rough on the micron scale. Our hypothesis for the effect of this morphology change on conductivity will be discussed further below.\r\nFurther attempts to improve the conductivity of these materials through optimization of the synthetic procedure failed, so we next sought polymers with improved conductivity by weakening the lithium–borate interaction through perfluorination of the aromatic rings of the borate anions.23 Polymerization of perfluorinated arylborate monomer 12 under our standard conditions again provided a non-porous cross-linked polymer (Scheme 2, 13). After exchange of the triethylammonium cations to Li+, the resulting polymer (14), exhibited nearly an order of magnitude higher ionic conductivity of 2.7 × 10−4 S cm−1 at 28 °C. This value approaches that necessary for incorporation into working Li-ion battery cells.4 Cyclic voltammetry measurements using both stainless steel and titanium working electrodes also suggested that this initial material represented an appropriate starting point for solid electrolyte development (Fig. 5). Our initial fluorinated polymer (14) shows oxidative stability to approximately 3.5–3.7 V (vs. Li/Li+) at 90 °C. This may be directly applicable to cells incorporating iron phosphate cathodes,24 but is lower than expected considering the constituent parts have been reported in electrolytes with superior oxidative stabilities. The observed electrochemical reactivity may be the result of trace impurities in the synthesized material. Additionally, this material displayed acceptable initial stability to lithium metal. A symmetric Li(s)|electrolyte|Li(s) cell was constructed, and the ionic conductivity was measured every hour for 200 hours total. Over this period, no decrease in total conductance (i.e. including ionic and interfacial impedance) was observed. With the perfluorinated borate node identified as a suitable initial building block for a solid electrolyte, we were next able to shift our attention to varying the network structure through changes in polymerization conditions, as well as the structure of the linear bis-alkyne linker.\r\nSynthetic conditions that delivered porous anionic polymers were identified by utilizing the corresponding brominated monomer 15, which more closely resembles those described by Thomas for a similar porous polymer linked by 1,3,5-triethynylbenzene.25 Under these conditions, the resulting tetraarylborate polymer (16) displayed permanent porosity (Scheme 3). Therefore, the precise synthetic conditions, rather than the network topology, were responsible for the lack of permanent porosity in polymers 11 and 14. After soaking with excess LiPF6 to exchange any transition metal or organic cation impurities and subsequent thorough washing to remove excess lithium, BET surfaces areas on the order of 480 m2 g−1 were measured (see ESI†). The particle morphology of these samples was also rough (see Fig. S15†), similar to the non-conductive, non-porous samples of 14. Likewise, the porous materials proved to be over an order of magnitude less conductive than their non-porous analog 14 (1.4 × 10−5 S cm−1 for 16 vs. 2.7 × 10−4 S cm−1 for 14). In fact, in this case, the fluorinated polymer 16 displays lower conductivity than the non-fluorinated analog 11a prepared from DMSO. Surprisingly, while dense fluorinated polymer 14 and its porous analog 16 differ in terms of bulk conductivity by over an order of magnitude, they display approximately the same activation energy (Fig. 6). Therefore, the overall particle morphology, not permanent porosity, appears to be the most useful predictor of bulk conductivity across a pressed pellet.\r\nWhen considering transport through the polymer particles, two opposing features must be considered. While the non-porous materials may feature a favorable average anion-to-anion distance, and a higher density of charge carriers, the resulting conduction pathway could be highly tortuous or otherwise hindered. The porous materials might feature open transport pathways, but would require a longer ion hopping distance. In our case, the higher spatial concentration of charge carriers in the dense materials seems to lead to higher performance in polymer 14. However, these considerations still cannot explain the dramatic difference in conductivity between rough and smooth materials (i.e. 11a vs. 11b).\r\nAn additional, and perhaps more compelling explanation, however, is that bulk conductivity is highly dependent on surface conduction pathways. A mechanism based predominantly on grain boundary conduction would help to explain the overwhelming dependence of conductivity on morphology, where chemically identical polymers 11a and 11b differ in conductivity by over four orders of magnitude. The porous and non-porous materials would still feature different densities of charge carriers at the grain boundaries, allowing for large differences in bulk conductivity values in materials with identical activation energies (i.e. 14 vs. 16). We currently favor the following: the micron-sized particles imaged in Fig. 4 are not single polymer particles, but instead, are aggregates of much smaller individual particles. In the case of highly conductive materials such as 11a or 14, efficient packing of exceedingly small particles allows for a high density of surface conduction pathways. The 'rough' nature of non-conductive materials such as 12b is actually the visualization of individual polymer particles, which by simple geometry, feature fewer unbroken conduction pathways between the electrodes. This type of behavior would not be unprecedented. For example, CaF2 displays greater than an order of magnitude increase in fluoride ion conductivity upon decreasing the average crystallite size from 200 nm to 9 nm.26\r\nAs has been very well demonstrated in the context of block copolymers,27 ethylene glycol domains might provide effective conduction pathways for lithium ions, potentially in the absence of organic solvents, even if Li+ ion conduction occurred only along the interparticle boundaries. We therefore tethered two tri(ethylene glycol) moieties to the 1,4-diethynybenzene linker (17, Scheme 4) in order to evaluate this possibility. Our standard synthetic procedure using triethylammonium borate 12 provided the expected polymer in reasonable yield. However, we were surprised to find that no significant ion exchange occurred upon exposure to lithium hydroxide. Therefore, we generated the lithium-containing material 19 by polymerizing lithium borate 18, which proved to be free of nitrogen-containing impurities (i.e., triethylammonium cations generated during the Sonogashira polymerization) by elemental analysis.\r\nAlthough glycol-containing polymer 19 was not conductive without additional solvent, it did yield an important performance contrast with 14 when incorporated in symmetric Li(s)|borate polymer|Li(s) cells. Using a 300 mV applied potential (versus open circuit), we subjected polymers 14 and 19 to four 22 min potential steps and relaxations, followed by a 24 h hold, as an initial assessment of the lithium transference number and stability towards lithium metal under operating conditions (Fig. 7a). Polymer 14 exhibited higher ionic conductivity and larger current in response to the applied voltage. However, it also displayed greater current decay during both the 22 minute steps (indicating a lower transference number) as well as over the course of the entire experiment (indicating lower stability to lithium metal). Comparison of the current between the beginning and end of the potential step yields a transference number (tLi+) of 0.89 for 14 and 0.93 for 19 (average of four pulses). At the end of every step and relaxation, as well as at the end of the entire experiment, ac impedance spectra were collected (Fig. 7b), which also indicate that polymer 19 is more stable to the experimental conditions. Both materials showed little or no change in interfacial impedance, supporting the technique used for calculating transference number;28 tri(ethylene glycol) substituted polymer 19 actually displayed a slight increase in ionic conductivity over the course of the experiment (green data). This behaviour was in sharp contrast to that of 14, which suffered an obvious decrease. The ability to make a meaningful impact on such material parameters through straightforward chemical substitution of one of the monomer units should provide a direct avenue to further improve the performance of these materials and single-ion conductors.\r\n\r\nConclusions and outlook\r\nMany traditional heteroatom-containing polymers, such as polyethylene oxide, polyacrylates, polyacrylamides, polyacrylonitrile, polystyrenesulfonate, or polyvinylidene fluoride have formed the basis of novel electrolytes for lithium ion batteries, either as pure components,29 as composite materials with inorganic filler,30 or as gel electrolytes.31 Here, we have introduced a new organic polymer electrolyte, which has strong single ion-conducting character (tLi+ 0.89–0.93), moderate activation energies (0.25–0.28 eV), and promising room temperature conductivities (up to 2.7 × 10−4 S cm−1). While a full evaluation of the mechanical properties of these polymers has not been completed, their 3D-crosslinked nature is comparable in many senses to metal–organic frameworks, where Young's moduli around 10 GPa have already been measured,32 and shear moduli above 10 GPa have been predicted computationally for a number of frameworks.33 Although analogous measurements have not been made on PAF-type porous materials, initial computational work suggests that these materials should display similar rigidity.34 Although the most reasonable current mechanism for conductivity appears to invoke the particle surface exclusively, chemical modification of the monomer units provides a straightforward approach to further tune performance. With conductivity metrics that are already competitive with more mature polymer platforms, further investigations based upon non-coordinating arylborate building blocks should prove to be a promising new direction in solid electrolyte design.", user_id: 4, journal_id: 12, field_id: 10, institution_id: 17});

paper20 = Paper.create!({title: "Comparative Genomic Analysis of Asian Haemorrhagic Septicaemia-Associated Strains of Pasteurella multocida Identifies More than 90 Haemorrhagic Septicaemia-Specific Genes", body: "Abstract\r\nPasteurella multocida is the primary causative agent of a range of economically important\r\ndiseases in animals, including haemorrhagic septicaemia (HS), a rapidly fatal disease of\r\nungulates. There is limited information available on the diversity of P. multocida strains that\r\ncause HS. Therefore, we determined draft genome sequences of ten disease-causing isolates\r\nand two vaccine strains and compared these genomes using a range of bioinformatic\r\nanalyses. The draft genomes of the 12 HS strains were between 2,298,035 and 2,410,300\r\nbp in length. Comparison of these genomes with the North American HS strain, M1404, and\r\nother available P. multocida genomes (Pm70, 3480, 36950 and HN06) identified a core set\r\nof 1,824 genes. A set of 96 genes was present in all HS isolates and vaccine strains examined\r\nin this study, but absent from Pm70, 3480, 36950 and HN06. Moreover, 59 genes were\r\nshared only by the Asian B:2 strains. In two Pakistani isolates, genes with high similarity to\r\ngenes in the integrative and conjugative element, ICEPmu1 from strain 36950 were identified\r\nalong with a range of other antimicrobial resistance genes. Phylogenetic analysis indicated\r\nthat the HS strains formed clades based on their country of isolation. Future analysis\r\nof the 96 genes unique to the HS isolates will aid the identification of HS-specific virulence\r\nattributes and facilitate the development of disease-specific diagnostic tests.\r\n\r\nIntroduction\r\nPasteurella multocida is a Gram-negative, nonmotile, nonspore-forming coccobacillus. It is the\r\ncausative agent of a spectrum of economically important diseases worldwide, including atrophic\r\nrhinitis in pigs, haemorrhagic septicaemia (HS) in cattle and buffalo, fowl cholera in poultry, snuffles\r\nin rabbits and sporadic human infections that often follow dog or cat bites [1,2]. P. multocida\r\nis a heterogeneous species with strains being commonly differentiated by serology [3], or more\r\nrecently capsular locus-specific multiplex PCR [4], into five capsular serogroups designated A, B,\r\nD, E and F. Strains belonging to capsular serogroups A, D and F produce capsules composed of\r\nhyaluronic acid, heparin and chondroitin respectively [4]. The composition of the B and E capsules\r\nis unknown but the genes required for their biosynthesis have been defined [4]. A second\r\nserological typing system is also often used to differentiate strains into 16 Heddleston serotypes or\r\nserovars based on lipopolysaccharide (LPS) antigens [5]. Full strain designations usually combine\r\nboth systems, such that a designation of B:2 indicates capsule serogroup B and LPS serovar 2.\r\nHaemorrhagic septicaemia (HS) is an acute and generally fatal disease which occurs mainly in\r\ncattle and buffalo [2]. Haemorrhagic septicaemia is prevalent in Asia and Africa, where its presence\r\nis of great economic importance. In Pakistan, it has been reported as the most economically\r\nimportant bacterial disease of cattle and buffalo [6]. Similarly, in Thailand, HS ranks high on the\r\nlist of economically important diseases of livestock [7]. Haemorrhagic septicaemia is caused by\r\ninfection with P. multocida strains belonging to capsular serogroups B and E [2]. Haemorrhagic\r\nsepticaemia strains producing a serogroup B capsule are predominant in Asia while strains producing\r\na serogroup E capsule are predominant in Africa, although African serogroup B isolates\r\nand Asian serogroup E isolates have occasionally been reported [8]. P. multocida strains that\r\ncause HS belong to the LPS serovars 2 or 5 which share the same LPS outer core biosynthesis\r\nlocus and produce structurally highly related, but antigenically distinct, LPS molecules [9].\r\nThe first complete genome sequence of a P. multocida strain (Pm70; GenBank accession\r\nAE004439) was determined in 2001 [10]. Analysis of the Pm70 genome identified more than\r\n100 genes predicted to be involved in virulence and identified complete gene sets for the following\r\npathways: TCA cycle, glycolysis, glyconeogenesis, oxidative pentose phosphate and Entner—\r\nDoudoroff [10].\r\nThere are currently 25 publicly available complete or draft P. multocida genomes. These\r\ngenomes are from strains isolated from different hosts and which cause a range of different diseases\r\n[11]. There have been only limited comparative analyses of these different genomes.\r\nHowever, analysis of the Pm70, 36950, 3480, HN06, X73, and P1059 genomes identified a\r\nunique 18 kbp region in the porcine atrophic rhinitis isolate, HN06, that contained 14 genes,\r\nincluding the toxA gene encoding the P. multocida toxin (PMT) (which causes the signs of\r\natrophic rhinitis) as well as several phage-related genes [12]. Further analyses also showed that\r\nan integrative conjugative element (ICE), ICEPmu1, was found in bovine respiratory disease\r\nisolate 36950, but not in any of the other strains. This element carried 11 different antibiotic\r\nresistance genes. A similar ICE has also been found in Histophilus somni and Mannheimia haemolytica\r\nwhich are both bovine respiratory pathogens [12].\r\nPrevious analysis of five P. multocida genomes (M1404, Pm70, 36950, X73, and P903) identified\r\na core set of 1786 genes (88% of Pm70 gene content) common to all strains and a pan\r\ngenome of more than 2,800 genes. Furthermore, each of these strains contained between 90 and\r\n261 unique genes not found in any of the other strains examined [13]. For strain 36950, more\r\nthan 47% of the unique genes identified were within the ICEPmu1 element, whereas for strain\r\nM1404 28% of unique genes were phage-derived elements. Importantly, a previous phylogenetic\r\ncomparison of nine P. multocida strains indicated little correlation between phylogenetic relationship\r\nand disease type, capsular/LPS type, host predilection or place of isolation [13].\r\nWe recently analyzed the genotypes of 23 P. multocida isolates, 14 recovered from HS-diseased\r\ncattle and buffalo located in different geographical areas and climate zones of Pakistan\r\nand nine from different regions of Thailand. All isolates were serovar B:2 and indistinguishable\r\nby multi locus sequence typing (MLST) with all strains sequence type 122. Furthermore, all isolates\r\nfrom within each country were indistinguishable by pulsed-field gel electrophoresis\r\n(PFGE) [14]. Therefore, to determine whether there was any diversity across these isolates we\r\ndetermined whole draft genome sequences of a selection of 12 of the strains using next generation\r\nsequencing (NGS). The draft genomes were then compared with the M1404 genome (a\r\nNorth American serovar B:2 HS-associated strain) and the genomes from four strains not associated\r\nwith HS (Pm70, 36950, 3480 and HN06). To our knowledge, this is the first detailed\r\ngenomic analysis of multiple HS-associated isolates of P. multocida.\r\n\r\nMaterials and Methods\r\nTen P. multocida strains that had been collected from buffalo or cattle with HS, each from different\r\nregions of Pakistan or Thailand, were sourced from the National Veterinary Laboratory\r\nin Islamabad or the Department of Livestock Development in Thailand, respectively. In addition,\r\ntwo vaccine strains from Pakistan were also included in this study (Table 1). Except for\r\nthe Faisalabad isolate (Table 1), all of the isolates had previously been identified as P. multocida\r\nand typed using MLST (all sequence type 122) [14]. The Faisalabad isolate was received\r\nfrom the National Veterinary Laboratory, Islamabad, Pakistan, and identified as a HS-associated\r\nP. multocida strain using both a P. multocida-specific and a HS-specific PCR (data not\r\nshown) [15].\r\nSequence assembly\r\nThe genomes of ten of the strains were de novo assembled using SPAdes v2.5.0 [16] and the\r\nremaining two strains were assembled using Velvet v1.2.07 [17]. For ten of the twelve strains,\r\nthe SPAdes procedure generated acceptable assemblies. However, for the Faisal and ATTK\r\nstrains, SPAdes produced unexpectedly large genome assemblies (8,278,703 and 6,134,337 bp\r\nfor Faisal and ATTK, respectively) due to low level contamination with genomic DNA from\r\nanother bacterial species (Bacillus cereus and Bacillus subtilis, respectively). Examination of\r\nthe Velvet statistics showed that the contaminating sequences were represented by short contigs\r\nhaving sequencing depth below 10x. To filter this contamination, we assembled the Faisal\r\nand ATTK sequences using Velvet with a manual setting of 10 for the minimum required coverage\r\n(“velvetg-cov_cutoff 10”) to remove these undesirable components of the assembly\r\ngraph prior to repeat resolution and contig extraction. Final genome assemblies of these\r\nstrains were also checked for contaminating sequences using BLASTN v2.2.26 [18,19]. To\r\nevaluate the accuracy of the generated contigs of the 12 assembled genomes, they were compared\r\nwith the Pm70 reference genome [10] using QUAST v2.3 [20]; sequence and assembly\r\nstatistics of the 12 genomes are given in Table 2. For all strains, scaffolds (or contigs for the\r\nVelvet assembled genomes) of less than 200 bp in length were removed before the final reordering\r\nusing Mauve [21] with Pm70 used as the reference sequence. The final ordered and oriented\r\nscaffold sequences were then annotated using the NCBI Prokaryotic Genome\r\nAnnotation Pipeline [22]. The 12 annotated genomes were submitted to GenBank [23,24];\r\naccession numbers are given in Table 3.\r\nVariant calls: single-nucleotide polymorphisms (SNPs) and insertion/\r\ndeletion polymorphisms (indels)\r\nSnippy (available at https://github.com/tseemann/snippy) was used to identify SNPs and Indels\r\nin the NGS sequence reads (FASTQ format) from each of the 12 genomes compared with the\r\nreference genome, Pm70.\r\nGenome alignments and feature analysis\r\nMauve v2.3.1 (default settings) [25] was used to align the genomes of the twelve Pakistani and\r\nThai P. multocida strains with the genomes of the following strains; M1404 (bovine HS isolate,\r\ntype B:2) [13], Pm70 (avian fowl cholera isolate) [10], HN06 (porcine atrophic rhinitis isolate)\r\n[26] and 3480 (GenBank: NC_017764.1) and 36950 [27] (porcine and bovine respiratory disease\r\nisolate respectively). The “homologs table” in Mauve was used to identify colinear orthologs\r\nacross each of the genomes using 50% DNA identity and 50% gene coverage as the\r\nminimum criteria for a match. All genes present only in a single strain were then manually\r\nchecked by BLAST [18,19] to confirm that they were unique. Genes unique to the Pakistani or\r\nThai strains, or unique to M1404, were also identified by this method.\r\nThe PHAge Search Tool (PHAST) [28] was used to identify the positions of putative phage\r\nelements in all genomes. For PHAST analysis the FASTA files containing all concatenated contigs\r\nfor each genome were uploaded to the public PHAST web server (http://phast.wishartlab.\r\ncom/). To avoid false positives caused by non phage-related mobile genetic elements, PHAST\r\nfilters out these mobile genetic elements using a two-step process. In the first step, PHAST uses\r\na customized mobile genetic element database to directly filter out some of the most typical\r\nmobile genetic elements (Y. Zhou, personal communication). In the second step, PHAST filters\r\nout the rest of the mobile genetic elements when it identifies potential prophages by the density-based\r\nspatial clustering of applications with noise (DBSCAN) algorithm [28]. Specifically,\r\nthe DBSCAN algorithm marks out the random mobile genetic elements as noise and clusters\r\nother gene elements into potential prophages (Y. Zhou, personal communication). In addition,\r\nPHAST predicts potential prophages based on a number of factors including the relative density\r\nof identified prophage-like genes, GC ratio, functional completeness and gene similarity to\r\nalready known phages. The genomes were also checked for the presence of antimicrobial resistance\r\ngenes using the ResFinder tool [29].\r\n\r\nResults and Discussion\r\nGenome sequencing of 12 P. multocida HS strains\r\nTen P. multocida strains, isolated from HS cases in buffalo (8 isolates) and cattle (2 isolates)\r\nfrom Pakistan and Thailand, and two Pakistani HS vaccine strains were used for this study\r\n(Table 1). Except for the Faisalabad isolate (Table 1), all of the isolates had previously been genotyped\r\nusing MLST as ST122 [14]. Therefore, in order to identify if there were differences\r\nbetween the strains, we determined whole genome draft sequences of each strain. Genomic\r\nDNA was isolated from each strain and sequenced on an Illumina HiSeq 2000. Sequences reads\r\nwere de novo assembled, resulting in between 32 (strains THF and V1) and 77 (strain Karachi)\r\ncontigs of > 200 bp. The genomic features of the 12 sequenced strains and accession numbers\r\nare shown in Table 3. The predicted genome sizes ranged from 2.34 to 2.46 Mbp and the number\r\nof coding sequences (CDS) ranged between 2,082 (strains THA, THD and THF) and 2,179\r\n(strain TX1). The GC content was highly conserved across all strains (40.31 to 40.41%).\r\nVariant calls and genetics of capsule and LPS biosynthesis in the HScausing\r\nstrains\r\nMapping of the sequencing reads of the 12 Asian genomes to the complete genome of Pm70\r\nidentified between 16,443 and 16,513 CDS SNPs in the 12 genomes (Table 4). Furthermore,\r\nbetween 12 and 19 indels were also identified in the CDS of the 12 genomes (Table 4).\r\nAll HS-associated strains contained the type B capsular biosynthetic locus. Only three\r\nnucleotide changes were observed in the cap locus of all of the Asian strains compared to the\r\ncap locus of M1404 [35]. Two of the mutations were silent, while the third encoded a missense\r\nmutation (D50Y) within the putative glycosyltransferase EpsJ. An additional nucleotide change\r\nin a non-coding region was observed in the Pakistani strains (relative position: 1185274 in\r\nBUKK). The FASTA file of the cap locus of strain BUKK is provided as S1 File.\r\nAll HS-associated strains also contained the LPS outer core biosynthesis locus that is shared\r\nby strains belonging to Heddleston serovars 2 and 5 [9]. Only a single nucleotide change was\r\nobserved across the LPS outer core biosynthesis loci of the 12 Asian strains when compared\r\nwith the M1404 locus [9]. The FASTA file of the LPS biosynthesis locus of strain BUKK is provided\r\nas S2 File. The Heddleston 2 and 5 type strains can be differentiated serologically by the\r\npresence (serovar 5) or absence (serovar 2) of PEtn on the 2nd inner core heptose of the LPS\r\n[9]. Addition of this PEtn residue to the LPS is dependent on the presence of an intact lpt-3\r\ngene (annotated as dcaA in Pm70) [9]. All HS strains contained a disrupted lpt-3 gene, with a\r\nnonsense mutation (relative position: 499751 in BUKK strain) identical to the mutation previously reported in M1404 [9]. Therefore, all of the HS strains analysed in this study are\r\npredicted to belong to LPS serovar 2. Indeed, all of the Pakistani and Thai strains had previously\r\nbeen classified using Heddleston serology as LPS serovar 2, except for THD which had\r\nbeen reported as LPS serovar 2,5 (P. Pathanasophon, personal communication, June, 2012).\r\nHowever, our genetic analyses would indicate that THD also belongs to LPS serovar 2,\r\nhighlighting the advantage of molecular over serological typing methods.\r\nIt has been shown previously that most P. multocida strains produce two inner core LPS glycoforms\r\ndesignated A and B [30]. Production of these two glycoforms is dependent on the\r\npresence of two active heptosyltransferases, HptA and HptB. HptA is specific for inner core\r\nglycoform A and is responsible for the addition of the first heptose to a single phosphorylated\r\n3-deoxy-D-manno-octulosonic acid (Kdo). For glycoform B assembly, unphosphorylated Kdo\r\nresidues have a second Kdo residue added followed by the addition of the first heptose by a different\r\nheptosyltransferase, HptB [30]. The hptB gene in all strains included in this study was\r\nintact, indicating that HptB would be fully functional. The hptA gene was intact in all strains\r\nincluded in this study except for strain 3480 where it contained a premature stop codon (mutation\r\nat 2232375). Therefore, we would predict that strain 3480 is unable to add the first heptose\r\nto the glycoform A inner core. Interestingly, a hptA mutant constructed in the P. multocida\r\nfowl cholera isolate VP161 was significantly attenuated for virulence, predicted to be due to the\r\npresence of truncated glycoform A LPS on the surface of the cell [30]. However, in a further\r\nstudy it was found that growth of the hptA mutants in vivo selected for virulent strains with\r\nnonsense suppressor mutations in the Kdo phosphokinase gene, kdtA. This mutation prevented\r\nthe phosphorylation of any Kdo residues, allowing all Kdo residues to be available for\r\nglycoform B LPS assembly [36].\r\nPhage identification\r\nAll of the genomes from known HS-associated strains were analysed for the presence of phage\r\nelements using PHAST [28]. This analysis identified four regions corresponding to putative\r\ntemperate phage elements. The genomic locations of these four regions in PVAcc strain, as an\r\nexample, are presented in Table 5. These regions correspond with the main genetic differences\r\nidentified between different groups of strains (regions 1–4; Fig 3). Regions 3 and 4 were identified\r\nas intact phages and have been reported previously [13]. Region 2 was identified as an\r\nincomplete phage and region 1 as a questionable phage (Fig 3). The questionable phage identified\r\nin region 1 is present in the seven Pakistani strains, the incomplete phage identified in\r\nregion 2 is shared by all the Asian strains (relative position BUKK_04735–04880) and the\r\nintact phages identified in region 3 and 4 are shared by all the HS strains (relative position\r\nBUKK_07250–07540). The phage elements identified in regions 1, 2, 3 and 4 are situated at\r\ntRNALeu, tRNAMet, tRNASer and tRNAMet genes respectively. This correlates with the previous\r\nreports that the F108 phage and the lysogenic phage carrying the PMT toxin, integrate into the\r\nt33tRNALeu and the t3tRNALeu genes respectively [13,40]. Temperate phages may contain \r\nimportant virulence genes [41]. Indeed, as noted above the P. multocida PMT toxin is the primary\r\nvirulence factor for porcine atrophic rhinitis and is carried on a lysogenic bacteriophage\r\n[42]. Therefore, the presence of different phage elements in different sets of strains may impact\r\non the virulence of these strains. Further studies should assess the impact of these different\r\ngene sets on virulence. A P. multocida HS-specific diagnostic PCR has been developed previously [15]. We\r\nsearched for the DNA sequence recognized by this PCR in all genomes and identified it within\r\nthe putative intact prophage within region 3 (Fig 3), Thus, this sequence is indeed present in all\r\nof the HS strains analysed in this study and is not present in any of the non HS-associated\r\ngenomes analysed.\r\n\r\nConclusion\r\nIn conclusion, we have shown that HS-associated P. multocida strains belonging to capsular\r\nserogroup B form a very closely related group, but are distinguishable using whole genome\r\nanalyses. We identified 96 genes unique to the HS-associated strains and future characterization\r\nof these genes should elucidate the roles they play in disease pathogenesis, virulence and\r\nhost specificity. Selected genes from this group will be excellent candidates for the development\r\nof a rapid diagnostic test for HS. The putative integrative conjugative element (ICE) identified\r\nin two Pakistani isolates should be further analysed to determine its mobility and relatedness to\r\nICEPmu1 of strain 36950.", user_id: 1, journal_id: 11, field_id: 7, institution_id: 18});

paper21 = Paper.create!({title: "Composite genome approach to identify phylogenetically informative data from next-generation sequencing", body: "Abstract\r\nBackground\r\nImprovements in sequencing technology now allow easy acquisition of large datasets; however, analyzing these data for phylogenetics can be challenging. We have developed a novel method to rapidly obtain homologous genomic data for phylogenetics directly from next-generation sequencing reads without the use of a reference genome. This software, called SISRS, avoids the time consuming steps of de novo whole genome assembly, multiple genome alignment, and annotation.\r\nResults\r\nFor simulations SISRS is able to identify large numbers of loci containing variable sites with phylogenetic signal. For genomic data from apes, SISRS identified thousands of variable sites, from which we produced an accurate phylogeny. Finally, we used SISRS to identify phylogenetic markers that we used to estimate the phylogeny of placental mammals. We recovered eight phylogenies that resolved the basal relationships among mammals using datasets with different levels of missing data. The three alternate resolutions of the basal relationships are consistent with the major hypotheses for the relationships among mammals, all of which have been supported previously by different molecular datasets.\r\nConclusions\r\nSISRS has the potential to transform phylogenetic research. This method eliminates the need for expensive marker development in many studies by using whole genome shotgun sequence data directly. SISRS is open source and freely available at https://github.com/rachelss/SISRS/releases webcite.\r\nKeywords: Phylogenetics; Next-generation sequencing; Apes; Mammals\r\n\r\nBackground\r\nUntil recently, phylogenetic studies relied on tens of loci (at most) from the genome to determine evolutionary relationships [1], [2]. However, these datasets often had insufficient information to provide strong support for all the relationships of interest [3]. Recent improvements in sequencing technology have enabled phylogenetic studies to use larger datasets in an attempt to resolve previously undetermined or controversial evolutionary relationships, but this area of research is still in its infancy [4]–[11].\r\nThere are currently several approaches to producing large datasets for phylogenetics. In the first approach, whole genomes are sequenced and assembled; genomes are then compared to identify homologous regions for phylogenetics [11]. The drawback of this approach is the time required to construct quality assemblies and identify homologous regions, either by annotating the genome or using genome comparison tools. Furthermore, because distantly related taxa may not be easily comparable, phylogenetic analyses using whole-genome comparisons have focused on closely related species for which alignments are possible [11], [12].\r\nIn a second approach, shotgun sequence data are aligned to a reference genome. This method assumes a reference genome, which is not always available. As with whole genome comparisons, the de novo assembly of a high-quality reference genome requires high-coverage data and significant time. However, even given a reference genome, homologous loci may not be recoverable for species distantly related to the reference [13].\r\nOther approaches involve sequencing a subset of the genome. One such approach screens existing datasets for variation in the taxa of interest [14]–[16]. In another, regions that are conserved across taxa are identified from whole-genome alignments; both the conserved elements and regions adjacent to them may contain phylogenetic information [6], [8], [9], [17]. In a third, a consistent subsample of the genome may be sequenced [18]. However, the drawback of these approaches is that new phylogenetic markers must be developed for each research study; significant time is often required for marker development and these data have limited potential for reuse. Additionally, a consistent, phylogenetically informative subsample of the genome may be difficult to obtain at deep taxonomic levels.\r\nHere we describe a novel computational tool, SISRS (pronounced “scissors”), to identify informative data for phylogenetic studies directly from shotgun sequencing of whole genomes. SISRS, which stands for Site Identification from Short Read Sequences, requires neither a reference genome nor a priori knowledge of potentially informative loci. Our software circumvents the difficulties in identifying homologous loci from whole-genome alignments when rearrangements have occurred because the conserved regions are not required to share identifiable synteny across taxa. SISRS also takes advantage of the raw data to avoid erroneously called genotypes in previously assembled genomes due to sequencing error or copy number variable regions (CNVs).\r\nSISRS identifies phylogenetically informative regions via a novel protocol (Fig. 1). (1) SISRS assembles a “composite genome” from shotgun sequencing reads for all taxa. (2) The composite genome is used as a reference to align the sequencing data for each sample. (3) The sequence for each sample is identified via a strict consensus (i.e. sites that are variable are called as unknown). (4) SISRS removes loci that have too few sites with callable genotypes (as specified by the user). In this way, SISRS identifies sites across entire genomes that are phylogenetically informative and reduces errors due to biological and experimental error.\r\nWe demonstrate that SISRS provides high quality phylogenetic datasets across a range of simulated and empirical data. First, the data output by SISRS for simulated shotgun reads was congruent with the starting phylogeny at all depths in the tree. Second, using previously sequenced shotgun data for seven primate taxa, we were able to rapidly identify homologous data using SISRS and estimate the known phylogeny accurately. Third, we used available data to estimate the phylogeny of mammals, the root of which has remained controversial. Using SISRS, phylogenies can be produced from next-generation sequencing reads in a matter of days. For example, identifying hundreds of thousands of variable sites for phylogenetics from over 100 Gb of raw mammalian transcriptome reads took less than four days.\r\n\r\nResults\r\nRecovery of phylogenetically informative sites\r\nTo determine how well our approach identified phylogenetically informative data, we simulated genomes on 36 phylogenies. These phylogenies included two topologies (ladder shaped and balanced) with three variants each: equal-length branches, longer deep branches, and shorter deep branches (Fig. 2). Each tree was rescaled by multiplying the branch length by a scaler of one to six. We then simulated NGS data on these genomes and examined how well we were able to recover variable sites. For all simulation trees, the number of potentially informative sites identified using SISRS increased with increased coverage (Fig. 3). As the distance between taxa (i.e. branch length) increased for a given tree, the number of output sites decreased (Fig. 3). Of these sites, a plurality allowed the accurate identification of the shallowest nodes within a tree, with a decreasing number allowing the identification of deeper nodes (Fig. 4; Additional file 1: Figure S1). Insufficient coverage in the simulations, lack of coverage by the composite genome, and insufficient coverage following mapping of the reads to the composite genome reference contributed to a failure to recover all variable sites (Fig. 5). Potential false positives due to read simulation error were removed by SISRS as part of calling by strict consensus; however, some new false positives were introduced, likely due to erroneous mapping of reads to the composite genome. These false positives represented less than 1 % of the sites found for any tree; thus, they have little effect on phylogenetic inference.\r\nMammal phylogeny\r\nWe further tested the utility of SISRS using NGS data from placental mammals, for which the phylogeny is controversial. This analysis was conducted using 40 cores; the total time to produce the composite genome was less than an hour; the remaining alignment, base calling, and site identification steps required an additional 87 hours. 10 Gb of memory was required during the composite genome assembly. The maximum amount of memory required to process the data mapped to the composite genome was 45 Gb; however, because data processing was conducted across multiple cores to increase the speed of the analysis, the total amount of memory used at one time by SISRS was over 300 Gb. Thus, this analysis could be conducted using fewer resources over more time.\r\nWe produced 15 alignments, each allowing a set number of unknown genotypes at each site (i.e. alignment 1 has no more than one species with an unknown genotype). The number of sites in the alignments ranged from 21 to over 1.5 million. Analyzed in a ML framework, the first four alignments produced phylogenies with multiple polytomies due to limited data; they are not described further. The remaining alignments produced phylogenies that reflect previous conflicting estimates of the relationships among mammals. For example, in regards to the basal relationships alignments 5, 10, 11, and 12 supported Xenarthra+Afrotheria (Atlantogenata) as a clade sister to all other mammals [19]–[21], alignment 6 supported Xenarthra as a separate clade [22], alignments 13, 14, and 15 supported Afrotheria as a separate clade [9], [23], and the remaining alignments did not resolve these relationships. Similarly, the relationship of the treeshrew to other mammals was difficult to resolve: for some alignments this species formed a clade with rodents, while for others it formed a clade with primates. The majority rule consensus phylogeny generated from alignment 10 (i.e. no more than 10 species had an unknown genotype at each site) is shown in Fig. 7; additional phylogenies are shown in Additional file 2: Figure S2.\r\n\r\nDiscussion\r\nData produced by SISRS\r\nFor simulations, SISRS was able to recover large numbers of variable sites, unless branch lengths were unreasonably long or coverage was low. Based on these results, coverage should average 5–10x for optimal marker identification; however, low coverage sequencing will also identify useful data. Most genomes are much larger than the one million bases in our simulations; far more sites will be identified for larger genomes, making the use of low coverage data feasible.\r\nIdentifying homologous variable sites was more challenging for trees with long branches (i.e. large evolutionary distances as measured by number of substitutions per site between pairs of taxa). Large numbers of substitutions at a region in the genome will result in difficulties assembling this region as a single locus to which data from all species can be aligned. Instead, we expect that data from the most similar species (e.g. A–B in the pectinate trees) will be assembled into a consensus contig; the distance between these species for the longest equal-branch-length pectinate tree is 0.12 substitutions per site. However, the distance from C to any other species is at least 0.24 substitutions per site (on average), and distances are longer for the remaining species. Thus, the contigs are expected to be assembled jointly from A/B, and independently from data for each of the remaining species (if assembly is possible given low-coverage subsampling of reads). Consequently, data from each species for a region of the genome will either align to different contigs (assembled independently from different species) or fail to align entirely. This process results in difficulty identifying homologous data using SISRS when branch lengths are long.\r\nHowever, this result is less problematic for empirical data. In real genomes, unlike our simulations, loci evolve at different rates; thus, there will likely always be some loci for which the branch length (in substitutions per site) between taxa is very small. These sites will be identified by SISRS.\r\nAs expected, deeper nodes were more difficult to recover, likely because the synapomorphies between the two clades may be overwritten by new substitutions. However, the sites that were identified are informative about these relationships. Overall, the concordance of the data with the simulation trees demonstrates that the SISRS approach produces extensive phylogenetically informative data for deep and shallow evolutionary time scales.\r\nEmpirical results\r\nUsing available NGS data we were able to recover the phylogeny of apes quickly and accurately. Similarly, using available NGS data we recovered a mammal phylogeny reflecting previous conflicting estimates of the relationships among mammals [12], [21], [23], [24]. These conflicting estimates, particularly in regards to the basal relationships and the position of the treeshrew, were all found using “traditional” phylogenetic methods.\r\nAdvantages of a composite genome\r\nGenerating a composite genome has multiple advantages over aligning data to a reference genome to identify potential phylogenetically informative sites. First, an assembled reference genome similar to the taxa of interest is not always available. Second, assembling a reference genome requires high coverage data from at least one species and is time consuming; assembling the whole genome is necessary because it is impossible to determine a priori regions of the genome that may be phylogenetically informative. In contrast, SISRS does not require high levels of coverage or a time consuming assembly. A composite reference genome containing phylogenetically-informative homologous regions can be assembled in a few hours. Furthermore, when taxa are highly diverged, data may align poorly to a single reference genome. In contrast, a composite genome contains data from all taxa, allowing better alignment of all data across the phylogeny. Because each species is subsampled for the assembly, unique regions will be limited in the final assembly, while maintaining an optimal assembly for conserved regions. Within each conserved region, the composite genome contains sites with the most common base, making it more likely that data from all taxa will align to this region.\r\nTime required\r\nThe time to run SISRS is highly variable, depending on the number of processors available, the number of samples sequenced, and the amount of data sequenced per sample. Given large numbers of processors (e.g. a cluster of >30 nodes), SISRS makes phylogenetic analysis from shotgun data possible within a few days. Even given the limitations of a desktop computer, it is possible to produce many phylogenies within a couple of weeks. Unlike other phylogenetic methods, SISRS entirely avoids the weeks required for marker development or sample processing; preparation for sequencing and the sequencing time itself are required for all phylogenomic approaches. Alternatively, as with the analyses conducted here, all time required for sequencing and preparation was avoided entirely by using data made available from other research projects.\r\nData analysis\r\nThe approaches we have used to analyze our data are not designed for large datasets of variable sites, although our results suggest that with the exception of short deep internodes the recovery of the phylogeny is quite good. Ideal methods would accommodate differences among gene trees to correctly estimate the species tree and model the substitution process to accurately infer substitutions. However, current methods to analyze genome-wide variable sites are limited [25]. It is important to note that these methods are in development; as we begin to use whole-genome data it is obvious that subsets of data must be used and the optimal data are likely not linked regions, but individual sites [11]. Furthermore, the availability of tools designed for limited datasets should not prevent us from developing methods to identify more comprehensive datasets.\r\nFuture directions\r\nFuture versions of SISRS will accommodate larger genomes and output more variable sites more rapidly as a result of improved assembly of the composite genome and improved genotype calling. We will also evaluate the application of SISRS output to deep-time phylogenetics and estimation of branch lengths/divergence times among taxa.\r\n\r\nConclusions\r\nThe approach introduced here has the potential to transform phylogenetic research. SISRS eliminates the need for expensive marker development in many studies by using whole genome shotgun sequence data directly. As technology improves, whole-genome sequencing will soon be affordable even for large-scale projects. By using shotgun sequence data, error in next-generation sequence data and co-alignment of paralogous genes does not affect subsequent analyses.\r\nSISRS also promotes the reuse of data. Shotgun genomic sequences available in public databases can be used directly for phylogenetic analyses, as we have done in this study. Sequencing performed with the goal of identifying phylogenetic data using SISRS can be made available for subsequent use in other studies, including phylogenetics at any taxonomic level, or any other study utilizing genomic data. Reusing available next-generation sequencing reads can substantially reduce costs.", user_id: 1, journal_id: 13, field_id: 4, institution_id: 19});

paper22 = Paper.create!({title: "Metal-centered polyoxometalates encapsulated by surfactant resulting in the thermotropic liquid crystal materials", body: "Abstract\r\nWaugh- and Silverton-type polyoxometalates (POMs) K3(NH4)3[MnMo9O32] and H8[CeMo12O42] are enwrapped by dioctadecyldimethylammonium (DODA+) forming the surfactant-encapsulated POMs (SEPs) (DODA)6[MnMo9O32]·16H2O (DODA-MnMo9) and (DODA)8[CeMo12O42]·9H2O (DODA-CeMo12), which exhibit typical thermotropic liquid-crystalline properties. Here, the Waugh- and Silverton-type polyoxoanions centered by metal cation were firstly introduced into liquid crystal materials. The chemical composition of these SEP complexes was determined by IR spectra, elemental analysis and TG analysis. Also, the polarized optical microscopy, differential scanning calorimetry (DSC), variable temperature X-ray diffraction (VT-XRD) and transmission electron microscopes (TEM) were performed to characterize their liquid-crystalline behavior.\r\n\r\nKeywords\r\nPolyoxometalate; Surfactant; Thermotropic liquid crystal; Lamellae structure; Smectic phase\r\nPOMs, as a unique class of nanosized metal oxide clusters with abundant topologies and oxygen-rich surface, have exhibited remarkable properties in the field of catalysis, medicine and optics, etc. [1], [2], [3], [4], [5] and [6]. Despite the unparalleled success in POM synthetic chemistry [7], [8], [9], [10], [11] and [12], the application of POMs in various functional architectures, devices and materials still requires a progressive step for constructing POM-based functional systems. To modify the weak compatibility between POMs and organic solvents, several issues, such as the low mass transfer and high lattice energy as well as improving the surface of POMs, need to be solved. Recently, POM-based functional materials were efficiently prepared by the exchange of counterions with cationic surfactants, which was regarded as an effective and highly economic procedure for constructing the POM-based functional materials. In these POM-based functional materials, the solubility of POMs in regular organic solvents and the structural stability in diverse chemical environments are effectively improved. Furthermore, the obtained SEPs exhibit enhanced catalytic efficiencies with easy and fast catalyst recovery from the reaction system. In addition, it is possible to predict and control, to some extent, the structure and functionality of the hybrid materials by selecting the surfactants and POMs with different physical–chemical properties. In recent years, the smart self-assembly of surfactants and POMs has resulted in remarkable nanostructured organic–inorganic hybrid materials that exhibit attractive prospects in the field of catalysis, Langmuir–Blodgett films and dynamic transformations under control of external stimulus. Up to date, various morphology self-assemblies and liquid crystals have been achieved in the POMs/surfactant system [13], [14], [15], [16], [17], [18], [19], [20] and [21]. Among them, liquid crystals constructed from cationic surfactant and POMs have attracted much attention. The liquid crystal materials synthesized in this way has overcome the complex multiple-step synthetic process of the traditional organic liquid crystals. Wu and Dietz succeeded in introducing the POMs into ammonium or phosphonium derivatives by the ionic self-assembling route resulting in several SEPs with characteristic thermotropic liquid-crystalline behavior [22], [23], [24], [25] and [26]. The giant Mo clusters [Mo132O372(H2O)72(CH3COO)30]42 − enwrapped by cationic surfactants display ionic liquid-crystalline properties [27]. By reasonable modulation of the surfactant, Faul and coworkers [28] described the liquid-crystalline behaviors built from [EuPW5W30O110]12 − and [Eu(SiW9Mo2O39)2]13 −. Liu et al. [29] demonstrated that Keggin-type polyoxoanions enwrapped by tetra-n-octylammonium counterions through ionic self-assembly exhibited thermotropic liquid-crystalline behavior. Obviously, part of the thermotropic liquid crystals were obtained by using the mesomorphic cationic surfactant to encapsulate POMs. However, this method cannot be widely adopted because of its complex multiple-step synthetic process. Besides, these liquid-crystalline materials are mostly constructed from Keggin-type and sandwich-type POMs. Herein, the Waugh- and Silverton-type POMs K3(NH4)3[MnMo9O32] and H8[CeMo12O42], centered by the MnO6 octahedron and CeO12 icosahedron, respectively, were firstly introduced into the POM/surfactant system to construct thermotropic liquid-crystalline materials (DODA)6[MnMo9O32] (DODA-MnMo9) and (DODA)8[CeMo12O42] (DODA-CeMo12) [30], [31] and [32]. Further, the Cis-terminal oxygen atoms of MoO6 octahedra were observed in both K3(NH4)3[MnMo9O32] and H8[CeMo12O42], which are rarely observed in the typical Keggin and Wells–Dawson POMs and their derivatives. These studies are of significance because they will offer opportunities for introducing new POMs into the SEPs system for constructing functional liquid crystal materials ( Fig. 1).\r\nDODA-MnMo9 and DODA-CeMo12 were synthesized by a straightforward ion exchange reaction, respectively. The phase transitions of DODA-MnMo9 were determined by DSC during its first cooling and second heating cycles. As shown in Fig. 2a, DODA-MnMo9 displays three phase transitions at 31 °C, 49 °C and 148 °C during its second heating. We notice a halo with a peak at 65 °C, but the present evidence cannot further indentify the transition exactly. Upon cooling, three transitions were observed at 126 °C, 43 °C and 24 °C, respectively. The peak at 31 °C during the second heating process should be assigned to the transition between two kinds of solids, and the VT-XRD results could further confirm the transition [22]. The peak that appeared at 49 °C can be attributed to the transition from solid state to mesophase; the broad peak at 148 °C corresponds to the transition between liquid crystal phase and isotropic phase. Fig. 2b displays two transitions of DODA-CeMo12 during its first cooling and second heating process. Upon its second heating run, DODA-CeMo12 displays an endothermic halo from 40 °C to 55 °C with the apex at 50 °C, which can be attributed to the transition between the solid state and the liquid crystal phase. With the increase of the temperature, the transition from liquid crystal phase to isotropic phase can be observed at 137 °C. When DODA-CeMo12 was cooled from its isotropic phase, the transition of isotropic phase to liquid crystal phase can be seen at 126 °C. On further cooling, the halo from 52 °C to 32 °C with the peak at 43 °C can be assigned to the transition between liquid crystal phase and solid state. The phase transition temperature, enthalpies and assignments of the transition between different states of DODA-MnMo9 and DODA-CeMo12 are summarized in Table 1. Polarizing optical microscopy was employed to identify the liquid crystal phases of DODA-MnMo9 and DODA-CeMo12. During the cooling process from isotropic phase, we observed clear liquid birefringence phenomenon of DODA-MnMo9 with fan-shaped textures at 95 °C (Fig. 3a). For DODA-CeMo12, the phenomenon of liquid birefringence is clearly observed at 90 °C during its cooling process with a grain texture, although the optical texture is not typical (Fig. 3b).\r\nTEM was employed to confirm the lamellae structures of DODA-MnMo9 and DODA-CeMo12 at room temperature. Fig. 4a shows the lamellar structure of DODA-MnMo9, and the spacing between two layers is approximately 4.2 ± 0.3 nm. For DODA-CeMo12 (Fig. 4b), the layer distance is estimated to 4.0 ± 0.3 nm. VT-XRD was employed to further demonstrate the liquid-crystalline behaviors of DODA-MnMo9 and DODA-CeMo12. From Fig. 5a, it can be concluded that DODA-MnMo9 in its solid state exhibits the layer structure at room temperature according to the three equidistant diffractions in the small-angle region, and the layer distance is 4.53 nm, which is in accordance with the layer distance estimated from TEM at room temperature. When the temperature increases to 40 °C, we can clearly see the equidistant diffractions in the small-angle region and several sharp peaks in the wide-angle region. This heating process leads to a solid–solid transition as the layer distance decreases to 3.67 nm. These results could further confirm the transition between two solids observed from the DSC. With the increase of temperature, the equidistant diffractions were clearly observed in the small-angle region as well as a broad halo in the wide-angle region centered at 2θ ≈ 20°, which indicated the formation of typical lamellar structure, and the distance between the two neighboring layers is 3.15 nm. Combining the fan-shaped textures, the phase can be identified as SmA phase. Fig. 5b shows the VT-XRD results of DODA-CeMo12 at 25 °C and 100 °C. The equidistant peaks in the low-angle region of the diffraction pattern illustrate the layered structure of DODA-CeMo12 both in its solid state and liquid crystal phase. The lamellar structure in its liquid crystal phase indicates the formation of a smectic X phase [23].\r\nThe calculated layer spacing for DODA-MnMo9 and DODA-CeMo12 is listed in Table 2. In fact, the diameter of anion [MnMo9]6 − is about 0.7 nm, the normal length of DODA+ is 2.25 nm, the ideal thickness of a single complex should be 5.2 nm. The measured layer distance of DODA-MnMo9 in its mesophase is shorter than the theoretical molecular length, indicating that the molecules in the mesophase are partly interdigitated or tilted [24] and [25]. For DODA-CeMo12, the layer distance (3.64 nm) calculated from the VT-XRD at 100 °C is not consistent with the theoretical layer 5.4 nm (the diameter of [CeMo12O42] is 0.9 nm), which also indicates the molecules in DODA-CeMo12 are interdigitated or titled in its liquid crystal phase. Possible packing structures of DODA-MnMo9 and DODA-CeMo12 are shown in Fig. 6a and b, respectively.\r\n\r\nIn summary, a simple surfactant DODA+ was used to encapsulate metal-centered POMs (Waugh- and Silverton-type POMs), resulting in two SEPs complexes. The Waugh- and Silverton-type POMs with metal cation as their heteroatoms were firstly introduced into the POMs/surfactant system, and the obtained SEP materials exhibited thermotropic liquid crystal behaviors. The results of polarized optical microscopy, VT-XRD and DSC reveal the smectic mesomorphic behaviors of DODA-MnMo9 and DODA-CeMo12 in a relatively wide temperature range. Compared with the thermotropic liquid crystal materials built from Keggin-type POMs and cationic surfactant [29], DODA-CeMo12 shows reversible phase transitions during their first heating and second heating cycles, and the smectic-type phase of Keggin-type POMs liquid crystal materials is more structurally ordered than the SmA phase of DODA-MnMo9. The research on thermotropic liquid-crystalline properties of these materials will provide access for constructing new POMs-based functional materials.", user_id: 1, journal_id: 14, field_id: 12, institution_id: 20});

paper23 = Paper.create!({title: "Assembly of a POM-based hybrid compound consisting of both helical and interdigitated motifs", body: "Abstract\r\nA new compound, {[Ag(DF)2]4SiW12O40} (1), (DF = 4,5-diazafluoren-9-one), has been hydrothermally synthesized, and characterized by elemental analyses, IR, TG and single crystal X-ray diffraction. A structural feature in 1 is that the adjacent [Ag(DF)2]2(SiW12) fragments are linked together by H-bonds to achieve left- and right- handed helical chains with the pitch ca. 26.3 Å. Furthermore, these helical chains are linked via H-bonds forming a poly-pendant layer, in which the [Ag(DF)2] moieties as pendants are appended to the two sides of the layer. Interestingly, adjacent layers mutually engage in an interdigitated pattern to result in a novel a 2D + 2D → 3D architecture. The electrochemical studies show that 1 has a good electrocatalytic activity toward reduction of hydrogen peroxide molecules.\r\n\r\nKeywords\r\nPolyoxometalates; Helix; Interdigitation; Electrochemical properties\r\nHelical structures such as protein bundles and DNA are prevalent in biological systems and represent a topic of intense interest in coordination and materials chemistry. Many chemists have put great efforts on the rational design and synthesis of artificial helical compounds [1], [2], [3] and [4], which show significance in multidisciplinary areas such as biology, optical devices, and asymmetric catalysis [5], [6] and [7]. An effective strategy to construct helical compounds is the assembly of metal ions and organic ligands containing O- or N-donor atoms [8]. Recently, a promising route for constructing helical compounds has emerged by introducing polyoxometalates (POMs) into the reaction systems of metal ions and organic ligands [9] and [10]. The POMs, as a large family of metal–oxygen clusters, have become attractive inorganic building blocks due to their large numbers of structural diversity and various applications in different areas, including catalysis [11], [12], [13], [14] and [15], medicine [16] and [17], and materials science [18], [19], [20], [21], [22], [23] and [24]. Thus, the helical compounds based on POMs, which can combine the features of helixes and POMs to possess more broadening applications, have attracted much attention of chemists. And many of artificial helical compounds have been obtained [25], [26], [27] and [28]. The POMs in such compounds mainly show three kinds of roles: templates enraptured in the helical network [25], connectors of the helical chains [26], as well as pendants attached on the helical chains [28].\r\nOn the other hand, interdigitated compounds are held together by gear-like (or tongue-and-groove) pattern rather than by covalent bonds [29] and [30], and the interdigitated compounds are more flexible than the usual networks entirely based on coordination bonds, due to their unique mechanically interlocked structures [31], [32], [33] and [34]. Apart from their intrinsic esthetic appeal, the interdigitated compounds have potential applications in ranging from guest sorption [35], self-replication [36] to fiber behavior [37]. From the structural point of view, POM-based compounds consisting of both helical and interdigitated motifs are very interesting, since there exists a correlation between structural complexity and multi-functionality in coordination compounds. However, to date, the POM-based compounds possessing both helical and interdigitated motifs in one compound have not been reported.\r\nIn the present communication, we report the synthesis and structure of a new POMs-based compound with both helical and interdigitated motifs, {[Ag(DF)2]4SiW12O40} (1), (DF = 4,5-diazafluoren-9-one). Also, electrochemical studies show that 1 has a good electrocatalytic activity toward reduction of hydrogen peroxide (H2O2) molecules.\r\nCompound 1 was synthesized under hydrothermal conditions [38]. Single-crystal X-ray diffraction analysis [39] reveals that 1 consists of two [Ag(DF)2]+ moieties and a [SiW12O40]4 −(SiW12) cluster in an asymmetric unit (Fig. 1). The silver atoms in the two [Ag(DF)2]+ moieties are with different coordination modes: Ag1 is five-coordination in rectangular pyramidal coordination geometry achieved by one bridging oxygen atom from the SiW12 cluster and four nitrogen atoms from two DF ligands; Ag2 are coordinated by four nitrogen atoms in a square plane coordination geometry. The bond distances and angles around the Ag atoms are in 2.887(9) Å for Agsingle bondO and 2.168(6)–2.841(7) Å for Agsingle bondN, and Nsingle bondAgsingle bondN angles are in 74.61(18)–178.2(2)°. The Ag1 connects two DF molecules forming a hinge motif (Fig. 2 left) while Ag2 connects two DF molecules achieving a plane motif (Fig. 2 middle). The SiW12 cluster shows the well-known α-Keggin type structure, consisting of central SiO4 tetrahedron corner-sharing four triad {W3O13} clusters.\r\nOne structural feature for 1 is its helical chains (Fig. 3), which can be described in detail as follows: Firstly, each of the SiW12 cluster links two hinge [Ag1(DF)2] moieties via its bridging oxygen atoms to form a [Ag1(DF)2]2(SiW12) fragment (Fig. 2 right). The adjacent [Ag1(DF)2]2(SiW12) fragments are linked together by H-bonds to achieving left- or right-handed helical chains along the c axis ( Fig. 3). The pitch of the left- and right-handed helical chains is ca. 26.3 Å. Furthermore, these right-handed helical chains are linked via H-bonds forming a novel chiral layer ( Fig. 4a). Nevertheless, there also exists a similar chiral layer constructed by left-handed helical chains. As a result, the whole architecture of 1 does not possess chiral.\r\nAs shown in the Fig. 4b, the chiral layer is also a poly-pendant layer view along the c axis, in which the [Ag1(DF)2] moieties as pendants are appended to the two sides of the layer. There are many gaps between the [Ag1(DF)2] pendants. As is known, such large structural gaps are often occupied by solvent molecules or guest molecules to achieve the structural stabilization. Otherwise, the interdigitation phenomena may occur, that is, the gaps associated with one structure motif are occupied by one or more independent structure motifs to fill the spaces. Interestingly, in the structure of 1, these gaps of one layer are interdigitated by the protrudent [Ag1(DF)2] pendants from the adjacent layers to form a 2D + 2D → 3D architecture ( Fig. 4c). There exist π⋯π interactions ( Fig. 4c, the centroid–centroid distances ca. 3.285 Å) and multiple hydrogen bondings ( Table 1) in their extended structures, which further stabilizes the 3D interdigitated architecture.\r\nTo examine the thermal stabilities of 1, the thermogravimetric analysis was carried out from 25 to 600 °C at a heating rate of 10 °C⋅min− 1 in air atmosphere (Fig. S1). The TGA curve of 1 shows one-step of weight loss below 550 °C corresponding to the gradual loss of 8 DF molecules (found: 30.3%; calcd: 29.2%). The result of DTA shows three immediately subsequent steps. The first big exothermic peak at ca. 400 °C is attributable to the decomposition of the DF molecules. The additional two small exothermic peaks at ca. 450 °C and 500 °C in the DTA curve may be attributable to the decomposition of the SiW12 cluster [40]. Both TGA and DTA analyses support the chemical composition of 1 and also show that 1 possesses a high stability under 350 °C.\r\nAs shown in Fig. S2, the IR spectrum exhibits the characteristic peaks of α-Keggin structure at 965, 912, 883 and 788 cm− 1 which are attributed to ν(Sisingle bondOc), ν(Wdouble bond; length as m-dashOt), νas(Wsingle bondObsingle bondW) and νas(Wsingle bondOcsingle bondW) [41] and [42], respectively. In addition, bands in the 1100–1740 cm− 1 region can be assigned to characteristic peaks of the DF molecules.\r\nThe electrochemical behavior of 1-modified carbon paste electrode (1-CPE) and its electrocatalytic reduction of hydrogen peroxide were investigated. The cyclic voltammetric behavior for 1-CPE in 1 M H2SO4 aqueous solution was recorded (see Fig. 5) in the range of + 0.8 to − 1.0 V. There are two pairs of reversible redox peaks (II–II′ and III–III′) attributed to the redox process of tungstate atoms in SiW12 clusters of 1[43], and one irreversible anodic peak (I) assigned to one-electron oxidation processes of silver atoms [44]. The 1-CPE displays good electrocatalytic activity to reduction of hydrogen peroxide. As shown in Fig. 5, with addition of hydrogen peroxide, the II and III cathodic peak currents, especially the III, increased gradually, while the corresponding anodic peak currents decreased. The nearly equal current steps for each addition of hydrogen peroxide demonstrate stable and efficient electrocatalytic activity of 1-CPE. The electrocatalytic efficiency of 1-CPE (based on a rough calculation using CAT formula) [45] toward the reduction of hydrogen peroxide was ca. 110% at 1 M H2SO4 containing 10 mM hydrogen peroxide, which suggests that 1 has potential applications in detection of hydrogen peroxide.\r\n\r\nIn conclusion, a novel supermolecular architecture has been synthesized under hydrothermally condition, utilizing of SiW12 clusters, DF ligands and silver cations as building blocks. This work, besides presenting the first example of POM-based structure consisting of both helical and interdigitated motifs, may generate a new kind of materials that combines the useful properties of helix, interdigitattion and POM. More work in this field is underway in our laboratory.", user_id: 1, journal_id: 14, field_id: 12, institution_id: 21});

paper24 = Paper.create!({title: "Chirality delivery through multiple and helical H-bonding from chiral coordination complex to its supramolecular architecture", body: "Abstract\r\nThe path of the chirality delivery in the crystalline and chiral nucleotide–Co(II) complex, [Co(GMP)(H2O)5]·3H2O (GMP = guanosine-5′-monophosphate), has been studied based on X-ray single crystal diffraction analysis, liquid- and solid-state circular dichroism (CD) spectroscopy. The multiple and helical H-bonding is a distinctive way of chirality delivery from the discrete molecules to three-dimensional supramolecular architecture.\r\n\r\nKeywords\r\nChirality delivery; Circular dichroism; Nucleotide complex; Supramolecular architecture\r\nThe chirality delivery is a growing topic of interest in light of its importance in biology and advanced materials [1]. To understand the way and mechanism of chirality delivery is important for controllable synthesis of chiral material and understanding the functions of biological system, which is still a challenge to chemists. At present, self-assembly is a distinctive method to construct chiral materials from chiral or achiral constituents [2] and [3]. Noncovalent interactions such as H-bonding, aromatic stacking, electrostatic, etc. are vital in the self-assembly process and in determining the final geometry of the resulting metallosupramolecular structures [3] and [4]. As we know, nucleotide is a kind of optically active and fundamental biomolecules and can be chiral ligands for transition metal [5] and [6]. Although there are a few of nucleotide coordination complexes reported [7] and [8], the coordination chemistry and supramolecular chemistry of nucleotide–metal systems are still in infant. We have studied the chirality delivery in the nucleotide–Cu(II) complex, [CuNa(GMP)(HGMP)(H2O)7]·6(H2O)·CH3OH (GMP = guanosine 5′-mono phosphate) [7a]. The chirality delivery through non-covalent interactions has been studied based on the viewpoint of supramolecular chemistry [9]. The result indicates the diversity of supramolecular chirality.\r\nHerein, an alternative and unusual path of the chirality delivery in GMP–Co(II) complex, different from the path in the GMP–Cu(II) complex, has been investigated based on X-ray single crystal diffraction, liquid- and solid-state circular dichroism (CD) spectroscopy. The multiple and helical H-bonding along 2D layer is a distinctive way of chirality delivery in this work.\r\nThe space group of the crystal structure of complex 1 is C2, which indicates that the crystal is homochiral. The molecular structure of complex 1 is built up of a Co(II) ion coordinated with one GMP ligand and five coordinated water molecules (Fig. 1, Tables S1 and S2). The chirality of GMP ligand was remained in the molecule of 1 and induced molecular chirality based on the distorted octahedral geometry of the Co(II) center. Different to nucleotide-ratio in complex 1 is 1:1, which makes the large freedom of GMP ligand especially for phosphate group. It leads to the diversity of H-bonding pattern and helical pattern in molecular packing in crystal lattice in the viewpoint of supramolecular chemistry. The molecules are linked by a strong H-bonding, O11―H11A…O5 (1.845 Å, 2.657 Å, 166.64°) and O9―H9A…O6 (1.945 Å, 2.755 Å, 168.27°) (Fig. 2(a)) to form a 1D right-handed helical chain along b axis. The molecule is twisted nearly by 180° and the screw pitch is 11.072(4) Å. The twist is mainly origin from the flexibility of sugar moiety and phosphate group and π–π packing between adjacent helical chains, which induces rotation angle to be nearly 180° and is different from the previous report [7a]. Then, these 1D helix chains are assembly by H-bonding at the presence of solvent water molecules (O13, O14) to construct the 3D chiral supramolecular architectures. One kind of the assembly mode is the neighbor helical chains linked by strong and right-handed helical H-bonding along b axis [O8―H80…O14 (1.741 Å, 2.550 Å, 176.33°), O14―H14B…O4 (1.969 Å, 2.782 Å, 168.51°), O9―H9B…O4 (2.173 Å, 2.173 Å, 168.27°)] ( Fig. 2(b)). Interestingly, this H-bonding mode is the same with that within the 1D chain, which is twisted nearly by 180° and the screw pitch is 11.072(4) Å. That is to say, the 1D chain consisted of the half of the blue chain and the half of the green chain is the same with homocolor chain, blue or green one. Clearly, the molecules are linked each other by the right-handed helical H-bonding to extend the 2D layer structure. To the best of our knowledge, this is the first report about chirality delivery through 2D continuous helical H-bonding. Further, these 2D sheets are packed based on π–π stacking (3.3304 Å) between on the ab plane combining with H-bonding [O14―H14A…O15 (1.890 Å, 2.691 Å, 164.53°); O14―H14B…O4 (1.969 Å, 2.782 Å, 168.51°)] ( Fig. 2(c)). The 3D topology of complex 1 with each complex as one node and intermolecular interactions as linker is (4,6) network ( Fig. 2(d)), which displays the relationship of complex molecules packing in the crystal lattice clearly.\r\nBoth of the chirality of the ligand and complex 1 have been confirmed by liquid circular dichroism (CD) studies (Fig. 3(a)). The CD spectrum of the GMP ligands in aqueous solution has a strong negative band at 196 nm which relates to the conformation of the sugar moiety. Positive bands centered at 219 nm, of which the transition is n → π* [10]. Most of the CD active transitions are n → π* in nature [11], although the π → π* transitions dominate UV–vis spectrum (Fig. S1). As observed for purine nucleotides, α-anomers have positive and β-anomers have negative 260 nm bands [5]. The absence of this band in the spectrum of GMP might be caused by the balance between α- and β-anomers through mutarotation in water solution [10]. The typical CD spectrum illustrates that the GMP ligands are the d-ribonucleotide which has a positive band near 220 nm and was found to be the mirror image of the l-ribo [5]. Compared to the ligand, the positive cotton effect (CE) of complex 1 becomes weaker and narrower, which can be explained by the fact that the coordination of Co(II) to the nucleobase reduces the n → π* transition of the chromophore [12] and the number of G4 is decreased [3]. Weak negative bands centered at 250, 253 and 269 nm appear, which are composed of two π → π* transition and one n → π* transition, respectively [5]. This negative CE demonstrates that the chiral of GMP delivers to GMP–Co(II) compounds and GMP mainly keeps the β-anomers in the complex.\r\nTo deliberate the chirality of the supramolecular architecture, solid state circular dichroism spectra were measured in a KCl matrix for GMP ligand and the single-crystals of complex 1 (Fig. 3(b)). There is a red-shift in the solid state CD spectrum of GMP compared with its liquid CD spectrum. The negative band about the conformation of the sugar moiety has nearly disappeared. In solid-state, mutarotation is more difficult and the negative band at the 260 nm nearby can be detected which indicates that the GMP ligand is mainly β-anomers. In the spectrum of complex 1, the weak negative band at 215–225 nm indicates that the GMP exists as l-ribo [5], which is induced by the strong π–π and hydrogen bonding interaction. For solid samples, CD spectroscopy is highly sensitive to even a very small distortion from planarity of the aromatic chromophore [12]. The strong negative CE centered at 297 nm (θ ≈ − 10 mdeg) is due to the excitation coupling of π → π* transitions of the aromatic chromophores, including the intra- and intermolecular coupling of the guanine chromophores [13], which is consistent with the single crystal structure.\r\nIn this work, the experiment results confirmed that the chirality of GMP can be preserved when coordinated to Co(II) center and the chirality of this nucleotide complex molecule can be delivered to its supramolecule architecture by hydrogen bonding and π–π interaction. Liquid- and solid-state circular dichroism spectroscopy has been carried out and offers an effective ways for chirality delivery. To the best of our knowledge, it offers a new path of chirality delivery from nucleotide–metal complex molecules to its supramolecular architectures, which is significant for understanding the origin of life. In future, preparing suitable nucleotide–metal complexes for single-crystal X-ray studies and the research about the supramolecular chemistry and chirality of them remains an important assignment for us.", user_id: 1, journal_id: 14, field_id: 12, institution_id: 22});

paper25 = Paper.create!({title: "Pretend model of traveling wave solution of two-dimensional K-dV equation", body: "Abstract\r\nTraveling wave resolution of Korteweg-de Vries (K-dV) solitary and numerical estimation of analytic solutions have been studied in this paper for imaginary concept. Pretend model of traveling wave deals with giant waves or series of waves created by an undersea earthquake, volcanic eruption or landslide. The concept of traveling wave is frequently used by mariners and in coastal, ocean and naval engineering. We have found some exact traveling wave solutions with relevant physical parameters using new auxiliary equation method introduced by Pang et al. (Appl. Math. Mech-Engl. Ed 31(7):929–936, 2010). We have solved the imaginary part of exact traveling wave equations analytically, and numerical results of time-dependent wave solutions have been presented graphically. This procedure has a potential to be used in more complex system for other types of K-dV equations.\r\n\r\nIntroduction\r\nTraveling wave is a wave in which the medium moves in the direction of propagation of the wave. In this wave, energy is transported from one part of a medium to another. The traveling wave carries energy away from its source. It is the wave that is not bounded by a given space but can propagate freely. In case of this wave, the vibration is in the direction of propagation. Karim et al. studied numerical estimation of traveling wave solution of two-dimensional K-dV equation using a new auxiliary equation method [1]. They studied the numerical estimation of traveling wave solution of K-dV equations for real cases. A tsunami is a giant wave (or series of waves) created by an undersea earthquake, volcanic eruption or landslide. Tsunami waves are totally uncertain. These are not like a normal sea waves. Tsunamis are often called tidal waves, but this is not an accurate description because tides have little effect on giant tsunami waves. In this research, we defined this sorts of giant waves are the traveling wave of imaginary concept. Herman's numerical experiment shows that their method has high accuracy. A model of an incompressible flow through a cylindrical metal pipe and the fundamental physical and mathematical facts presented in [2] are used to show how a solitary velocity wave (solution) can arise in this system; Rukavishnikov and Tkachenko are studied [3]. Although the resulting asymptotic expression in the radial co-ordinate differs considerably from the classical expansion in depth for shallow-water waves, they are able to derive the K-dV equation. They also show how to proceed back from the K-dV equation to the velocity function and present the numerical results obtained for a model problem. Smaoui and Al-Jamal studied the boundary control problem of the generalized Korteweg-de Vries Burger (GKdVB) equation on the interval [0, 1], [4]. They presented numerical results supporting the analytical ones for both the controlled and uncontrolled equations using a finite element method. Pang et al. studied the method of finding the traveling wave solution to K-dV equation using a new auxiliary equation method [5]. They got a set of traveling wave solution for a specific third-order K-dV equation. Zaiko studied the presence of a singularity results in that the velocity of long wave perturbations in the system becomes imaginary, which corresponds to the wave propagation in the range of nontransparency [6]. Stefano et al. studied that their work is to start up a thorough investigation of earthquake-related tsunamis in the Mediterranean area and a systematic assessment of the associated hazards [7]. They begin by focusing on the expected tsunami impact on the coasts of Southern Italy. Although other source types, such as large submarine landslides [8] or volcanic activity [9,10], have been invoked to explain large historical and pre-historical tsunamis in the Mediterranean, they focused on strictly earthquake-generated tsunamis because their impact can be systematically addressed based on existing knowledge.\r\nIn this research, two-dimensional third-order K-dV equations have been studied. Using a new auxiliary equation method, we got the 15 sets of travelling wave solution of K-dV equation. There are three cases to be arises, two of them are real sense and the other is imaginary concept. In our study, we solve the imaginary part of exact traveling wave equations analytically, and numerical results of time-dependent wave solutions have been presented graphically.\r\n\r\nMethod of solution\r\nThe remarkable form of Korteweg-de Vries nonlinear partial differentiable equation [11] was first introduced by Dutch mathematics Diederik Korteweg and Gustav de Vries in 1895, to describe long water waves in a channel of depth h0, where σ=16c0h02 is a constant for fairly long waves, c0=(gh0)12, u is displacement of wave and g is the acceleration due to gravity. In this section, we introduce the method of finding the analytic wave solution to nonlinear evolution equation due to Pang et al. [5]. First, a given nonlinear partial differential equation has the form.\r\n\r\np(u,ut,ux,utt,uxx,…....)=0\t(1)\r\nThis method mainly consists of four steps:\r\n\r\nStep1: Take the complex solutions of (1) in the form\r\n\r\nu(x,t)=u(ξ),ξ=x−vt,\t(2)\r\nwhere v is a real constant. Under the transformation (2), (1) becomes an ordinary differential equation\r\n\r\nQ(u,u′,u′′,……)=0.\t(3)\r\nStep2: Take the solutions of (3) in the more general form:\r\n\r\nu(ξ)=a0+∑i=1mai(G(ξ)G′(ξ))i+bi(G(ξ)G′(ξ))−i\t(4)\r\nwhere am and bm are not zero at the same time, and a0, ai and bi (i = 1, 2, 3,….. ….m) are constants to be determined later. The integer m in (4) can be determined by balancing the highest order nonlinear terms and the highest order linear terms of u(ξ) in (3). G = G(ξ) satisfies the second-order linear ordinary differential equation\r\n\r\nG′′+λG′+μG=0,\t(5)\r\nwhere λ and μ are constants for the general solution of (5) are as follows:\r\n\r\nWhen λ2−4μ>0,G(ξ)=c1exp(−λ+λ2−4μ√2ξ)+c1exp(−λ−λ2−4μ√2ξ);\r\n\r\nWhen λ2−4μ=0,G(ξ)=(c1+c2ξ)exp(−λ2ξ);\r\n\r\nWhen λ2−4μ<0,G(ξ)=exp(−λ2ξ)(c1cos4μ−λ2√2ξ+c2sin4μ−λ2√2ξ)\r\n\r\nNote: Let ai = 0, i = 1, 2, ….. …. ….m. Equation (4) changes to\r\n\r\nu(ξ)=a0+∑i=1mbi(G(ξ)G′(ξ))−i.\t(6)\r\nThe form of (6) has been used in study of Pang et al. If we set bi = 0(i = 1, 2 ……m), (4) changes to\r\n\r\nu(ξ)=a0+∑i=1mai(G(ξ)G′(ξ))i.\t(7)\r\nStep3: Substitute (4) into (3) and collect all terms with the same order of GG′ together. The left-hand side of (3) is converted into a polynomial in GG′. Then, let each coefficient of this polynomial to be zero to derive a set of over-determined partial differential equations for a0, ai, bi (i = 1, 2, …   …  , m), λ, μ, and v.\r\n\r\nStep4: Solve the algebraic equations obtained in Step3 with the aid of a computer algebra system (such as Mathematica or Maple) to determine these constants. Moreover, the solutions of (5) are well known. Then, substituting a0, ai, bi (i = 1, 2, …   …  , m),  v and the solutions of (5) into (4), we can obtain the exact analytical/traveling wave solutions of (1).\r\n\r\nResults and discussion\r\nIt can be seen that the potential has the form of the bore (according to the terminology of [12]), which is a standard function of the nonlinear wave theory. The u wave function is determined by Equation (12) by computing the governing Equation (8). Figure 2a shows that the wave moves right direction along t as x increases. At x = 10.0, waves fall down, and for x = 15.0, waves fall down sharply and the other cases as well. But in every wave, it maintains at a surface level which depict a general phenomena of a long water waves. The wave moves right direction along x as t increases in Figure 2b. At a time t = 0.1, waves fall sharply, and then, it maintains a steady-state level. In other cases, wave behaviors are the same. Figure 3 depicts the u wave contour against t and x. For a particular wave, it is seen that the amplitude of the wave is minimum at the mid-point of that wave. In two-dimensional case, u wave contour is always the same at the mid-point at time t = 0.2 and a position x = 5.0 is -441.33, which is minimum. The negative sign indicates that the wave falls down below the surface level. For the imaginary case, we chose the parameters as λ = 2.0,μ = 5.0 and c = 10.0 such that λ2 - 4μ < 0 (Table 1).\r\nFor the cases below, the numerical estimations are based on the Equation (13). Figure 4a depicts the time evolution of the solution u(x, t), with λ = 2.0, μ = 5.0 and c = 10.0 so that λ2 - 4μ < 0 for the values x = 5.0, x = 10.0, x = 15.0, x = 20.5 and x = 25.0. In case of x = 5.0, waves fall down at t = 0.1 and goes up immediately. Wave decreases as increasing values of t to a certain level like t = 0.5, and after that, it increases for that particular case against t. Numerical representation of u wave against x for the different values of t like t = 0.1, t = 0.5, t = 0.9, t = 1.3 and t = 1.7 is shown in Figure 4b. It gives the shape of wave which is exact traveling wave solution of the problem (8). For increasing values of t, wave moves to the left but every wave maintaining same level against x which shows the Figure 4b. Here, we see that the numerical result is stable and reliable, and it keeps almost the same shape as exact solution. For a specific wave, it is seen that the amplitude is maximum at the mid-point of that wave. Figure 5 represents the numerical estimation of u wave contour against x and t simultaneously.\r\nFigures 6a,b and 7 show the traveling wave solution of K-dV equation (14). Figure 6a represents the time evolution of u wave against t for different values of x. Waves fall down at t = 0.1, which close to the surface level just after the given values of t for x = 5.0. Wave decreases as increasing values of t to a certain level like t = 0.5, and after that, it increases against t. For increasing values of t, wave moves to the right but every wave maintaining same surface level against x which is shown in Figure 6b. But Figure 7 depicts the u wave contour against t and x. For the graphical representation of the equation, we consider the parameters λ = 2.0, μ = 5.0 and c = 10.0 so that λ2 - 4μ < 0 but c does not depend on λ and μ. It is found that the wave which is periodic for x = 5.0, x = 10.0, x = 15.0, x = 20.0 and x = 25.0 against t, oscillates regularly. Here, the time t is defined over the interval [0, 1.2]. At the centre of the contour the amplitude of the wave is minimum, and it increases gradually around the centre.\r\nNow we consider the numerical estimation of (16) for an imaginary case where the parameters λ = 2.0, μ = 5.0 and c = 10.0 such that λ2 - 4μ < 0. Figure 10a shows the numerical representation of u wave against t for different values of x = 5.0, x = 10.0, x = 15.0, x = 20.0 and x = 25.0. We have seen that wave increases against t to a certain time t = 0.3, and later, it gradually decreases. While in every case, wave maintains the surface level. In tsunami, it could be really impossible which indicate that this is a pretend model of K-dV equation. Here, we see that u wave is solitary, and it is very much regular that we expect in analytical sense. As t increases, wave moves to the right but every wave maintains same surface level against x which is shown in Figure 10b. Figure 11 shows that the u wave contour against x and t. In two-dimensional case, u wave contour is always same at the mid-point for a particular value of t = 1.0 and x = 3.0 is -629.68. Other cases have the same analysis. In tsunami, the wave moves over large amount of obstacle with huge energy. Thus, in tsunami, it is quite difficult to predict what happens in the waves.\r\n\r\nConclusion\r\nIn this research, numerical estimation of traveling wave solution of two-dimensional K-dV equation using a new auxiliary equation method has been studied. The K-dV equation for the present problem comes from the third-order two-dimensional governing equation (*) after some suitable transformation. It is found that there are five exact traveling wave solutions (12 to 16) of K-dV equation exist for pretend model depends on different values related physical parameters. Numerical results of five analytical solutions for imaginary case obtained by using FORTRAN program have been shown graphically and discussed accordingly. While employing the Fortran-Scheme for the numerical estimation of K-dV equations, we presented those graphically when λ2 - 4μ < 0. Note that the real life examples of imaginary concept may be seen in Tsunami waves. Further study is needed to use its potentiality for more complex types of K-dV equations.", user_id: 1, journal_id: 15, field_id: 16, institution_id: 23});

paper26 = Paper.create!({title: "String cloud and domain walls with quark matter in kink cosmological model", body: "Abstract\r\nWe have studied quark matter coupled with string cloud and domain walls in the context of general relativity. For this purpose, we solved Einstein’s field equations for quark matter coupled to the string cloud and domain walls in spherical symmetric kink space-time. It is found that cosmic strings and domain walls do not survive in this space-time. Hence, the space-time in both the cases reduces to Minkowskian and the space-time is flat.\r\n\r\nKeywords: Quark matter; Domain walls; String cloud; Kink space-time; 04.20Cv\r\nBackground\r\nIt is still a challenging problem to know the exact physical situation at very early stages of the formation of our universe. At the very early stages of evolution of universe, it is generally assumed that during the phase transition (as the universe passes through its critical temperature) the symmetry of the universe is broken spontaneously. The topological stable defects [1] which occur during the phase transition are identified as strings. The other topological defects are monopoles and domain walls. Spontaneous symmetry breaking is an old idea, described within the particle physics in terms of the Higgs field mechanism. The symmetry is called spontaneously broken if the ground state is not invariant under the full symmetry of the Lagrangian density. Thus, the vacuum expectation value of the Higgs field is non-zero. In quantum field theories, broken symmetries are restored at high temperatures.\r\n\r\nA star which is smaller than neutron stars, the possibility of a quark star or a compact star, which is supported by degenerate pressure of quark matter, has been pointed out. Such a quark star has been investigated by many authors [1-4]. In their view, it is commonly assumed that, such quark stars contain quark matter in the core region and are surrounded by harmonic matter, although they are in the branch of neutron stars [5]. One of the interesting consequence of the first-order phase transition from quark phase to hadron phase in the early universe is the formation of strange quark matter and it has been attracting much interest [6,7]. It is plausible to attach strange quark matter to the string cosmology. Because string is free to vibrate and different vibration modes of the string represent the different particle types. The different modes are observed as different masses or spins. Satchel [8] and Letelier [9] initiated the relativistic treatment of strings. The gravitational effects of cosmic strings have been extensively discussed by Vilenkin [10], Gott [11] in general relativity. Krori et al. [12], Chatterjee and Bhui [13], Tikekar and Patel [14], and Bhattacharjee and Baruah [15] obtained relativistic string models of Bianchi space time.\r\n\r\nIn the present paper, we have attached strange quark matter to the string cloud, since one of such transition during the phase transition of the universe could be the quark-glucon plasma (QGP) harden gas when cosmic temperature was T ≈ 200 MeV. Itoh [4], Bodmar [16], and Witten [6] proposed two ways of formation of strange quark matter: the quark-hadron phase transition in the early universe and conversion of neutron stars into strange ones at ultrahigh densities. Alcock et al. [17] and Haensel et al. [18] examined that some neutron stars could actually be strange stars built entirely of strange matters if the hypothesis of the quark matter is true. Cheng et al. [19] have studied strange star properties, while Yavuz et al. [20] studied strange quark matter attached to the string cloud in spherical symmetric space-time admitting conformal motion.\r\n\r\nTypically, quark matter is modeled with the equation of state (EOS) which is based on the phenomenological bag model of quark matter. In the framework of this model, quarks are thought as degenerate Fermi gas which exists only in the region of space endowed with vacuum energy density BC. Also in the framework of this model, the quark matter is composed of massless u, d quarks and massive s quarks and electrons. In the simplified bag model, it is assumed that when quarks are massless and non-interacting, we then have quark pressure\r\n\r\npq=ρq3,\t(1)\r\nwhere ρq is the quark energy density.\r\n\r\nThe total energy density is\r\n\r\nρm=ρq+BC,\t(2)\r\nbut the total pressure is\r\n\r\npm=pq−BC.\t(3)\r\nThe equation of state for strange quark matter is [21,22]\r\n\r\npm=13(ρm−4BC).\t(4)\r\nRecently, the quark-gluon plasma is created as the perfect liquid in the Brookhaven National Laboratory [23-25]. So, we shall consider the quark-gluon plasma in the form of perfect fluid and also use the following equation of state:\r\n\r\npm=(γ−1)ρm,\t(5)\r\nwhere 1 ≤ γ ≤ 2 is a constant.\r\n\r\nIt is possible to couple quark matter with cosmic strings and domain walls. Because, the strings are free to vibrate and different vibrational modes of the strings represent the different particle types since different modes are seen as different masses or spins. Yilmaz [26,27] have studied 5-D Kaluza-Klein cosmological models with quark matter attached to the string cloud and domain walls. Adhav et al. [28,29] have discussed string cloud and domain walls with quark matter in n-dimensional Kaluza-Klein cosmological model in general relativity and strange quark matter attached to string cloud in Bianchi type-III space time in general relativity. Khadekar et al. [30] have confirmed their work to the quark matters which attached to the topological defects in general relativity. Katore and Shaikh [31] have obtained a cosmological model with strange quark matter attached to a cosmic string for axially symmetric space-time in general relativity. Mahanta et al. [32] have discussed string cloud with quark matter in self creation cosmology. Recently, Sahoo and Mishra [33,34] have studied string cloud and domain walls with quark matter for plane symmetric cosmological model and string cloud with strange quark matter in axially symmetric space-time in bimetric theory.\r\n\r\nA formulation of the general relativity theory is given in terms of three postulates about a mathematical model for space time. This model is a manifold M with a metric g of the Lorentz signature. The physical significance of the metric (space time) is given by the first two postulates: those of local casualty and of local conservation of energy momentum. These postulates are common to both general and special theory of relativity, and so are supported by the experimental evidence of the latter theory. The third postulate, the field equations for the metric g, is less well experimentally established. However, most of our results will depend only on the property of field equations that gravity is attractive for positive matter densities. This property is common to both general theory and alternative theories of relativity.\r\n\r\nThe metrical kinks discovered by Finkelstein and Misner [35] have arisen in the context of topology changing space-times [36] and in the study of black holes [37,38]. Although some interesting kink space-times can be found by explicit construction [39,40]; however, in view of the profusion of space-times representing known solutions of the Einstein equations (of varying degrees of physical reasonableness) [41], it is logical to look for kink space-times in this well-established list. Williams [42] has studied the rotating kink space-time in 2+1 Dimensions. The Gödel kink space-time has been identified by Harriott and Williams [43]. A natural generalization of a previously known (2+1)-dimensional kinked perfect fluid space-time [42] was shown to produce a (3+1)-dimensional space-time that does not represent a physically acceptable (perfect or imperfect) fluid but which, nevertheless, can satisfy the weak, strong and dominant energy conditions [44]. Our purpose in this paper is to construct this topic in relation to a broader class of kink space-time. The purpose of the present work is to study spherically symmetric kink cosmological models in general relativity with quark matter coupled to the string cloud and domain walls.\r\n\r\nField equations and their solutions for string cloud with quark matter\r\nHere, we considered the simplest spherically symmetric space-time in the presence of a kink which is given by [35]\r\n\r\nds2=−cos2αdt2−2sin2αdrdt+cos2αdr2+r2dΩ2,\t(6)\r\nwhere dΩ2 = dθ2 + sin2θdφ2 and α = α(r).The energy momentum tensor for string cloud is given by\r\n\r\nTij=ρuiuj−λxixj,\t(7)\r\nwhere ρ is the rest energy density for a cloud with particle attached to them and λ is the tension density of the strings; they are related by\r\n\r\nρ=ρp+λ,\t(8)\r\nwhere ρp is the rest energy density of particles.\r\n\r\nThe string is free to vibrate and different vibrational modes are seen as different masses or spins. Therefore, we will consider quarks instead of particles in the cloud of strings. In this case from (8), we get\r\n\r\nρ=ρq+λ+BC\t(9)\r\nFrom (7) and (9), we can write the energy momentum tensor for strange quark matter attached to the string cloud as [20]\r\n\r\nTij=(ρq+λ+BC)uiuj−λxixj,\t(10)\r\nwhere ui is the four velocity of the string and xi representing the direction vector of anisotropy. The string source is along the z-axis, which is the axis of symmetry.\r\n\r\nOrthonormalisation of ui and xi is given as\r\n\r\nuiui=−1,uixi=0,xixi=1\t(11)\r\nIn the co-moving coordinate system, from Equations (10) and (11)\r\n\r\nT11=0=T22;T44=ρ;T33=λ;Tij=0,i≠j\t(12)\r\nThe Einstein’s field equation in general relativity is\r\n\r\nRij−12Nδij=−8πGTij\t(13)\r\nHere, we consider geometrized units so that 8πG = c = 1. The Einstein’s field Equation (13) for the line element (6) with the help of Equations (7, 10,11, and 12) becomes\r\n\r\n2r2sin2α+2rα1sin2α=0\t(14)\r\n2rα1sin2α+α11sin2α+2α21cos2α=0\t(15)\r\n2rα1sin2α+α11sin2α+2α21cos2α=λ\t(16)\r\n2r2sin2α+2rα1sin2α=−ρ\t(17)\r\nHere afterwards, the suffix 1 following an unknown function denote ordinary differentiation with respect to r.\r\n\r\nThe field equations (14 to 17) gives the solution\r\n\r\nλ=0andρ=0\t(18)\r\nFrom (14), we obtain\r\n\r\n(rsin2α)1=0\t(19)\r\nwhich on integration yields\r\n\r\nα=sin−1kr‾‾√,\t(20)\r\nwhere k is a constant.\r\n\r\nHence, the simplest spherically symmetric kink space-time takes the form\r\n\r\nds2=−(1−2kr)dt2−4kr(1−2kr)‾‾‾‾‾‾‾‾‾‾√drdt+(1−2kr)dr2+r2(dθ2+sin2θdφ2)\t(21)\r\nFor r = 2k, there is no singularity in the space-time.\r\n\r\nField equations and their solutions for domain walls with quark matter\r\nThe energy momentum tensor TDij of a domain wall in the conventional form [45] is given by\r\n\r\nTDij=ρUiUj+p(gij+UiUj),\t(22)\r\nwhere Ui is time-like vector such that UiUi = -1 otherwise 0. Here, we also use the co-moving co-ordinate system. This perfect fluid form of the domain walls include quark matter [26] described by ρm = ρq + BC and pm = pq - BC as well as domain walls tension σw is given by ρ = ρm + σw and p = pm - σw which are related by the bag model equation of state (Equation 4) and equation of state (Equation 5).\r\n\r\nUsing the line element (6), the field Equation (13) take the form for (22) as\r\n\r\n2r2sin2α+2rα1sin2α=−p\t(23)\r\n2rα1sin2α+α11sin2α+2α21cos2α=−p\t(24)\r\n2r2sin2α+2rα1sin2α=ρ\t(25)\r\nThe set of field Equations (23 to 25) immediately yields\r\n\r\np+ρ=0\t(26)\r\nIn view of reality conditions p > 0, ρ > 0, Equation (26) implies that\r\n\r\np=0andρ=0\t(27)\r\nwhen p = 0 = ρ (vacuum), from Equations (23-25) which in turn yield the same vacuum solution given by Equation (20).\r\n\r\nConclusion\r\nGeneral relativity provides a rich arena to understand the natural relation between geometry and matter furnished by the Einstein equations. Field equations mean that any two field configurations connected by a diffeomorphism which are empirically indistinguishable and physically identical. Topological stable objects like domain walls and cosmic strings play a fundamental role in the formation of universe during the early stage of evolution. It is evident from the literature that Einstein’s theory of general relativity has been extensively used to establish the existence of thick domain walls and cosmic strings. Here, it is shown that the spherically symmetric kink universe does not accommodate domain walls and cosmic strings coupled with quark matter in the general theory of relativity. In both the cases, the space-time turns up to be flat. Hence, a vacuum kink model is obtained. It is interesting to note that the vacuum model (21) obtained here has no singularity at r = 2k.", user_id: 1, journal_id: 15, field_id: 16, institution_id: 24});

paper27 = Paper.create!({title: "First principles study on structural and magnetic properties of small and pure carbon clusters (C n , n = 2 - 12)", body: "Abstract\r\nWe have demonstrated the structural and magnetic properties of small carbon clusters (Cn,n = 2 - 12) in the framework of collinear approximation using density functional theory. The calculations were performed for amorphous, linear, and ring carbon clusters using full-potential local-orbital (FPLO) method. We have obtained stable structures, total energies, total magnetic moments, and HOMO-LUMO energy gap of these clusters. We have found that the amorphous carbon clusters with minimum energy are not magnetic clusters whereas their less-stable isomers with special configurations are ferromagnetic objects. Two robust magnetic moments were found for C5 carbon ring (6µB) and for pentagonal pyramid C6 structure (4µB).\r\n\r\nKeywords: Carbon cluster; Density functional theory; Nanomagnetism\r\nIntroduction\r\nThe intriguing possibility of magnetism and structural properties of carbon clusters has triggered great research interests due to their potential applications in molecular magnetism and spin functional nanodevices. Especially, nanodiamond particles can be used as a potential candidate to increase wear resistance and microhardness, and decrease the coefficients of friction and corrosion in composite functional layers such as hard disks and magnetic heads [1]. In addition, nanoscale magnetic sensors have been developed on the bases of nanodiamonds including nitrogen-vacancy impurities [2]. It has been found that carbon atoms can be magnetized around a vacancy defect in graphene [3] and also those carbon atoms located at the edges of a graphene nanoribbon [4,5]. As a consequence, one can examine a magnetic feature for carbon clusters with some especial configurations. Therefore, it is prime important to know the magnetic properties of carbon structures and to know in which structure the carbon clusters are magnetized.\r\n\r\nIn the present work, our interest is concerned with the theoretical density functional theory (DFT) calculations to investigate the structures, electronic, and especially the magnetic properties of pure and neutral small carbon clusters. In this context, many experimental and theoretical studies have been conducted on the pure carbon clusters [6-12]. Raghavachari and Binkley, using spin-unrestricted version of Hartree-Fock method, have obtained the structures and energies of small carbon clusters (Cn, n = 2 - 10) and revealed an odd-even pattern in the cluster geometries and that the odd-numbered clusters prefer linear structure and the even-numbered clusters prefer irregular cyclic structure [13]. Xu and co-workers have studied a number of annular carbon structures (Cn, n = 3 - 31) and linear carbon clusters (Cn, n = 2 - 12). They have found electronic properties of these carbon clusters such as total energies, energy gaps between highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO), and bond lengths at the level of DFT/B3LYP/6-31G ∗ approach [14,15]. Zhang and co-workers have optimized the structure of Cn clusters (n = 2 - 30) and have calculated binding energy for these clusters using the genetic algorithm associated with simulated annealing method [16]. The electronic properties and relative energies of carbon clusters with 2n atoms (2 ≤ n ≤ 16) for stable isomers including chains, rings, cages, and graphitic (plate and bowl) structures have been found by R.O. Jones [17]. Also, López-Urías and co-workers, using single-band Hubbard model and pseudo-potential approach implemented in the SIESTA package, have studied the electronic and magnetic properties of sp2 carbon isomers Cn(n = 10,12,14) [18]. They have found a triplet state for some studied isomers in which this state strongly depends on the cluster geometry [18]. It has to be taken into account that carbon atoms are hybridized together in the form of sp, sp2, and sp3. Therefore, one can examine that there are many stable isomers for a typical pure carbon cluster including n atoms. To the best of our knowledge, there is no systematic study on magnetic and structural properties of all isomers of carbon clusters even for small structures.\r\n\r\nIn this paper we made an exhaustive search in carbon isomers to find out magnetic and stable objects with amorphous structure. In addition, the binding energies, HOMO-LUMO energy gaps and magnetic properties of sp, sp2, and sp3 carbon clusters (Cn, n = 2 - 12) were studied. These properties were investigated for carbon clusters in the form of amorphous wire and ring structures using full-potential local-orbital method which is developed on the basis of linear combination of atomic orbitals (LCAO) method. In Section 'Computational method,’ the numerical approach is discussed. Section 'Results and discussion’ presents the structural properties of different carbon isomers, calculated magnetic moments, binding energies, etc. Finally, the paper is summarized in Section 'Conclusions.’\r\n\r\nComputational method\r\nAll magnetic calculations were performed using density functional theory [19] implemented within a self-consistent full-potential local-orbital basis band structure method, FPLO.9 package [20]. In this scheme, the scalar relativistic calculations were implemented within a spherical average on the spin-orbit interaction, using four-component Kohn-Sham-Dirac equation [21]. The generalized gradient approximation of (GGA) Perdew-Burke-Ernzerhof 96 was used for the exchange-correlation potential [22]. The valence basis set of carbon consisted of 1s, 2s, 2p, 3s, 3p, and 3d states so that for the sake of completeness, carbon core electrons and its polarization states were considered as valence electrons. For each size of studied clusters, several initial configurations were considered. In order to optimize atomic geometries, the position of all carbon atoms was fully relaxed. In the optimization process, the total energy and force converged to 0.001 meV and 0.001 eV/Å, respectively. The binding energy per atom (Eb) for all studied clusters was determined as Eb = (nEs - Et)/n, where n is the size of the cluster (number of carbon atoms), Es is the energy of the single carbon atom and Et is the total energy of the relaxed cluster.\r\n\r\nResults and discussion\r\nIn order to obtain stable carbon clusters, all amorphous structures were taken with most possible symmetry as initial configurations. However, it has to be pointed out that after relaxation process, most of the selected structures were unstable and deformed. The relaxed isomers and related point group symmetries of amorphous carbon clusters are illustrated in Figure 1. The relaxed carbon rings and their related point groups are shown in Figure 2. Table 1 shows the total energies of the lowest amorphous, linear, and ring structures. In Figure 3, we have indicated the calculated binding energies, related HOMO-LUMO gaps, and second difference energies for linear, ring, and amorphous structures with minimum energy.\r\nAt first, the calculations were performed for carbon dimer. The optimized bond length is 1.316 Å, and its magnetic moment was obtained 2 μB. The calculated C-C bond length at the DFT (GGA) level is larger than that in experimental value (1.243 Å) by about five percent [23]. Our calculated GGA bond length for C2 dimer can be compared to the calculated bond length (1.315 Å) done by Congie Zhang [16].\r\n\r\nFor C3 cluster, we considered linear and triangular structures. Linear isomer with D∞h symmetry was found to be the most stable structure whose magnetic moment is zero. Triangular structure (D3h) with magnetic moment 2 μB lies 564 meV higher in total energy compared to its linear isomer. The calculated bond length for triangular structure is 1.377 Å, which is in agreement with the calculated bond length done by Martin and co-workers [24]. The calculated C-C bond length of the C3 linear cluster is 1.304 Å, where it can be compared to the experimental value of 1.297 Å, determined by Hinkle et al. [25] and calculated bond length (1.305 Å) done by Hutter and co-workers [26].\r\n\r\nWe have studied square and tetrahedron structures for C4 cluster but after relaxation due to Jahn-Teller effect, they distorted to Figure 1 (4a) and (4b) structures, respectively. The most stable structure is a rhombic structure (Figure 1 (4a)) with D2h point group symmetry and zero magnetic moment. The Figure 1 (4b) structure with C2v symmetry is a ferromagnetic object with magnetic moment 2 μB lying 807 meV higher in total energy compared to rhombic isomer (Figure 1 (4a)). For the C5 cluster, we examined two different initial configurations: triangular bipyramid and squared pyramid. It is found that both isomers were deformed to the same structure after relaxation (see (5a) in Figure 1). The symmetry of C5 structure is D3h, and it was found to be a nonmagnetic object.\r\n\r\nWe have investigated three different geometries for C6. A distorted trigonal prismatic (Figure 1 (6a), C2v) was found to be the most stable structure and nonmagnetic cluster. The next two isomers are a pentagonal pyramid (6b, C5v) and a distorted octahedron (6c, C2v), which lie at 614 and 1041 meV higher than the structure with minimum energy whose magnetic moments are 4 and 2 μB, respectively. Our findings show that the pentagonal pyramid structure has the largest magnetic moment among the tridimensional carbon structures investigated in this work. For C7, we obtained two structures: hexagonal prism and plane-like structure. Our calculations have indicated that the planar C2v isomer is the most stable structure with 4,386 meV energy below the hexagonal prism with C6v point group symmetry. We have also studied five structures for C8 cluster. Our calculations indicated that Figure 1 (8a) with D4d symmetry is the most stable structure, and the planar D2h isomer in Figure 1 (8b) with energy difference of 2,016 meV lies higher than the D4d isomer. The next isomer with C2v symmetry lies 2330 meV higher compare to D4d structure. The Figure 1 (8d) structure has a cubic form with Oh symmetry and energy difference of 3950 meV higher than Figure 1 (8a) structure. The most nonstable isomer (Figure 1 (8e)) has also C2v symmetry with 5.011 eV higher with respect to the most stable structure.\r\n\r\nFor C9 cluster, two initial structures (capped tetragonal prism and tricapped trigonal prism) were deformed to Figure 1 (9a) and (9b) structures. The square pyramid structure was also stable (Figure 1 (9c), C4v). The Figure 1 (9a) cluster with C2v symmetry was found as the structure with minimum energy. The Figure 1 (9b) structure also with C2v symmetry lies 4,489 meV higher in energy and square pyramid in Figure 1 (9c) is less stable with energy difference of 5,959 meV higher than the Figure 1 (9a) cluster. In the case of C10 cluster, we have studied three structures, but only the square dipyramid structure Figure 1 (10c) retained its initial geometric configuration. However, this structure is the most nonstable isomer in comparison to the other studied C10 clusters and lies 11,070 meV higher in energy with respect to the minimum energy structure (Figure 1 (10a), Cs). The (10b) carbon cluster in Figure 1 with Cs symmetry and energy difference of 502 meV lies higher than Figure 1 (10a) structure. For C11, two stable structures were investigated. It was found that both relaxed configurations have amorphous feature with no symmetry. The most stable Figure 1 (11a) carbon structure lies below Figure 1 (11b) structure with energy difference of 715 meV. The last tridimensional cluster studied in this work is C12. The initial structure for C12 was chosen as an icosahedron with Ih symmetry. The total energy calculated for structure Figure 1 (12b) was -12,384.260 eV, whereas after relaxation the initial structure was totally deformed (see (12a) structure in Figure 1). This structure has Cs symmetry and its total energy is -12,417.34 eV. However, we have found that the icosahedral C12 cluster is a magnetic object and its calculated magnetic moment is 2 μB whereas it is not a stable structure at room temperature and ambient pressure.\r\n\r\nWe have also studied the magnetic properties of ring and linear carbon clusters in which they are isoelectronics to the considered amorphous structures. It has to be pointed out that our calculated magnetic moments for even-numbered linear clusters are 2 μB and for odd-numbered linear structures have vanished. Li and co-workers have also shown the same magnetic pattern for finite-sized carbon wires [27]. It can be seen in Figure 2 that the magnetic properties of ring structures are completely dependent on the size and structure of the clusters. It has to be pointed out that C3 (D3h) with triangular structure, C5 ring with pentagonal structure (D5h), and C7, C9, and C12 with C2v symmetry are magnetic rings. Among the studied carbon clusters with n ≤ 12, the C5 ring has the largest magnetic moment (6 μB). According to the data in Table 1, it can be argued that the carbon rings of C6, C10, C11, and C12 are more stable than their linear isomers with 362 meV, 2682 meV, 1011 meV and 547 meV lower in total energy, respectively. Martin and co-workers have found that the carbon linear structures with n ≤ 10 are more stable than their ring isomers [28,29]. Their findings are in contradiction with our results, since we have found that the ring structures of C6 and C10 are more stable than their linear structures. We have also found that the C5 with D 3h symmetry and C7 with C2v symmetry are more stable than the isoelectronic ring structures (see Table 1).\r\n\r\nThe behavior of binding energies (Eb), second difference energies Δ2E(n), and HOMO-LUMO gaps for the all studied carbon structures are depicted in Figure 3. It can be seen that the binding energies per carbon atom are increased with the increasing size of the cluster. For the amorphous carbon structures, it can be seen that there is a gradual increase in the binding energy in the range of n = 3 - 6 and n = 7 - 12 for tridimensional (amorphous) structure with minimum energy (see Figure 3). It has to be pointed out that also with increasing the number of carbon atoms in the clusters, the binding energies are merged to 6.5 eV. This value is very close to the binding energy of carbon macromolecules [16]. A better way to show the relative stability of a cluster is the second differences in energy Δ2E(n) defined by Δ2E(n) = E(n + 1) + E(n - 1) - 2E(n), where E(n) is the total energy of Cn clusters. It was shown in the middle panel of Figure 3 that the C3, C7, and C11 amorphous structures are more stable than their neighbors. The same argument can be concluded for C6 and C10 ring structures (see the middle panel of Figure 3). The Δ2E(n) for linear structures shows a systematic behavior whereas for amorphous and rings structures it behaves very irregular. It is obvious from Δ2E(n) in Figure 3 that the odd-numbered linear carbon structures are more stable than the even-numbered linear carbon structures. We have also investigated the behavior of HOMO-LUMO energy gaps (ΔH-L) for the studied structures (see Figure 3). It can be pointed out that the HOMO-LUMO gap can give a criterion for chemical reactivity of a typical cluster, in which a larger HOMO-LUMO gap means less reactivity. In Figure 3 it can be seen that HOMO-LUMO gaps of the odd-numbered linear structures are larger than the even-numbered linear clusters. On the other hand, the behavior of HOMO-LUMO gaps for amorphous and rings clusters is completely irregular compared to their linear isomers. We have found that the C6 carbon cluster with C5v point group symmetry is the less reactive cluster compared to the other studied amorphous carbon clusters. We have also clarified that C10 carbon ring is less reactive object compared to the other studied carbon rings. It can be seen in Figure 3 that the Δ2E(n) and ΔH-L have the same pattern for linear carbon structures, whereas this behavior cannot be seen for amorphous and linear structures.\r\n\r\nConclusions\r\nIn conclusion, we have studied the structures and magnetic properties of small carbon clusters (Cn, n = 2 - 12) using density functional theory method with generalized gradient approximation. The stable geometrical carbon structures are obtained after relaxation calculations. Then we have investigated the most stable structures, magnetic moments, binding energies, the second differences of energy, and the related HOMO-LUMO energy gaps. Furthermore, we have found that the magnetizations of amorphous and ring structures are completely dependent on the cluster size and configuration of the carbon atoms in the cluster. We have also shown that the lowest amorphous carbon structures with minimum energy when formed in a tridimensional structure have no net magnetic moments. According to our results for small and amorphous carbon clusters, we may expect a nonmagnetic feature for larger carbon clusters formed at room temperature and ambient pressure. Finally, we have shown that some less stable carbon isomers are magnetic in which one can imagine that they are initial building blocks for magnetic nanodiamonds at high pressure.", user_id: 1, journal_id: 15, field_id: 16, institution_id: 25});

paper28 = Paper.create!({title: "Relativistic spin symmetry of the generalized Morse potential including tensor interaction", body: "Abstract\r\nThe relativistic Dirac equation under spin symmetry is investigated for generalized Morse potential. We calculated the eigenvalues and the corresponding wave function by using the Nikiforov-Uvarov method. We also discussed two special cases: attractive radial and Deng-Fan potentials. We have also reported some numerical results and figures to show the effect of tensor interaction.\r\n\r\nIntroduction\r\nThe relativistic symmetries of the Dirac Hamiltonian had been discovered about 40 years ago. These symmetries have been recently recognized empirically in nuclear and hadronic spectroscopic [1]. However, within the framework of Dirac equation, the concepts of exact pseudospin symmetry occurs when the magnitude of the attractive Lorentz scalar potential S(r) and the repulsive vector potential V(r) are nearly equal but opposite in sign, i.e., S(r) ≈ -V(r) [2,3]. Also, the approximate pseudospin symmetry is when the sum of the potential is Σ(r) = cps = const ≠ 0 [4]. The pseudospin symmetry used to feature deformed nuclei and the superdeformation to establish an effective shell model [5]. On the other hand, the spin symmetry is relevant in mesons [6] and occurs when the difference of the scalar S(r) and V(r) potentials are constant, i.e., Δ(r) = V(r) - S(r) = cs = const ≠ 0 [3,4]. The pseudospin symmetry refers to a quasi-degeneracy of single-nucleon doublets with non-relativistic quantum number (n,l,j=l+12) and (n−1,l+2,j=l+32), where n, l, j denote the single nucleon radial, orbital, and total angular momentum quantum numbers, respectively [7,8]. Furthermore, the total angular momentum is j=l˜+s˜, where l˜=l+1 is the pseudo-angular momentum and s˜ is the pseudospin angular momentum [9].\r\n\r\nThe relativistic and non-relativistic quantum mechanics equations with different phenomenology have been considerably investigated in the recent years [10-25]. Ikhdair and Sever [19] have solved approximately the Dirac-Hulthen problem under spin and pseudospin symmetry limits including Coulomb-like tensor potential with an arbitrary spin-orbit coupling number κ. Also, Hamzavi et al. [20] studied the exact solutions of the Dirac equation for Mie-type potential and approximate solutions of the Dirac-Morse problem with Coulomb-like tensor potential and relativistic Morse potential with tensor interaction [21]. Similarly, Ikot [22] solved the generalized hyperbolical potential including a tensor potential for spin symmetry. The Morse potential is one of the convenient models for the potential energy of diatomic molecules. The Morse potential can be used to model interactions such as the interaction between an atom and a surface [23]. Berkdemir investigated the pseudospin symmetry in the relativistic Morse potential systematically by solving the Dirac equation by applying the Pekeris approximation to the spin-orbit coupling term [24]. The Morse potential (MP) is defined as [21]\r\n\r\nV(r)=De[1−e−2α(r−rc)],\t(1)\r\nwhere α is the screening parameter and De is the dissociation energy.\r\n\r\nIn this work, we introduced a novel potential and call it the New Generalized Morse-like potential (NGMP) model having the same behaviors as MP, attractive radial potential, and Deng-Fan potential models. It is defined as\r\n\r\nV(r)=De[1−(A+Be−αrC+D′e−αr)2],\t(2)\r\nwhere A, B, C, D′ are constant coefficients and the term in the bracket is the Mobius square potential proposed recently [25] (see Figure 1).\r\nThe motivation of the present work is intend to investigate this potential including the Coulomb-like term under the spin symmetry limit and calculate the energy eigenvalues and the corresponding wave functions expressed in terms of the hypergeometric functions.\r\n\r\nThe organization of the paper is as follows. In the 'Parametric Nikiforov-Uvarov method’ section, we briefly introduced the NU method. The 'Dirac equation with a tensor coupling’ section is devoted to the Dirac equation with scalar and vector potential with arbitrary spin-orbit coupling number κ including tensor interaction under spin and pseudospin symmetry limits. The energy eigenvalue equation and corresponding wave functions for spin symmetry limit is obtained in the 'Spin symmetry limit’ section. A special case of the potential under investigation is discussed in the 'Special cases’ section. Finally, we give a brief conclusion in the 'Conclusions’ section.\r\n\r\nParametric Nikiforov-Uvarov method\r\nThe NU method is used to solve second-order differential equations with an appropriate coordinate transformation s = s(r) [26].\r\n\r\nψ″n(s)+τ˜(s)σ(s)ψ′n(s)+σ˜(s)σ2(s)ψn(s)=0,\t(3)\r\nwhere σ(s) and σ˜(s) are polynomials, at most of second degree, and τ˜(s) is a first-degree polynomial. To make the application of the NU method simpler and direct without need to check the validity of solution, we present a shortcut for the method. So, at first, we write the general form of the Schrödinger-like Equation (3) in a more general form applicable to any potential as follows [27]:\r\n\r\nψ′′n(s)+(c1−c2ss(1−c3s))ψ′n(s)+(−ξ1s2+ξ2s−ξ3s2(1−c3s)2)ψn(s)=0,\t(4)\r\nsatisfying the wave functions\r\n\r\nψn(s)=ϕ(s)yn(s).\t(5)\r\nComparing (4) with its counterpart (5), we obtain the following identifications:\r\n\r\nτ˜(s)=c1−c2s,σ(s)=s(1−c3s),σ˜(s)=−ξ1s2+ξ2s−ξ3.\t(6)\r\nFollowing the NU method [26-30], we obtain the following;\r\n\r\n(1) the relevant constant:\r\n\r\nc4=12(1−c1),c6=c25+ξ1,c8=c24+ξ3,c10=c1+2c4+2c8‾‾√c12=c4+c8‾‾√c5=12(c2−2c3),c7=2c4c5−ξ2,c9=c3c7+c23c8+c6.c11=c2−2c5+2(c9‾‾√+c3c8‾‾√)c13=c5−(c9‾‾√+c3c8‾‾√)\t(7)\r\n(2) the essential polynomial functions:\r\n\r\nπ(s)=c4+c5s−[(c9‾‾√+c3c8‾‾√)s−c8‾‾√],\t(8)\r\nk=−(c7+2c3c8)−2c8c9‾‾‾‾√,\t(9)\r\nτ(s)=c1+2c4−(c2−2c5)s−2[(c9‾‾√+c3c8‾‾√)s−c8‾‾√],\t(10)\r\nτ′(s)=−2c3−2(c9‾‾√+c3c8‾‾√)<0.\t(11)\r\n(3) the energy equation:\r\n\r\nc2n−(2n+1)c5+(2n+1)(c9‾‾√+c3c8‾‾√)+n(n−1)c3+c7+2c3c8+2c8c9‾‾‾‾√=0.\t(12)\r\n(4) the wave functions:\r\n\r\nρ(s)=sc10(1−c3s)c11,\t(13)\r\nϕ(s)=sc12(1−c3s)c13,c12>0,c13>0,\t(14)\r\nyn(s)=P(c10,c11)n(1−2c3s),c10>−1,c11>−1,\t(15)\r\nψnκ(s)=Nnκsc12(1−c3s)c12−c13c3P(c10−1,c11c3−c10−1)n(1−2c3s),\t(16)\r\nwhere P(μ,ν)n(x),μ>−1,ν>−1 and x ∈ [-1, 1] are Jacobi polynomials with\r\n\r\nP(α,β)n(1−2s)=(α+1)nn!F12(−n,1+α+β+n;α+1;s),\t(17)\r\nand Nnκ is a normalization constant. Also, the above wave functions can be expressed in terms of the hypergeometric function as\r\n\r\nψnκ(s)=Nnκsc12(1−c3s)c132F1(−n,1+c10+c11+n;c10+1;c3s),\t(18)\r\nwhere c12 > 0, c13 > 0 and s ∈ [0, 1/c3], c3 ≠ 0. This method has been used extensively to solve various second-order differential equations in quantum mechanics such as Schrodinger equation, Klein-Gordon equation, Duffin-Kemmar-Petiau equation, spinless-Salpeter equation, and Dirac equations [31].\r\n\r\nNumerical results\r\nWe obtain the energy eigenvalues in the absence (H = 0) and the presence (H =0.5 and 1) of the Coulomb-like tensor potential for various values of the quantum numbers n and κ. In Table 1, we have reported the numerical values of the energy for various values of H. We can clearly see that there is the degeneracy between the bound states and in the presence of the tensor interaction, these degeneracies are changed or removed. Also, we have reported the behavior of the energy in Figure 3, which represent energy vs. H which clearly see the degeneracy in the spin doublets for some values of H and the energy eigenvalue difference between the degenerate state increases as H increases. In Figure 4, we show the behavior of the energy vs. α for spin symmetry limits. It is seen that if the α-parameter increases, the bound states become more bounded both for the spin symmetry limit. Similarly, the energy has also been plotted vs. the potential coefficients De, A and B in Figures 5, 6, and 7. Finally, Figure 8 shows the plot of the energy for different values of Cs. It is seen in Figures 5, 6, 7, and 8 that although bound states obtained in view of spin symmetry become more bounded with increasing De, A and Cs, they become less bounded with increasing B.\r\n\r\nConclusions\r\nWe have presented analytical expressions for the eigenvalues and wave function for the Dirac equation with a generalized Morse potential including Coulomb-like potential in view of the spin symmetry limit by using Nikiforov-Uvarov method. We have found the radial upper and lower wave functions in terms of the Jacobi polynomials. We have also discussed two special cases of this potential such as the attractive radial potential and Deng-Fan potential which is consistent with those found in the literature [37,38,40,41]. These results we have obtained will be useful in many areas of physics such as theoretical, molecular, and nuclear physics.", user_id: 1, journal_id: 15, field_id: 16, institution_id: 26});

paper29 = Paper.create!({title: "Controlled double-slit electron diffraction", body: "Abstract\r\nDouble-slit diffraction is a corner stone of quantum mechanics. It illustrates key features of quantum mechanics: interference and the particle-wave duality of matter. In 1965, Richard Feynman presented a thought experiment to show these features. Here we demonstrate the full realization of his famous thought experiment. By placing a movable mask in front of a double-slit to control the transmission through the individual slits, probability distributions for single- and double-slit arrangements were observed. Also, by recording single electron detection events diffracting through a double-slit, a diffraction pattern was built up from individual events.\r\n\r\nIntroduction\r\nRichard Feynman described electron diffraction as a phenomenon 'which has in it the heart of quantum mechanics. In reality, it contains the only mystery' [1]. He went on to describe a thought experiment for which he stated 'that you should not try to set up' because 'the apparatus would have to be made on an impossibly small scale to show the effects we are interested in'. He used these effects to help illustrate the phenomena of wave–particle duality, which is a postulate that all particles exhibit both wave and particle properties. The effects he described were: the relations between electron probability distributions from single- and double-slits, and observation of single particle diffraction. In this paper we report both control over the individual slits to observe probability distributions from both single- and double-slits, and the build-up of a diffraction pattern at single electron detection rates to achieve the full realization of Feynman's thought experiment. We use the term build-up to refer to the measurement of the cumulative spatial detection pattern as a function of time.\r\nThe general perception is that the electron double-slit experiment has already been performed. This is true in the sense that Jönsson demonstrated diffraction from single, double, and multiple (up to five) micro-slits [2], but he could not observe single particle diffraction, nor close individual slits. In two separate landmark experiments, individual electron detection was used to produce interference patterns; however, biprisms were used instead of double-slits [3, 4]. First, Pozzi recorded the interference patterns at varying electron beam densities. Then, Tonomura recorded the positions of individual electron detection events and used them to produce the well known build-up of an interference pattern. It is interesting to point out that the build up of a double-slit diffraction pattern has been called 'The most beautiful experiment in physics' [5, 6], while the build-up for a true double-slit has, up to now, never been reported.\r\nMore recently, electron diffraction was demonstrated with single- and double-slits using focused ion beam (FIB) milled nano-slits [7, 8]. In addition, one single slit in a double-slit was closed by FIB induced deposition [9]. This process is not reversible, so observation of the electron probability distribution through both single-slits could not be done. Also, using a fast-readout pixel detector, electrons were recorded one at a time and stacked into a final diffraction pattern [10], but intermediate spatial patterns were not reported.\r\nFeynman's thought experiment is summarized in figure 1. The figure is an adaptation from Feynman Lectures on Physics, vol III, figures 1–3, with the mask, experimental data, and micrographs added. The thought experiment contained two parts. The first involved observing probability distributions in three scenarios: electrons traveling through slit 1 with slit 2 closed (P1); electrons traveling through slit 2 with slit 1 closed (P2); and electrons traveling through both slits (P12). These scenarios illustrate the quantum mechanical superposition principle, i.e. the wave properties, and can be demonstrated with control of the slits (figure 2). The second part of the thought experiment was the observation of individual electrons associated with detection 'clicks'. This illustrates that a quantum mechanical electron wave cannot be thought of as comprising multiple electrons, i.e. the particle properties, which can be demonstrated with the build-up of the diffraction pattern (figure 3).\r\n\r\nExperimental setup\r\nThe experimental setup is shown diagrammatically in figure 1(a). An electron beam with energy of 600 eV, which corresponds to a de Broglie wavelength of 50 pm, was generated with a thermionic tungsten filament and several electrostatic lenses. The beam was collimated with a slit of 2 μm width and 10 μm height placed at 16.5 cm. The double-slit was located 30.5 cm from the collimation slit. The resulting patterns were magnified by an electrostatic quadrupole lens and imaged on a two-dimensional microchannel plate and phosphorus screen, then recorded with a charge-coupled device camera. For a more detailed description of the setup see supplementary information (available from stacks.iop.org/NJP/15/033018/mmedia).\r\nTwo methods were used to analyze the images. To investigate the probability distributions, the images were summed up by adding each frame's intensity, then normalized. This resulted in a false color probability distribution (figures 1 and 2). To study the build-up of the diffraction pattern, each electron was localized using a 'blob' detection scheme [11, 12]. Each detection was replaced by a blob, whose size represents the error in the localization of the detection scheme. The blobs were compiled together to form the electron diffraction patterns (figure 3).\r\nThe collimation slit, double-slit, and mask were made by FIB milling into three 100 nm-thin silicon-nitride membrane windows. The FIB milling was performed on a 30 keV Ga+ system (FEI Strata 200xp). After milling, each membrane was coated with approximately 2 nm of gold. The double-slit consists of two 62-nm-wide slits with a center-to-center separation of 272 nm (see inset 1 in figure 1). Each slit is 4 μm tall and has a 150 nm support midway along its height. The mask is 4.5 μm wide ×10 μm tall (see inset 2 in figure 1), and was placed 240 μm away from the double-slit. The mask was held securely in a frame that could slide back and forth and was controlled by a piezoelectric actuator. For a more detailed description of the setup and analysis see supplementary information.\r\n\r\nResults\r\nThe movable mask was placed behind the double-slit, see figure 1. The mask was moved from one side to the other (figure 2 top to bottom). Initially the majority of the electrons are blocked. As the mask is moved, slit 1 becomes partially, then fully open. When one slit is open, single-slit diffraction can be observed (P1 in figures 1(b) and 2). Feynman indicates this as the solid black curve P1 (figure 1(b)), which is just the central order of the single-slit diffraction pattern. Because of the finite separation of the mask and double-slit, weak double-slit diffraction can be seen in the negative first order of the single-slit diffraction pattern (see left edge of P1 in figure 2).\r\nAs the mask is moved further, more electrons can travel through both slits, changing the pattern from single-slit to double-slit diffraction. When the mask is centered on the double-slit, both slits are completely open and full double-slit diffraction can be observed (P12 in figures 1(c) and 2). In this position, interaction between the mask and the diffracting electrons is negligible. The edges of the mask are 2250 nm away from the center and would only affect diffraction orders greater than the 50th. The mask is then moved further and the reverse happens; double-slit diffraction changes back to single-slit diffraction (P2 in figures 1(b) and 2). Now, the single-slit diffraction pattern has a weak contribution of double-slit diffraction in its positive first order (see right edge of P2 in figure 2). (See supplementary movie 1 for more positions of the mask.)\r\nElectron build-up patterns were recorded with the mask centered on the double-slit. The electron source's intensity was reduced so that the electron detection rate in the pattern was about 1 Hz. At this rate and kinetic energy, the average distance between consecutive electrons was 2.3 × 106 m. This ensures that only one electron is present in the 1 m long system at any one time, thus eliminating electron–electron interactions. The electrostatic quadrupole lens was set to zoom in on the central five diffraction orders. In figure 3 the build-up of the diffraction pattern is shown. In figures 3(a)–(c), the electron hits appear to be completely random and only after many electrons are accumulated can a pattern be discerned, figure 3(d). In figure 3(e) the pattern is clearly visible. The final build-up of the pattern took about 2 h. A full movie of the electron build-up is included in the supplementary data (see supplementary movie 2, available from stacks.iop.org/NJP/15/033018/mmedia).\r\n\r\nConclusion\r\nIn this paper, we show a full realization of Feynman's thought experiment and illustrate key features of quantum mechanics: interference and the wave–particle duality of matter. By controlling the transmission through the individual slits of a double-slit we were able to observe the diffraction patterns from slit 1 (P1), slit 2 (P2), and both (P12), thus observing the wave properties of electrons. Also, by recording single electron detection events diffracting through a double-slit we were able to build up a diffraction pattern, thus observing the particle properties of electrons.", user_id: 1, journal_id: 16, field_id: 16, institution_id: 27});

paper30 = Paper.create!({title: "Simplified self-consistent probabilities method for percolation and its application to interdependent networks", body: "Abstract\r\nInterdependent networks in areas ranging from infrastructure to economics are ubiquitous in our society, and the study of their cascading behaviors using percolation theory has attracted much attention in recent years. To analyze the percolation phenomena of these systems, different mathematical frameworks have been proposed, including generating functions and eigenvalues, and others. These different frameworks approach phase transition behaviors from different angles and have been very successful in shaping the different quantities of interest, including critical threshold, size of the giant component, order of phase transition, and the dynamics of cascading. These methods also vary in their mathematical complexity in dealing with interdependent networks that have additional complexity in terms of the correlation among different layers of networks or links. In this work, we review a particular approach of simple, self-consistent probability equations, and we illustrate that this approach can greatly simplify the mathematical analysis for systems ranging from single-layer network to various different interdependent networks. We give an overview of the detailed framework to study the nature of the critical phase transition, the value of the critical threshold, and the size of the giant component for these different systems.\r\n\r\nIntroduction\r\nSystems consisting of multiple inter connected networks with different types of links have received enormous attention in recent years [1–9] due to their ubiquitous applications in complex systems. Such networks appear in the literature as interdependent networks or multiplex networks. Studies have shown that interdependent networks show different percolation/phase transition behaviors than single networks. In particular, an interdependent network is more vulnerable to random attacks [10]. As many real-world infrastructure networks can be classified into interdependent networks [11–14], the understanding of their robustness carries great practical significance.\r\nIn a network consisting of links and nodes, one of the most important quantities used to analyze its robustness is the size of the giant component, which is defined as the largest set of nodes that are connected to each other. When a network is under attack (i.e., a fraction  of nodes (or links) are removed), the size of the largest cluster shrinks. Usually its size is a finite fraction of the total number of nodes in the network, unless more than a certain fraction, , of nodes are removed. If that happens, then the largest cluster, which is known as the giant component, disappears and all of the clusters become negligibly small. This phase is associated with the disintegration of the network. Therefore, the size, , of the giant component serves as an order parameter that is very useful in studying the phase transition behaviors and the robustness of the network structure.\r\nSome original works [1, 15] provided a precise and powerful analytical solution to the phase transition behaviors. In their mathematical analysis, recursive mapping was used to track the percolation process in each stage of cascading failures. In some systems where correlations exist in dependency links [7–9, 16, 17], this method, while having the advantage of following and yielding insight into the cascading process [18], could lead to very complicated formulations that are not always easy to solve. To study different network constructions, some of the other studies used different methods to achieve a relatively simpler analytical framework. In particular, the works in [7, 8, 19–22] used self-consistent equations of the converging probabilities to have an alternative approach to analyzing the critical behaviors of certain types of interdependent networks. Some of these methods can be extended to other scenarios.\r\nIn this paper, we illustrate the use of one particular technique based on self-consistent probabilities [8, 19–21], and we demonstrate that this technique could be applied to a wide variety of different interdependent networks with minimum simplicity by surveying the literature in this field. This method focuses on the recursive representation of two central quantities, defined as the probabilities of finding a link/node in the giant component. It is able to give a set of straightforward self-consistent equations describing the percolation behaviors without going through the cascading process [1], and it also deals with many correlated systems with simpler mathematical formulations.\r\nFirst we will illustrate the framework through the example of single-layer network. Next, we will extend it to multilayer networks without degree-degree correlations. Following that, we extend the analysis to more complicated scenarios of partially correlated networks and degree-degree correlated networks. More complications are added to the case when multiple dependency links per node are introduced along with correlations, as well as a single network with different types of links, which is also known as a multiplex network.\r\n\r\nSingle-layer network\r\nThe classic site-percolation problem in a random network [23, 24, 28, 29] gives rich phase transition phenomena for various network structures. In the simplest case, we consider a random network without any correlations, and its degree distribution, P(k), fully captures its structural property. We start by introducing a key quantity, x, in to the system. This x will be similarly defined throughout this work and will play a central role in the mathematical analysis. If we randomly choose a link from the network and travel along one direction of the link, there is a probability, x, that it would reach the giant component of the network, and a probability, , that it will not. (See figure 1 for an illustration.)\r\nMultilayer interdependent network\r\n3.1. Two-layer interdependent network\r\nIn the original and seminal work of Buldyrev et al [1], generating functions ware used to study the phase transitions in a two-layer interdependent network. The system consists of two networks, A and B, with degree distributions PA(k) and PB(k), respectively. Networks A and B both have N nodes, and each node in network A is linked with exactly one node in network B by a dependency link, and vice versa. The dependency link is different from the connectivity links within each network, in that once a node on one end of the dependency link is removed, the other node on the other network is also removed. This corresponds to the case where the failure of a power plant in the grid network will make the connected computer system shut down due to lack of electricity. Also, any node outside the giant cluster of its own network would fail since it is disconnected from the majority of the other nodes. In the defined mutually connected giant component (MCGC), every node in the giant component is connected via the connectivity links in its own network, and its dependent node is in the giant component of the other network as well. Thus the MCGC is a steady state of the remaining network, such that no further cascading of failures would happen.\r\nHere we present a simple method for studying the phase transition behaviors using the formulation extended from the previous section. Following the definition in equation (2), we define x as the probability that a randomly chosen link in network A leads to the giant component. Analogously, we define y as the probability that a randomly chosen link in network B leads to the giant component.\r\nIf a randomly chosen link in A leads to a node with degree k, the node is in the MCGC only if at least one of its other  links leads to the giant component and its dependent node in network B is also in the MCGC. Otherwise, this link will be not be in the MCGC, and it will eventually be deleted, according to [1]. (See figure 2 for a detailed illustration.) Therefore, by calculating the probability that a randomly chosen link in A leads to the MCGC, we would obtain Equation 9\r\nwhere  is the probability that at least one of node u's other  connectivity links in network A leads to the MCGC, and  is the probability that at least one of the k' connectivity links of the dependent node u' in network B leads to the MCGC.\r\n\r\nConclusion\r\nIn this work, we have provided a specific mathematical framework to review the critical phase transition behavior of interdependent networks, otherwise known as the network of networks. Starting from single random networks, we have shown that by defining two key mathematical quantities—the probabilities of finding a link/node in the final giant component—one is able to directly write down the sets of self-consistent equations of these quantities without going through the iterative process of cascading failures in stages. This methodology greatly simplifies the mathematical analysis in complicated network structures, especially in very complex systems involving correlations and multiple dependency links per node. In this self-consistent probabilities approach, we focus on the final equilibrium state of the networks; the original generating function framework in [1] managed to lend insight on the process of cascading failures, which is not coveredin this paper.\r\nThere have been many other works that we have not included here. For example, [9] analyzed multiplex-directed networks in the context of social networks. [40–42] studies evolutionary games. Interdependent networks with spatial constraint [43, 44] have been shown to exhibit unique phase transition behaviors, though we have not discussed them due to their analytical difficulties. In this work, our focus is to provide a mathematical overview using the specific technique of simplified self-consistent probabilities. The recursive mapping method [1] yields the same results, but we demonstrated that this particular method could greatly simplify the mathematical derivations for a wide range of complicated systems.\r\nAlthough this method proves to be applicable to a wide range of network systems in studying their percolation behaviors, caution must be taken when implementing it. It is crucial that the self-consistent equations be carefully constructed, such that every component of the equations strictly follows the branching process underlying the percolation behaviors.", user_id: 1, journal_id: 16, field_id: 16, institution_id: 28});

paper31 = Paper.create!({title: "Super-Almost Continuous Sets and Statistical Set Theory", body: "Introduction\r\nIt has long been known that v > Z [10]. In [33], the authors address the\r\nstability of globally smooth triangles under the additional assumption that\r\nI\r\n(g) ∈ e. In contrast, it is essential to consider that rg may be left-Russell.\r\nIs it possible to extend isometric lines? A useful survey of the subject can\r\nbe found in [31]. In [21], the authors address the regularity of classes under\r\nthe additional assumption that there exists a Cantor and trivially super-real\r\npoint. We wish to extend the results of [22, 6, 17] to pseudo-Hilbert–Leibniz\r\npaths.\r\nF. Zhou’s classification of naturally super-convex, Ramanujan triangles\r\nwas a milestone in analytic logic. Unfortunately, we cannot assume that.\r\nThis could shed important light on a conjecture of Sylvester. This could\r\nshed important light on a conjecture of Weil. It was Lie who first asked\r\nwhether locally algebraic Cayley spaces can be extended. Recent interest in\r\nreversible, anti-universal, ultra-pairwise n-dimensional groups has centered\r\non characterizing embedded paths. Here, convergence is trivially a concern.\r\nMoreover, every student is aware that ι(R¯) ∼= 2. Recently, there has been\r\nmuch interest in the computation of characteristic matrices. This could shed\r\nimportant light on a conjecture of Milnor–D´escartes.\r\nIt is well known that ¯c(JC ,u) <\r\n√\r\n2. In contrast, L. Zhou [12] improved\r\nupon the results of N. Zhao by computing fields. This reduces the results\r\nof [12] to well-known properties of Hadamard monodromies. In [24], the\r\nauthors computed smoothly irreducible functors. X. Zhou’s classification of\r\nsubgroups was a milestone in absolute graph theory. In [25], the authors\r\naddress the smoothness of minimal homomorphisms under the additional\r\nassumption that 1−3 6= d\r\n\u0010\r\nΦ( ¯ Z(γ))2\r\n\r\nIt is well known that A0−5 = ζ (π × νˆ). Recent interest in compactly\r\np-adic monoids has centered on computing everywhere complex primes. Recently,\r\nthere has been much interest in the characterization of conditionally\r\nintegral topoi. Thus in [5], the authors address the connectedness of isomorphisms\r\nunder the additional assumption that every complex, everywhere\r\ninjective homeomorphism is convex and standard. The work in [14] did not\r\nconsider the Artinian case.\r\n2. Main Result\r\nDefinition 2.1. A category j0\r\nis multiplicative if Λ ∼= w.\r\nDefinition 2.2. A right-admissible, surjective, non-projective isometry ι is\r\nextrinsic if F is null and connected.\r\nWe wish to extend the results of [16] to right-prime, Peano functions.\r\nThe groundbreaking work of C. Peano on complex, tangential, conditionally\r\nnatural topoi was a major advance. In contrast, this reduces the results\r\nof [31] to the existence of almost surely convex, nonnegative arrows. U.\r\nSuzuki [34] improved upon the results of A. Zhao by describing fields. So it\r\nwould be interesting to apply the techniques of [33] to countably compact\r\nsubsets. Recently, there has been much interest in the extension of semialgebraically\r\nsurjective subrings. Recent developments in p-adic arithmetic\r\n[31, 15] have raised the question of whether ε\r\n(S ) 6= ψ0\r\n. Therefore this reduces\r\nthe results of [22] to a standard argument. This could shed important light\r\non a conjecture of Monge. A central problem in introductory non-linear\r\ntopology is the extension of pairwise measurable, universally smooth, contraEuler–Dedekind\r\nelements.\r\nDefinition 2.3. Let C\r\n(n) be an algebraically admissible monoid. We say\r\na line ΓQ,` is Artinian if it is non-canonically quasi-multiplicative, Jacobi,\r\nlocal and unconditionally algebraic.\r\nWe now state our main result.\r\nTheorem 2.4. Let F be a ρ-negative functional. Let Ξ = ℵ0 be arbitrary.\r\nThen the Riemann hypothesis holds. It was Leibniz who first asked whether trivial, naturally Taylor, smoothly\r\nco-reducible functions can be derived. A useful survey of the subject can be\r\nfound in [30]. It is essential to consider that P\r\n0 may be locally bounded. In\r\n[5], the main result was the derivation of ultra-reversible topological spaces.\r\nThe goal of the present paper is to compute meromorphic algebras. A useful\r\nsurvey of the subject can be found in [1].\r\n\r\nBasic Results of Analytic Representation Theory\r\nIn [30], the authors described Dirichlet functionals. Thus it would be\r\ninteresting to apply the techniques of [10] to everywhere contra-dependent,\r\nalmost everywhere extrinsic rings. In this setting, the ability to characterize\r\nsub-Fourier, real monoids is essential. Next, R. Z. Sato [27] improved upon\r\nthe results of V. Suzuki by computing stable sets. In future work, we plan\r\nto address questions of measurability as well as countability. In [35], the\r\nmain result was the classification of embedded, anti-arithmetic points.\r\nLet T (u) ∼= Z(y\r\n0\r\n).\r\nDefinition 3.1. Let ν = ℵ0. We say a reversible, prime triangle acting\r\npairwise on a Wiener class E is Cartan–D´escartes if it is globally Siegel.\r\nDefinition 3.2. Let R be an embedded system. We say a null, analytically\r\nanti-independent isometry mM is Noetherian if it is invertible, bounded\r\nand freely differentiable.\r\nProposition 3.3. Let us assume we are given an one-to-one, Deligne, linearly\r\nsuper-one-to-one system η¯. Let ˜b ≤ ℵ0. Then there exists a real and\r\nquasi-embedded algebraic system. Proof. We show the contrapositive. By an easy exercise, every measurable,\r\nembedded, independent matrix is Riemannian and quasi-almost surely\r\ncanonical.\r\nOne can easily see that if ˜` 6= |kη| then every continuously d’Alembert\r\nfunction is sub-composite and Conway.\r\nObviously, j = E. Trivially, x is hyperbolic and multiply hyper-surjective.\r\nOf course, |c˜| ≤ C (q). Hence every topos is hyper-analytically irreducible\r\nand conditionally Hippocrates–Thompson. So J 00(¯r) ≤ d(s). So Ξ ⊂ 1.\r\nMoreover, if J is Landau then |n| ≡ kΨ¯ k.\r\nBy existence, if the Riemann hypothesis holds then Siegel’s criterion applies.\r\nObviously, S(hA) ≤ φ(i\r\n0\r\n). Of course, there exists a non-essentially\r\nco-associative meromorphic isomorphism. By existence, if Heaviside’s condition\r\nis satisfied then Let N be a scalar. By a well-known result of Grassmann [18], if ι\r\n0\r\nis\r\nsmoothly Fibonacci–Abel and pointwise negative then e = −∞. Moreover,\r\nif J <\r\n√\r\n2 then there exists a convex, continuously maximal, everywhere\r\nleft-commutative and elliptic smooth monoid. Now if Q ≤ kFk then K 0\r\nis\r\nnot larger than s. By a standard argument, if Ξ¯ < −1 then f\r\n00 ∈ −1. In\r\ncontrast, π ⊂ π. Obviously, if the Riemann hypothesis holds.\r\nIn contrast, Z is partially super-D´escartes, Noether and dependent. This\r\ncompletes the proof.\r\nProposition 3.4. Suppose we are given a sub-measurable class gk,z. Let\r\n|p| > ℵ0 be arbitrary. Then −∞ > τ (K)−1\r\n\u0010\r\ngW˜\r\n\u0011\r\n.\r\nProof. We proceed by induction. Assume we are given a quasi-everywhere\r\npseudo-meager factor Q. Clearly, if Γ 6= ∞ then Y ⊃ 0. Thus if the Riemann\r\nhypothesis holds then Clifford’s conjecture is false in the context of ultrabounded\r\npoints. Trivially, if Lm ≤ e then X00 is greater than `V . Note\r\nthat there exists a holomorphic compactly non-separable category. Clearly,\r\nif |P| 6= kh\r\n00k then there exists a positive definite quasi-complex element.\r\nBecause L ≥ c, if e is differentiable then π\r\n(i) ≥ ϕt(K). Note that if λ is\r\nEuclidean, freely surjective and geometric then β\r\n00 6= Z(T). One can easily\r\nsee that if m is simply Leibniz and super-D´escartes then every field is freely\r\ncanonical, anti-finitely admissible and composite.\r\nFundamental Properties of Isomorphisms\r\nEvery student is aware that w00 → kaik. This reduces the results of [14]\r\nto a recent result of Bhabha [18]. This could shed important light on a\r\nconjecture of Newton.\r\nLet u¯ be a countable curve equipped with a negative definite, contrastandard,\r\nΨ-nonnegative triangle.\r\nDefinition 4.1. A pairwise hyper-Cayley path χ is Monge–Beltrami if\r\nU ≤ E.\r\nDefinition 4.2. Let us assume we are given a contra-continuously tangential,\r\nsimply negative isomorphism B. We say a topos t\r\n00 is universal if it is\r\nglobally null and co-universally degenerate.\r\nFundamental Properties of Pseudo-Trivially Steiner,\r\nQuasi-Linearly Independent Arrows\r\nA central problem in statistical geometry is the computation of pseudocharacteristic\r\nalgebras. This leaves open the question of uniqueness. Unfortunately,\r\nwe cannot assume that w0\r\nis not homeomorphic to d. The\r\ngoal of the present paper is to study integral sets. Next, it is not yet known\r\nwhether every simply super-measurable vector is multiplicative, local, stable\r\nand composite, although [12] does address the issue of continuity.\r\nSuppose ρ\r\n0\r\nis controlled by c.\r\nDefinition 5.1. Let L 3 2. We say a left-infinite, additive path equipped\r\nwith an invariant subalgebra jm,Σ is differentiable if it is non-freely M¨obius.\r\nDefinition 5.2. A contravariant monoid c is characteristic if J\r\n00 is leftfreely\r\np-adic.\r\nLemma 5.3. Let p < −1 be arbitrary. Then a ⊃ PH,F .\r\nProof. We begin by considering a simple special case. Trivially, if Littlewood’s\r\ncriterion applies then D(c) = qJ . Next, there exists a superalgebraically\r\nsub-orthogonal and hyper-Gaussian canonical, meager, bounded\r\nline. On the other hand, J\r\n0\r\nis arithmetic and holomorphic. As we have\r\nshown, every almost pseudo-Laplace system is independent. Since f\r\n00 is stable,\r\nultra-almost surely ordered, sub-unique and minimal, j = 1. On the\r\nother hand, u(C) ≤ G00. Now if Tˆ ≤ O then every universal, Cardano prime\r\nis generic and trivially right-Noetherian. So F¯ ≥ ℵ0.\r\n\r\nConclusion\r\nRecent interest in functions has centered on extending onto, Cavalieri\r\nfields. On the other hand, G. Moore’s derivation of left-additive, Maclaurin,\r\nbijective functionals was a milestone in formal knot theory. V. Anderson’s\r\nderivation of meager, intrinsic monodromies was a milestone in potential\r\ntheory. In [5], the authors described discretely Banach random variables.\r\nRecent developments in introductory non-commutative representation theory\r\n[29] have raised the question of whether every Cantor point is empty.\r\nThus it would be interesting to apply the techniques of [28] to pseudoinvertible\r\nrings. In contrast, W. White’s computation of admissible random\r\nvariables was a milestone in universal topology. Next, this leaves open the\r\nquestion of uncountability. It has long been known that Vˆ ∼= −1 [35]. On\r\nthe other hand, a useful survey of the subject can be found in [14].", user_id: 1, journal_id: 17, field_id: 17, institution_id: 6});

paper32 = Paper.create!({title: "Algebraically Non-Composite Polytopes and Elliptical Category Theory", body: "Introduction\r\nRecently, there has been much interest in the description of multiply Cantor\r\npaths. Recently, there has been much interest in the extension of injective points.\r\nNow we wish to extend the results of [15, 15, 21] to subalegebras. Therefore in\r\nthis setting, the ability to characterize sub-almost surely integral, compactly surjective\r\nequations is essential. G. L. Heaviside [37] improved upon the results of S.\r\nNoether by constructing isometric numbers. It is well known that there exists a\r\nbijective globally projective, unique algebra. W. White’s derivation of super-Boole\r\nmorphisms was a milestone in pure calculus.\r\nIt has long been known that H is dominated by T [22]. It is essential to consider\r\nthat ζ may be compactly meager. Is it possible to examine right-stochastic arrows?\r\nL. Kumar’s derivation of canonically dependent random variables was a milestone\r\nin universal graph theory. Thus this reduces the results of [48] to Hilbert’s theorem.\r\nHence it would be interesting to apply the techniques of [22] to hyperbolic, leftalmost\r\neverywhere co-Lebesgue, non-Cantor points. This could shed important\r\nlight on a conjecture of Levi-Civita.\r\nA central problem in constructive group theory is the computation of meager\r\nfields. In future work, we plan to address questions of completeness as well as convergence.\r\nIt is well known that there exists an arithmetic, unconditionally J-unique,\r\nfinitely quasi-linear and onto positive definite vector space. A central problem in \r\ndifferential topology is the construction of numbers. Therefore A. Martin [19, 23]\r\nimproved upon the results of E. Cauchy by studying extrinsic subsets. A useful survey\r\nof the subject can be found in [43]. In [26], the authors address the uniqueness\r\nof sub-open functors under the additional assumption that there exists a reversible,\r\nstable, contra-commutative and Markov commutative graph. Now this could shed\r\nimportant light on a conjecture of Smale. P. H. Raman’s derivation of contramultiply\r\nnatural subrings was a milestone in microlocal measure theory. On the\r\nother hand, unfortunately, we cannot assume that every embedded, independent\r\nset equipped with an almost natural curve is contra-affine.\r\nIn [26], the main result was the characterization of pseudo-Grassmann–Russell\r\nfactors. In future work, we plan to address questions of measurability as well as\r\nexistence. This reduces the results of [43] to a standard argument. Hence the\r\ngroundbreaking work of N. Sasaki on totally Cantor, uncountable categories was\r\na major advance. Recent developments in axiomatic topology [41] have raised the\r\nquestion of whether there exists a contra-degenerate, Grothendieck, invertible and\r\nnegative definite generic manifold. This leaves open the question of smoothness.\r\nRecent developments in integral PDE [31, 21, 2] have raised the question of whether\r\nˆs is bounded.\r\n\r\nMain Result\r\nDefinition 2.1. A characteristic, unconditionally extrinsic, invertible point ξ\r\n(A)\r\nis\r\nempty if Θ00 is not smaller than v.\r\nDefinition 2.2. A left-multiply natural, composite random variable equipped with\r\nan ordered subset X is empty if L is bounded by N (e)\r\n.\r\nRecently, there has been much interest in the extension of left-commutative,\r\nhyper-trivially nonnegative, closed factors. It is not yet known whether every Riemannian\r\nmonodromy acting freely on a completely projective scalar is partially\r\nsemi-Riemannian and pseudo-measurable, although [6] does address the issue of\r\nuncountability. The groundbreaking work of O. Zheng on super-separable topoi\r\nwas a major advance. Recently, there has been much interest in the extension\r\nof Q-maximal, algebraically Weil rings. It would be interesting to apply the techniques\r\nof [48] to super-empty triangles. Recent developments in differential topology\r\n[38, 37, 46] have raised the question of whether Nˆ − ∞ ≡ g\r\n−1\r\n\u0010\r\nZˆ(c)\r\n3\r\n\u0011\r\n. S. Moore\r\n[15] improved upon the results of T. Huygens by describing trivially orthogonal\r\nfunctors. It has long been known that w ≤ ˜d\r\n−1\r\n(−∅) [21]. The work in [40] did not\r\nconsider the local, contravariant, invertible case. Hence in this context, the results\r\nof [19] are highly relevant.\r\nDefinition 2.3. A homeomorphism V˜ is Pythagoras if ϕ ≥ kPk.\r\nWe now state our main result.\r\nTheorem 2.4. Let θC,r →\r\n√\r\n2. Then Heaviside’s conjecture is true in the context\r\nof linearly right-integral rings.\r\nIn [5], it is shown that every hyperbolic triangle is completely complex and\r\nDarboux. Recently, there has been much interest in the computation of hyperEinstein–Legendre\r\npoints. In this context, the results of [6] are highly relevant.\r\nThis leaves open the question of uniqueness. A useful survey of the subject can \r\nbe found in [13]. Is it possible to characterize random variables? G. Martin [7]\r\nimproved upon the results of K. Wang by examining co-normal factors. This could\r\nshed important light on a conjecture of Frobenius. So a useful survey of the subject\r\ncan be found in [32]. Therefore it is not yet known whether I ≡ˆ Y\r\n0\r\n, although [31]\r\ndoes address the issue of splitting.\r\nFundamental Properties of Partial Topoi\r\nIn [11], the authors described compactly finite, canonically anti-arithmetic, closed\r\nmorphisms. The work in [39] did not consider the contra-Hausdorff case. In [33],\r\nthe authors address the compactness of dependent graphs under the additional assumption\r\nthat there exists a stable and freely right-admissible hyper-trivial, ultrauncountable\r\nsubgroup. The work in [38] did not consider the stochastically measurable,\r\ncountably real, super-invariant case. J. P. Dirichlet’s derivation of discretely\r\nunique hulls was a milestone in general number theory. We wish to extend the\r\nresults of [34] to Perelman homomorphisms. Now recently, there has been much\r\ninterest in the derivation of right-essentially maximal monoids.\r\nLet us assume 2 ≥ sinh\r\nξ\r\n\r\nDefinition 3.1. Let d be a quasi-multiplicative matrix. We say a d-conditionally\r\nirreducible, semi-multiplicative, parabolic element equipped with an intrinsic, semimaximal\r\nfield T\r\n0\r\nis Kronecker if it is almost everywhere right-Euclidean.\r\nDefinition 3.2. Let us suppose we are given a positive element l. We say a\r\nmultiplicative hull acting simply on a n-dimensional modulus ι is n-dimensional\r\nif it is Cauchy.\r\nTheorem 3.3. Let Z\r\n00 ≥ ℵ0. Then Jˆ ≥ ∞\r\nThe goal of the present paper is to characterize non-parabolic, elliptic, Y -projective\r\nalgebras. In [24, 36], the authors address the positivity of symmetric, convex, nonnegative\r\ndefinite vector spaces under the additional assumption that there exists a\r\nbounded extrinsic, linearly pseudo-complete manifold. V. Wu [7] improved upon\r\nthe results of O. K. Moore by examining left-algebraic, right-tangential, convex\r\nfunctionals. The goal of the present paper is to describe M¨obius, degenerate, stochastic\r\nsubgroups. So we wish to extend the results of [40] to canonically projective,\r\nhyper-Milnor, naturally invertible planes. The groundbreaking work of T. Watanabe\r\non left-multiplicative random variables was a major advance. Is it possible to\r\nderive canonical subalegebras?\r\nSuppose φˆ is super-associative and left-additive.\r\nDefinition 4.1. Let W ∼= \u000F. A prime group is an ideal if it is hyper-Jordan and\r\nnegative.\r\nDefinition 4.2. Let K be a semi-nonnegative definite, compact, singular factor.\r\nA Frobenius scalar is a scalar if it is anti-continuous and independent.\r\nLemma 4.3. Let v¯ ⊂ L be arbitrary. Then O = ∞.\r\nProof. We show the contrapositive. Let us suppose we are given an irreducible\r\nsubring ˜µ. It is easy to see that if ` < √\r\n2 then m(F)\r\nis equal to d. Hence if λ¯ is\r\nanalytically co-covariant and countably Frobenius then Yˆ is multiplicative. Now\r\nMilnor’s criterion applies. Hence if Q is Kovalevskaya and surjective then there\r\nexists a non-Artinian and negative definite ideal. Obviously, a` ≥ 2. Moreover,\r\nc ⊂ 1. This is the desired statement.\r\nIt is well known that Σ˜ ∈ Z. In this context, the results of [13] are highly relevant.\r\nIt would be interesting to apply the techniques of [28] to extrinsic manifolds. In\r\nfuture work, we plan to address questions of invariance as well as measurability. A\r\nuseful survey of the subject can be found in [4]. It has long been known that B¯ is\r\nLegendre [10]. It is well known that every continuously Cayley monoid equipped\r\nwith an elliptic system is infinite. In this context, the results of [5] are highly\r\nrelevant. A central problem in axiomatic combinatorics is the derivation of almost \r\nsurely ultra-commutative subrings. A useful survey of the subject can be found in [].\r\n\r\nConclusion\r\nIs it possible to construct Hamilton subrings? Recent interest in isomorphisms\r\nhas centered on constructing locally complex, unique classes. Hence recent developments\r\nin spectral graph theory [8] have raised the question of whether φ > ∆.\r\nConjecture 6.1. Let Y (πU,I ) 6= i. Let Zˆ be a generic number equipped with a\r\ncountably elliptic arrow. Further, let F be a homomorphism. Then there exists a\r\ncountably meromorphic arithmetic, hyper-countable isometry.\r\nIn [37], the authors derived matrices. It is essential to consider that R may\r\nbe linear. V. Taylor [42] improved upon the results of X. O. Euler by extending\r\nhyperbolic subalegebras. E. Thompson [14] improved upon the results of X. Bose\r\nby studying contra-everywhere left-Deligne paths. In [38], it is shown that E > Q˜.\r\nThis could shed important light on a conjecture of Clifford. It was Abel who first\r\nasked whether hyper-globally j-open homomorphisms can be examined. It would\r\nbe interesting to apply the techniques of [3] to uncountable ideals. In [17, 35, 1], it\r\nis shown that", user_id: 1, journal_id: 18, field_id: 17, institution_id: 6});


Author.create!([
  {name: "Michael Wehr"},
  {name: "Anthony Zador"},
  {name: "Alan Lloyd Hodgkin"},
  {name: "Andrew Huxley"},
  {name: "Hillel Adesnik"},
  {name: "William Bruns"},
  {name: "Hiroki Taniguchi"},
  {name: "Josh Huang"},
  {name: "Massimo Scanziani"},
  {name: "Carlos Cerqueira-Silva"},
  {name: "Onildo Jesus"},
  {name: "Elisa Santos"},
  {name: "Ronan Correa"},
  {name: "Anete Souza"},
  {name: "Alexander Hoepker"},
  {name: "David Collum"},
  {name: "Q. Wu"},
  {name: "Z. Qian"},
  {name: "Y. Jackson"},
  {name: "I. Kumar"},
  {name: "E. Sun"},
  {name: "R. Moore"},
  {name: "S. Williams"},
  {name: "X. Watanabe"},
  {name: "K. Wang"},
  {name: "W. Suzuki"},
  {name: "Saul Perlmutter"},
  {name: "Gregory Aldering"},
  {name: "Gerson Goldhaber"},
  {name: "Achilles Speliotopoulos"},
  {name: "Cynthia M. Sharma"},
  {name: "Steve Hoffmann"},
  {name: "Fabien Darfeuille"},
  {name: "Alexandra Sittka"},
  {name: "Sandrine Chabas"},
  {name: "Kristin Reiche"},
  {name: "Richard Reinhardt"},
  {name: "Peter F. Stadler"},
  {name: "Jorg Vogel"},
  {name: "Ping Wang"},
  {name: "Lydia Robert"},
  {name: "James Pelletier"},
  {name: "Wei Lien Dang"},
  {name: "Francois Taddei"},
  {name: "Andrew Wright"},
  {name: "Suckjoon Jun"},
  {name: "Christopher Gregg"},
  {name: "Jiangwen Zhang"},
  {name: "Brandon Weissbourd"},
  {name: "Shujun Luo"},
  {name: "Gary P. Schroth"},
  {name: "David Haig"},
  {name: "Catherine Dulac"},
  {name: "Hsin-Kai Liao"},
  {name: "Ying Gu"},
  {name: "Arturo Diaz"},
  {name: "John Marlett"},
  {name: "Yuta Takahashi"},
  {name: "Keiichiro Suzuki"},
  {name: "John Young"},
  {name: "Juan Carlos Izpisua Belmonte"},
  {name: "Karine Bagramyan"},
  {name: "Jason Barash"},
  {name: "Stephen Arnon"},
  {name: "Markus Kalkum"},
  {name: "Bogdan Z. Dlugogorski"},
  {name: "Eric M. Kennedy"},
  {name: "John C. Mackie"},
  {name: "Jeff Gore"},
  {name: "Mohammednoor Altarawneh"},
  {name: "Hugo E. Gottlieb"},
  {name: "Vadim Kotlyar"},
  {name: "Abraham Nudelman"},
  {name: "Jeffrey F. Van Humbecka"},
  {name: "Rob Amelootd"},
  {name: "William Dichtelc"},
  {name: "Jeffrey R. Long"},
  {name: "Ben Adler"},
  {name: "Marina Harper"},
  {name: "John Boyce"},
  {name: "Mark Bennett"},
  {name: "Rachel S. Schwartz"},
  {name: "Kelly M. Harkins"},
  {name: "Anne C. Stone"},
  {name: "Reed A. Cartwright"},
  {name: "Jun Zhanga"},
  {name: "Zhi-Ming Zhanga"},
  {name: "Qiu-Yu Lib"},
  {name: "En-Bo Wang"},
  {name: "Cheng Wanga"},
  {name: "Yang Gaoa"},
  {name: "Lili Lva"},
  {name: "Jinhui Changa"},
  {name: "Wenhui Hao"},
  {name: "Chun-Ying Zheng"},
  {name: "Hui Li"},
  {name: "Rezaul Karim"},
  {name: "Abdul Alim"},
  {name: "Laek Sazzad Andallah"},
  {name: "Pradyumn Kumar Sahoo"},
  {name: "Bivudutta Mishra"},
  {name: "Mahdi Afshar"},
  {name: "Mahboobeh Babaei"},
  {name: "Amir Hossein Kordbacheh"},
  {name: "Akpan Ikot"},
  {name: "Elham Maghsoodi"},
  {name: "Saber Zarrinkamar"},
  {name: "Hassan Hassanabadi"},
  {name: "Roger Bach"},
  {name: "Damian Pope"},
  {name: "Sy-Hwang Liou"},
  {name: "Herman Batelaan"},
  {name: "Ling Feng"},
  {name: "Christopher Pineda Monterola"},
  {name: "Yanqing Hu"},
  {name: "R. Gupta"},
  {name: "Q. Sato"},
  {name: "P. W. Jackson"},
  {name: "P. Smith"},
  {name: "G. Watanabe"},
  {name: "U. Gian"},
  {name: "J. Wu"},
  {name: "Y. Harris"}
])
AuthorTagging.create!([
  {paper_id: paper1.id, author_id: 1},
  {paper_id: paper1.id, author_id: 2},
  {paper_id: paper2.id, author_id: 3},
  {paper_id: paper2.id, author_id: 4},
  {paper_id: paper3.id, author_id: 5},
  {paper_id: paper3.id, author_id: 6},
  {paper_id: paper3.id, author_id: 7},
  {paper_id: paper3.id, author_id: 8},
  {paper_id: paper3.id, author_id: 9},
  {paper_id: paper4.id, author_id: 10},
  {paper_id: paper4.id, author_id: 11},
  {paper_id: paper4.id, author_id: 12},
  {paper_id: paper4.id, author_id: 13},
  {paper_id: paper4.id, author_id: 14},
  {paper_id: paper5.id, author_id: 15},
  {paper_id: paper5.id, author_id: 16},
  {paper_id: paper6.id, author_id: 17},
  {paper_id: paper6.id, author_id: 18},
  {paper_id: paper6.id, author_id: 19},
  {paper_id: paper6.id, author_id: 20},
  {paper_id: paper7.id, author_id: 21},
  {paper_id: paper7.id, author_id: 22},
  {paper_id: paper7.id, author_id: 20},
  {paper_id: paper8.id, author_id: 22},
  {paper_id: paper8.id, author_id: 23},
  {paper_id: paper8.id, author_id: 24},
  {paper_id: paper8.id, author_id: 17},
  {paper_id: paper10.id, author_id: 20},
  {paper_id: paper10.id, author_id: 25},
  {paper_id: paper10.id, author_id: 26},
  {paper_id: paper11.id, author_id: 27},
  {paper_id: paper11.id, author_id: 28},
  {paper_id: paper11.id, author_id: 29},
  {paper_id: paper12.id, author_id: 30},
  {paper_id: paper13.id, author_id: 31},
  {paper_id: paper13.id, author_id: 32},
  {paper_id: paper13.id, author_id: 33},
  {paper_id: paper13.id, author_id: 34},
  {paper_id: paper13.id, author_id: 35},
  {paper_id: paper13.id, author_id: 36},
  {paper_id: paper13.id, author_id: 37},
  {paper_id: paper13.id, author_id: 38},
  {paper_id: paper13.id, author_id: 39},
  {paper_id: paper14.id, author_id: 40},
  {paper_id: paper14.id, author_id: 41},
  {paper_id: paper14.id, author_id: 42},
  {paper_id: paper14.id, author_id: 43},
  {paper_id: paper14.id, author_id: 44},
  {paper_id: paper14.id, author_id: 45},
  {paper_id: paper14.id, author_id: 46},
  {paper_id: paper15.id, author_id: 47},
  {paper_id: paper15.id, author_id: 48},
  {paper_id: paper15.id, author_id: 49},
  {paper_id: paper15.id, author_id: 50},
  {paper_id: paper15.id, author_id: 51},
  {paper_id: paper15.id, author_id: 52},
  {paper_id: paper15.id, author_id: 53},
  {paper_id: paper16.id, author_id: 54},
  {paper_id: paper16.id, author_id: 55},
  {paper_id: paper16.id, author_id: 56},
  {paper_id: paper16.id, author_id: 57},
  {paper_id: paper16.id, author_id: 58},
  {paper_id: paper16.id, author_id: 59},
  {paper_id: paper16.id, author_id: 60},
  {paper_id: paper16.id, author_id: 61},
  {paper_id: paper17.id, author_id: 62},
  {paper_id: paper17.id, author_id: 63},
  {paper_id: paper17.id, author_id: 64},
  {paper_id: paper17.id, author_id: 65},
  {paper_id: paper18.id, author_id: 66},
  {paper_id: paper18.id, author_id: 67},
  {paper_id: paper18.id, author_id: 68},
  {paper_id: paper18.id, author_id: 69},
  {paper_id: paper18.id, author_id: 70},
  {paper_id: paper19.id, author_id: 71},
  {paper_id: paper19.id, author_id: 72},
  {paper_id: paper19.id, author_id: 73},
  {paper_id: paper20.id, author_id: 74},
  {paper_id: paper20.id, author_id: 75},
  {paper_id: paper20.id, author_id: 76},
  {paper_id: paper20.id, author_id: 77},
  {paper_id: paper21.id, author_id: 78},
  {paper_id: paper21.id, author_id: 79},
  {paper_id: paper21.id, author_id: 80},
  {paper_id: paper21.id, author_id: 81},
  {paper_id: paper22.id, author_id: 82},
  {paper_id: paper22.id, author_id: 83},
  {paper_id: paper22.id, author_id: 84},
  {paper_id: paper22.id, author_id: 85},
  {paper_id: paper23.id, author_id: 86},
  {paper_id: paper23.id, author_id: 87},
  {paper_id: paper23.id, author_id: 88},
  {paper_id: paper23.id, author_id: 89},
  {paper_id: paper24.id, author_id: 90},
  {paper_id: paper24.id, author_id: 91},
  {paper_id: paper24.id, author_id: 92},
  {paper_id: paper24.id, author_id: 93},
  {paper_id: paper24.id, author_id: 94},
  {paper_id: paper25.id, author_id: 95},
  {paper_id: paper25.id, author_id: 96},
  {paper_id: paper26.id, author_id: 97},
  {paper_id: paper26.id, author_id: 98},
  {paper_id: paper26.id, author_id: 99},
  {paper_id: paper27.id, author_id: 100},
  {paper_id: paper27.id, author_id: 101},
  {paper_id: paper28.id, author_id: 102},
  {paper_id: paper28.id, author_id: 103},
  {paper_id: paper28.id, author_id: 104},
  {paper_id: paper29.id, author_id: 105},
  {paper_id: paper29.id, author_id: 106},
  {paper_id: paper29.id, author_id: 107},
  {paper_id: paper29.id, author_id: 108},
  {paper_id: paper30.id, author_id: 109},
  {paper_id: paper30.id, author_id: 110},
  {paper_id: paper30.id, author_id: 111},
  {paper_id: paper30.id, author_id: 112},
  {paper_id: paper31.id, author_id: 113},
  {paper_id: paper31.id, author_id: 114},
  {paper_id: paper31.id, author_id: 115},
  {paper_id: paper32.id, author_id: 116},
  {paper_id: paper32.id, author_id: 117},
  {paper_id: paper32.id, author_id: 118},
  {paper_id: paper32.id, author_id: 119}
  # {paper_id: paper33.id, author_id: 120},
  # {paper_id: paper33.id, author_id: 121},
  # {paper_id: paper33.id, author_id: 122},
  # {paper_id: paper33.id, author_id: 123}
])

Annotation.create!([
  {user_id: 1, paper_id: 1, body: "This would ordinarily be an insightful comment by either the author or researcher in the field explaining this concept", start_index: 1100, end_index: 1291},
  {user_id: 1, paper_id: 2, body: "This is now widely accepted and a core concept of neurobiology research", start_index: 1167, end_index: 1488},
  {user_id: 4, paper_id: 18, body: "testing annotation", start_index: 342, end_index: 608},
  {user_id: 4, paper_id: 1, body: "patch-clamping is pretty crazy", start_index: 1534, end_index: 1834},
  {user_id: 5, paper_id: 6, body: "All of these math papers are actually fake", start_index: 154, end_index: 248},
  {user_id: 5, paper_id: 7, body: "Lots of real, famous mathematicians are mentioned in these papers to make them seem more real", start_index: 664, end_index: 784},
  {user_id: 5, paper_id: 7, body: "You will also notice a lot of questions", start_index: 2617, end_index: 2665},
  {user_id: 5, paper_id: 8, body: "the equations do seem to be a mess, but with some time, the seed data could be much cleaner", start_index: 243, end_index: 398},
  {user_id: 5, paper_id: 8, body: "another common phrase", start_index: 4155, end_index: 4187},
  {user_id: 6, paper_id: 11, body: "My physics lecture was cancelled two years ago because the acceptance speech for the Nobel prize for this work was being given in that lecture hall\r\n\r\n-Jenny", start_index: 9, end_index: 214},
  {user_id: 6, paper_id: 12, body: "This was one of my physics professors in college", start_index: 612, end_index: 1036},
  {user_id: 4, paper_id: 5, body: "I worked for Alex as an undergraduate for a while. Great guy!\r\n\r\n(this is not an example of a good annotation)", start_index: 841, end_index: 1161},
  {user_id: 4, paper_id: 19, body: "That's a lot of solutions...", start_index: 1674, end_index: 2768},
  {user_id: 4, paper_id: 19, body: "The amount of time I have spent reading NMR graphs...", start_index: 3073, end_index: 3212}
])

Comment.create!([
  {body: "Another neuroscientist might reply to this annotation, proposing an amendment or addition", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "If someone had something to say about this paper overall, for instance explaining its impact on the field, that comment would go here", commentable_id: 1, commentable_type: "Paper", user_id: 1},
  {body: "Comments will be ranked in order of number of votes", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "Comments are ordered by number of votes", commentable_id: 1, commentable_type: "Paper", user_id: 1},
  {body: "comment 3", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "comment 4", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "comment 5", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "comment 6", commentable_id: 1, commentable_type: "Annotation", user_id: 1},
  {body: "test comment", commentable_id: 1, commentable_type: "Paper", user_id: 6},
  {body: "new comment", commentable_id: 1, commentable_type: "Paper", user_id: 6},
  {body: "perhaps you should come up with more creative seed data?", commentable_id: 4, commentable_type: "Annotation", user_id: 4},
  {body: "Excellent!", commentable_id: 18, commentable_type: "Paper", user_id: 4},
  {body: "comment", commentable_id: 19, commentable_type: "Paper", user_id: 1},
  {body: "visit http://thatsmathematics.com/mathgen/\r\n\r\nit's pretty cool!", commentable_id: 6, commentable_type: "Annotation", user_id: 5},
  {body: "You don't say!", commentable_id: 11, commentable_type: "Annotation", user_id: 4}
])

Vote.create!([
  {user_id: 1, comment_id: 15, value: 1},
  {user_id: 1, comment_id: 16, value: -1},
  {user_id: 1, comment_id: 18, value: 0},
  {user_id: 1, comment_id: 19, value: 0},
  {user_id: 1, comment_id: 1, value: 1},
  {user_id: 6, comment_id: 21, value: 1},
  {user_id: 4, comment_id: 23, value: -1},
  {user_id: 4, comment_id: 24, value: 1},
  {user_id: 1, comment_id: 17, value: -1},
  {user_id: 5, comment_id: 28, value: 1}
])
